{"meta":{"exported_on":1443422519736,"version":"003"},"data":{"posts":[{"id":1,"uuid":"46dce593-8735-4639-9f5e-090d2549726b","title":"Welcome to Ghost","slug":"welcome-to-ghost","markdown":"You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at `<your blog URL>/ghost/`. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!\n\n## Getting Started\n\nGhost uses something called Markdown for writing. Essentially, it's a shorthand way to manage your post formatting as you write!\n\nWriting in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use *shortcuts* to **style** your content. For example, a list:\n\n* Item number one\n* Item number two\n    * A nested item\n* A final item\n\nor with numbers!\n\n1. Remember to buy some milk\n2. Drink the milk\n3. Tweet that I remembered to buy the milk, and drank it\n\n### Links\n\nWant to link to a source? No problem. If you paste in url, like http://ghost.org - it'll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here's a link to [the Ghost website](http://ghost.org). Neat.\n\n### What about Images?\n\nImages work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:\n\n![The Ghost Logo](https://ghost.org/images/ghost.png)\n\nNot sure which image you want to use yet? That's ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:\n\n![A bowl of bananas]\n\n\n### Quoting\n\nSometimes a link isn't enough, you want to quote someone on what they've said. It was probably very wisdomous. Is wisdomous a word? Find out in a future release when we introduce spellcheck! For now - it's definitely a word.\n\n> Wisdomous - it's definitely a word.\n\n### Working with Code\n\nGot a streak of geek? We've got you covered there, too. You can write inline `<code>` blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.\n\n    .awesome-thing {\n        display: block;\n        width: 100%;\n    }\n\n### Ready for a Break? \n\nThrow 3 or more dashes down on any new line and you've got yourself a fancy new divider. Aw yeah.\n\n---\n\n### Advanced Usage\n\nThere's one fantastic secret about Markdown. If you want, you can  write plain old HTML and it'll still work! Very flexible.\n\n<input type=\"text\" placeholder=\"I'm an input field!\" />\n\nThat should be enough to get you started. Have fun - and let us know what you think :)","html":"<p>You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at <code>&lt;your blog URL&gt;/ghost/</code>. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!</p>\n\n<h2 id=\"gettingstarted\">Getting Started</h2>\n\n<p>Ghost uses something called Markdown for writing. Essentially, it's a shorthand way to manage your post formatting as you write!</p>\n\n<p>Writing in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use <em>shortcuts</em> to <strong>style</strong> your content. For example, a list:</p>\n\n<ul>\n<li>Item number one</li>\n<li>Item number two\n<ul><li>A nested item</li></ul></li>\n<li>A final item</li>\n</ul>\n\n<p>or with numbers!</p>\n\n<ol>\n<li>Remember to buy some milk  </li>\n<li>Drink the milk  </li>\n<li>Tweet that I remembered to buy the milk, and drank it</li>\n</ol>\n\n<h3 id=\"links\">Links</h3>\n\n<p>Want to link to a source? No problem. If you paste in url, like <a href=\"http://ghost.org\">http://ghost.org</a> - it'll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here's a link to <a href=\"http://ghost.org\">the Ghost website</a>. Neat.</p>\n\n<h3 id=\"whataboutimages\">What about Images?</h3>\n\n<p>Images work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:</p>\n\n<p><img src=\"https://ghost.org/images/ghost.png\" alt=\"The Ghost Logo\" /></p>\n\n<p>Not sure which image you want to use yet? That's ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:</p>\n\n<h3 id=\"quoting\">Quoting</h3>\n\n<p>Sometimes a link isn't enough, you want to quote someone on what they've said. It was probably very wisdomous. Is wisdomous a word? Find out in a future release when we introduce spellcheck! For now - it's definitely a word.</p>\n\n<blockquote>\n  <p>Wisdomous - it's definitely a word.</p>\n</blockquote>\n\n<h3 id=\"workingwithcode\">Working with Code</h3>\n\n<p>Got a streak of geek? We've got you covered there, too. You can write inline <code>&lt;code&gt;</code> blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.</p>\n\n<pre><code>.awesome-thing {\n    display: block;\n    width: 100%;\n}\n</code></pre>\n\n<h3 id=\"readyforabreak\">Ready for a Break?</h3>\n\n<p>Throw 3 or more dashes down on any new line and you've got yourself a fancy new divider. Aw yeah.</p>\n\n<hr />\n\n<h3 id=\"advancedusage\">Advanced Usage</h3>\n\n<p>There's one fantastic secret about Markdown. If you want, you can  write plain old HTML and it'll still work! Very flexible.</p>\n\n<p><input type=\"text\" placeholder=\"I'm an input field!\" /></p>\n\n<p>That should be enough to get you started. Have fun - and let us know what you think :)</p>","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1411456685357,"created_by":1,"updated_at":1421393250127,"updated_by":1,"published_at":1411456685373,"published_by":1},{"id":2,"uuid":"55ce9749-48e3-45c3-9eef-832904c34f1c","title":"About Brian Christner","slug":"aboutme","markdown":"![](/content/images/2014/11/brianchristner.jpg)\n\n##Brian Christner\nI would describe myself as a technologist, motorcycle junkie, traveler, and all around outdoorsmen are just some of the terms I would use to describe myself. I also consider myself as a motorcycle racer trapped in a computer engineers body.\n##Career\nI'm a devoted technologist to everything Cloud, actually a Cloud junkie. I'm either researching new features, writing code for Docker or Cloud Foundry, or comparing new features with out competitors.  You can catch me attending <a href=\"http://www.meetup.com/openstack-ch/\" target=\"_blank\">OpenStack meetups</a>, Docker, or just about anything with Cloud in the title.\n\nI currently work for <a href=\"http://www.swisscom.ch\" target=\"_blank\">Swisscom</a> as a Cloud Designer. Our products include Cloud Products (shocking I know) such as <a href=\"http://www.swisscom.ch/en/business/sme/it-hosting/dynamic-computing-services.html\" target=\"_blank\">Dynamic Computing</a> where all data is stored in Switzerland and out of legal reach from the NSA. I design Cloud configurations based on the Enterprise customers architecture and requirements for PaaS and IaaS solutions.\n##My Other Sites\n<a title=\"2WheelTuesday.com\" href=\"http://www.2wheeltuesday.com\">www.2wheeltuesday.com</a> is a motorcycle site I started in 2008. I started the site originally as a project site following the progress of a project bike I was building. Well as things started rolling the site started gaining a lot of readers and I expanded the scope of the site to cover motorcycle news and racing.  During the sites prime I was getting over 100,000 views a month.  Now I post an interesting article or pictures of my rides as I just don't have time to maintain the site as like in it's previous glory. But more than anything I learned a ton about the blogosphere, made a ton of connections, and was burned a few times. So in the the end it was a great learning experience.  This is also where I perform a lot of Cloud and Performance testing as it is a big website with a lot of content.","html":"<p><img src=\"/content/images/2014/11/brianchristner.jpg\" alt=\"\" /></p>\n\n<h2 id=\"brianchristner\">Brian Christner</h2>\n\n<p>I would describe myself as a technologist, motorcycle junkie, traveler, and all around outdoorsmen are just some of the terms I would use to describe myself. I also consider myself as a motorcycle racer trapped in a computer engineers body.  </p>\n\n<h2 id=\"career\">Career</h2>\n\n<p>I'm a devoted technologist to everything Cloud, actually a Cloud junkie. I'm either researching new features, writing code for Docker or Cloud Foundry, or comparing new features with out competitors.  You can catch me attending <a href=\"http://www.meetup.com/openstack-ch/\" target=\"_blank\">OpenStack meetups</a>, Docker, or just about anything with Cloud in the title.</p>\n\n<p>I currently work for <a href=\"http://www.swisscom.ch\" target=\"_blank\">Swisscom</a> as a Cloud Designer. Our products include Cloud Products (shocking I know) such as <a href=\"http://www.swisscom.ch/en/business/sme/it-hosting/dynamic-computing-services.html\" target=\"_blank\">Dynamic Computing</a> where all data is stored in Switzerland and out of legal reach from the NSA. I design Cloud configurations based on the Enterprise customers architecture and requirements for PaaS and IaaS solutions.  </p>\n\n<h2 id=\"myothersites\">My Other Sites</h2>\n\n<p><a title=\"2WheelTuesday.com\" href=\"http://www.2wheeltuesday.com\">www.2wheeltuesday.com</a> is a motorcycle site I started in 2008. I started the site originally as a project site following the progress of a project bike I was building. Well as things started rolling the site started gaining a lot of readers and I expanded the scope of the site to cover motorcycle news and racing.  During the sites prime I was getting over 100,000 views a month.  Now I post an interesting article or pictures of my rides as I just don't have time to maintain the site as like in it's previous glory. But more than anything I learned a ton about the blogosphere, made a ton of connections, and was burned a few times. So in the the end it was a great learning experience.  This is also where I perform a lot of Cloud and Performance testing as it is a big website with a lot of content.</p>","image":null,"featured":0,"page":1,"status":"published","language":"en_US","meta_title":"About Brian Christner","meta_description":"A self described motorcycle racer trapped in a computer engineers body. Cloud, Open Source, and Traveling are topics I'm always discussing.","author_id":1,"created_at":1383251702000,"created_by":1,"updated_at":1421096296235,"updated_by":1,"published_at":1383251702000,"published_by":1},{"id":3,"uuid":"727a5b7a-52a2-4af0-8de8-bee476bef4f3","title":"My life journey with Mountain Biking","slug":"mountain-biking-coming-age","markdown":"I started off with BMX bikes and tried to perform every jump or trick I could think of.  At the ripe ol age of 10 I received my first Mountain Bike and never looked back. Growing up in Arizona I used to mountain bike in the desert surrounding our house with rocky hills, to river washes, and going up north to the high country on the weekends to ride in the forest. I loved the ability to ride where you wanted and be able to go off the beaten path at an early age. I would ride my mountain bike everywhere from school to racing my friends through canals or desert paths.\n\n1996 I joined the Air Force and my first duty station was Nellis Air Force Base in Las Vegas. Not exactly what I was aiming for since I grew up in the desertI was hoping to move somewhere with trees and snow. Instead I moved 5 hours from my house to Las Vegas.\n\n<img class=\"size-medium wp-image-211\" src=\"/content/images/2013/11/red-rock-3-300x214.jpg\" width=\"300\" height=\"214\" />\n*Red Rock Canyon, Las Vegas*\n\nWhile stationed at Nellis I met up with a group of guys that also enjoyed Mountain Biking. On the weekends we would drive out to <a href=\"http://www.redrockcanyonlv.org/\" target=\"_blank\">Red Rock Canyon</a> where we would ride until we couldn't go anymore. We would ride upwards of 30 to 50 miles depending how lost we became (This was before GPS's).\n\nI then moved from Las Vegas to Amsterdam, The Netherlands. The most bicycle friendly country in the world but more for city bikes. When you stand on top of your car anywhere in The Netherlands in any direction there was not a hill or mountain in sight. This was the longest period of my life without a Mountain Bike.  I gained a ton of weight and my lifestyle was just plain horrible. The weather was horrible and my motivation was very low.  So I was well over  200 Pounds (90 Kilos). Towards the end of my stay in the Netherlands I finally saw the light at the end of the tunnel that I was leaving.  So I started running again, going to the gym, and looking forward to my next destination SWITZERLAND.\n\n2010 my wife and I finally decided to move to Switzerland. One of my first purchases was a Mountain Bike a <a href=\"http://www.rockmachine.us/\" target=\"_blank\">Rock Machine</a>. My wife and I both bought a bike. My wife bought an all rounder as she just enjoys gentle trail rides.  I went for the Full Suspension high performance bike. Having ridden motorcycles also my entire life this was my first mountain bike with disc brakes. After using them for about 2 minutes I fell in love with them. The feel is so much better than pulley brakes and the stopping power is amazing. Just like on a motorcycle you can jam on the brakes and control every bit of the power. My next question is when are floating discs, seamless transmission, and ABS coming to Mountain Bikes? I am just saying since mountain bikes are slowly evolving into motorcycle components I see this as the next step.\n\n<ahref=\"/content/images/2013/11/jura_mountain_biking.jpg\"><img class=\"size-medium wp-image-212\" src=\"/content/images/2013/11/jura_mountain_biking-300x300.jpg\" width=\"300\" height=\"300\" /></a>\n*Jura, Switzerland mountain biking*\n\nAfter riding from the first moment I bought the bike until the snow started falling that season I continued riding as much as possible. Before I knew it people were starting to comment on my weight loss. Everyone was asking if I was on a diet. Well sort of as my wife and I decided to cut all processed foods from our diet and only eat fresh food.  This along with riding my mountain bike as much as possible I dropped 30 pounds (14 KG) since moving to Switzerland and not to toot my own horn my body looks just as good. My legs look like rocks and my stomach is almost completely flat.\n\nWith mountain bike trails right out my back door and amazing trails everywhere I ride. Why would I go to the gym while the weather is good?  I will bring everyone along as I explore the different trails in Switzerland and discover more and more beautiful parts of Switzerland all the while staying in shape.\n\nMy next projects include finding more trails, preparing for another race, and buying a new mountain bike for the 2014 season.","html":"<p>I started off with BMX bikes and tried to perform every jump or trick I could think of.  At the ripe ol age of 10 I received my first Mountain Bike and never looked back. Growing up in Arizona I used to mountain bike in the desert surrounding our house with rocky hills, to river washes, and going up north to the high country on the weekends to ride in the forest. I loved the ability to ride where you wanted and be able to go off the beaten path at an early age. I would ride my mountain bike everywhere from school to racing my friends through canals or desert paths.</p>\n\n<p>1996 I joined the Air Force and my first duty station was Nellis Air Force Base in Las Vegas. Not exactly what I was aiming for since I grew up in the desertI was hoping to move somewhere with trees and snow. Instead I moved 5 hours from my house to Las Vegas.</p>\n\n<p><img class=\"size-medium wp-image-211\" src=\"/content/images/2013/11/red-rock-3-300x214.jpg\" width=\"300\" height=\"214\" /> <br />\n<em>Red Rock Canyon, Las Vegas</em></p>\n\n<p>While stationed at Nellis I met up with a group of guys that also enjoyed Mountain Biking. On the weekends we would drive out to <a href=\"http://www.redrockcanyonlv.org/\" target=\"_blank\">Red Rock Canyon</a> where we would ride until we couldn't go anymore. We would ride upwards of 30 to 50 miles depending how lost we became (This was before GPS's).</p>\n\n<p>I then moved from Las Vegas to Amsterdam, The Netherlands. The most bicycle friendly country in the world but more for city bikes. When you stand on top of your car anywhere in The Netherlands in any direction there was not a hill or mountain in sight. This was the longest period of my life without a Mountain Bike.  I gained a ton of weight and my lifestyle was just plain horrible. The weather was horrible and my motivation was very low.  So I was well over  200 Pounds (90 Kilos). Towards the end of my stay in the Netherlands I finally saw the light at the end of the tunnel that I was leaving.  So I started running again, going to the gym, and looking forward to my next destination SWITZERLAND.</p>\n\n<p>2010 my wife and I finally decided to move to Switzerland. One of my first purchases was a Mountain Bike a <a href=\"http://www.rockmachine.us/\" target=\"_blank\">Rock Machine</a>. My wife and I both bought a bike. My wife bought an all rounder as she just enjoys gentle trail rides.  I went for the Full Suspension high performance bike. Having ridden motorcycles also my entire life this was my first mountain bike with disc brakes. After using them for about 2 minutes I fell in love with them. The feel is so much better than pulley brakes and the stopping power is amazing. Just like on a motorcycle you can jam on the brakes and control every bit of the power. My next question is when are floating discs, seamless transmission, and ABS coming to Mountain Bikes? I am just saying since mountain bikes are slowly evolving into motorcycle components I see this as the next step.</p>\n\n<p><ahref=\"/content/images/2013/11/jura_mountain_biking.jpg\"><img class=\"size-medium wp-image-212\" src=\"/content/images/2013/11/jura_mountain_biking-300x300.jpg\" width=\"300\" height=\"300\" /></a> <br />\n<em>Jura, Switzerland mountain biking</em></p>\n\n<p>After riding from the first moment I bought the bike until the snow started falling that season I continued riding as much as possible. Before I knew it people were starting to comment on my weight loss. Everyone was asking if I was on a diet. Well sort of as my wife and I decided to cut all processed foods from our diet and only eat fresh food.  This along with riding my mountain bike as much as possible I dropped 30 pounds (14 KG) since moving to Switzerland and not to toot my own horn my body looks just as good. My legs look like rocks and my stomach is almost completely flat.</p>\n\n<p>With mountain bike trails right out my back door and amazing trails everywhere I ride. Why would I go to the gym while the weather is good?  I will bring everyone along as I explore the different trails in Switzerland and discover more and more beautiful parts of Switzerland all the while staying in shape.</p>\n\n<p>My next projects include finding more trails, preparing for another race, and buying a new mountain bike for the 2014 season.</p>","image":"/content/images/2013/11/rock_machine_mtb-742x556.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1384081589000,"created_by":1,"updated_at":1430127471088,"updated_by":1,"published_at":1384081589000,"published_by":1},{"id":4,"uuid":"18eb689b-a044-418d-a2d1-eb6d83cf86ac","title":"My Mom's World Famous Chocolate Chip Cookie Recipe","slug":"chocolate-chip-cookies-recipe","markdown":"So it has come to be somewhat of a tradition that my mom has started.  It started off as a kid I would love Chocolate Chip Cookies from Double Tree Hotel in Phoenix next to her work. Well my Mom found this Chocolate Chip Cookie Recipe which she has been using since I was just a young lad.\n\nWhen I went away to the Military at 18 she would send me care packages with the World Famous Chocolate Chip cookies. I kept requesting these care packages every time she visited or sent a package.  When I started working in Europe I would start bringing them into the office to share with my co-workers who all fell in love with them.  To this day I think my old co-workers miss my Moms Cookies more than me :)  \n\n##Mom's World Famous Chocolate Chip Cookie Recipe\n\n<pre style=\"padding-left: 30px;\">INGREDIENTS:\n 1/2 cup quick cooking oats\n 2 1/4 cups all-purpose flour\n 1 1/2 teaspoons baking soda\n 1 teaspoon salt\n 1/4 teaspoon cinnamon\n 1cup unsalted butter\n 3/4 cup brown sugar\n 3/4 cup white granulated sugar\n 11/2 teaspoons vanilla extract\n 1/2 teaspoon fresh lemon juice\n 2 eggs\n 3 cups semisweet premium chocolate chips\n (Ghirardelli or Guittard or equivalent preferred)\n 1 1/2 cups chopped walnuts</pre>\n<pre style=\"padding-left: 30px;\">DIRECTIONS:\n Preheat oven to 350 degrees\n Combine the oats, flour, soda,salt,and cinnamon.\n In a separate bowl,cream together\n The butters, both sugars, vanilla and lemon.\n Add eggs and mix until smooth.\n Stir in dry ingredients.  Mix in chocolate\n Chips and nuts.  Spoon rounded balls\n (about 1/4 cup each) onto a parchment\n Or foil-lined cookie sheet about two\n Inches apart.  Bake 10-12 minutes or until\n Light golden brown on outside edges but still soft in the middle.  Makes 40 large cookies.</pre>\n<pre style=\"padding-left: 30px;\">Chill the dough for easier handling.\n The cookies freeze well.</pre>","html":"<p>So it has come to be somewhat of a tradition that my mom has started.  It started off as a kid I would love Chocolate Chip Cookies from Double Tree Hotel in Phoenix next to her work. Well my Mom found this Chocolate Chip Cookie Recipe which she has been using since I was just a young lad.</p>\n\n<p>When I went away to the Military at 18 she would send me care packages with the World Famous Chocolate Chip cookies. I kept requesting these care packages every time she visited or sent a package.  When I started working in Europe I would start bringing them into the office to share with my co-workers who all fell in love with them.  To this day I think my old co-workers miss my Moms Cookies more than me :)  </p>\n\n<h2 id=\"momsworldfamouschocolatechipcookierecipe\">Mom's World Famous Chocolate Chip Cookie Recipe</h2>\n\n<pre style=\"padding-left: 30px;\">INGREDIENTS:  \n 1/2 cup quick cooking oats\n 2 1/4 cups all-purpose flour\n 1 1/2 teaspoons baking soda\n 1 teaspoon salt\n 1/4 teaspoon cinnamon\n 1cup unsalted butter\n 3/4 cup brown sugar\n 3/4 cup white granulated sugar\n 11/2 teaspoons vanilla extract\n 1/2 teaspoon fresh lemon juice\n 2 eggs\n 3 cups semisweet premium chocolate chips\n (Ghirardelli or Guittard or equivalent preferred)\n 1 1/2 cups chopped walnuts</pre>\n\n<pre style=\"padding-left: 30px;\">DIRECTIONS:  \n Preheat oven to 350 degrees\n Combine the oats, flour, soda,salt,and cinnamon.\n In a separate bowl,cream together\n The butters, both sugars, vanilla and lemon.\n Add eggs and mix until smooth.\n Stir in dry ingredients.  Mix in chocolate\n Chips and nuts.  Spoon rounded balls\n (about 1/4 cup each) onto a parchment\n Or foil-lined cookie sheet about two\n Inches apart.  Bake 10-12 minutes or until\n Light golden brown on outside edges but still soft in the middle.  Makes 40 large cookies.</pre>\n\n<pre style=\"padding-left: 30px;\">Chill the dough for easier handling.  \n The cookies freeze well.</pre>","image":"/content/images/2013/11/ChocolateChipCookie-742x556.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1384714488000,"created_by":1,"updated_at":1430127503214,"updated_by":1,"published_at":1384714488000,"published_by":1},{"id":5,"uuid":"1c485f4c-669b-4ba8-b6e2-cd483a5f9e13","title":"Samsung I'm tired of waiting...","slug":"im-tired-waiting-samsung","markdown":"Dear Samsung,\n\nYou first caught my eye with your technical prowess. I was a long time Apple fan boy until I first laid eyes on my first Android phone the HTC which was an OK phone but I really enjoyed Android. Android really wet my appetite for more power and more features in comparison to iPhones at the time.\n\nSo on to my next phone and my first encounter with Samsung I chose the Samsung Google Nexus. I loved this phone, period(actually I still do). Like all Nexus devices you get Android updates within days. This was so great to continually get new features and a faster OS every few months. The Android interface is not cluttered with non-sense bloatware and the performance was OK. The downside was the performance was just OK and the screen is small in comparison to other Samsung models.\n\nSo I started my new job in April and had the option to choose any phone as my company phone (unfortunately not another Nexus). With so many choices and a great experience with the Samsung Google Nexus. I selected the Samsung S3 4G. Fresh on the market at the time, great reviews, big screen, good camera, 4G, yada yada yada....\n\nSo what am I waiting for you ask?  I am waiting for a bloody Android update for gods sake!  When I received my S3 it was still running Android 4.1.2 which was released July 9, 2012. I received my phone April 2013 and till this date I have yet to receive an Android update. Since the time I have owned this device Google has released two more <ahref=\"http://en.wikipedia.org/wiki/Android_version_history\" target=\"_blank\">Android versions 4.3 and 4.4</a>. I am trolling all the Android update sites impatiently reading all the articles where they loosely predict (never correctly I might add) when the Samsung S3 Android release will be available. The answer seems always to be next month.\n\nThis is a reoccurring problem with another Samsung device I own as well the Tab 2 we purchased in 2012. Since the day we bought this device we have yet to receive an Android or Samsung update. Over 2 years and no updates!!\n<h2>Whats wrong with Samsung?</h2>\nSamsung has created so many different models of phones, tablets, and electronics period the sheer number of devices per year is mind blowing. Well try to release 100 unique devices a year and still try to maintain updates on these devices. Sounds like a nearly impossible mission.\n\nSamsung is gravitating towards caring less and less about the software than runs on top of their hardware and only focus on current models.\n\nGoogle has gotten so frustrated with the Android update situation that it has taken matters in its own hands by allowing updates to the new Android 4.4 OS in layers which addresses the <a href=\"http://news.cnet.com/8301-1023_3-57584973-93/google-engineers-were-trying-to-fix-android-fragmentation/\" target=\"_blank\">Android Fragmentation problem</a>. By updating Android in layers this allows Google to push out updates without having to wait on companies like Samsung.\n<h2>Where am I going after Samsung?</h2>\nJust like how PC's operate in conjunction with Operating Systems. Regardless of the hardware that is running underneath, the OS continues to move forward until the hardware cannot cope. Once my contract is up I am moving back to a manufacture like Apple or a Google Nexus device that can continue supporting their device and doesn't leave me out in the dark.","html":"<p>Dear Samsung,</p>\n\n<p>You first caught my eye with your technical prowess. I was a long time Apple fan boy until I first laid eyes on my first Android phone the HTC which was an OK phone but I really enjoyed Android. Android really wet my appetite for more power and more features in comparison to iPhones at the time.</p>\n\n<p>So on to my next phone and my first encounter with Samsung I chose the Samsung Google Nexus. I loved this phone, period(actually I still do). Like all Nexus devices you get Android updates within days. This was so great to continually get new features and a faster OS every few months. The Android interface is not cluttered with non-sense bloatware and the performance was OK. The downside was the performance was just OK and the screen is small in comparison to other Samsung models.</p>\n\n<p>So I started my new job in April and had the option to choose any phone as my company phone (unfortunately not another Nexus). With so many choices and a great experience with the Samsung Google Nexus. I selected the Samsung S3 4G. Fresh on the market at the time, great reviews, big screen, good camera, 4G, yada yada yada....</p>\n\n<p>So what am I waiting for you ask?  I am waiting for a bloody Android update for gods sake!  When I received my S3 it was still running Android 4.1.2 which was released July 9, 2012. I received my phone April 2013 and till this date I have yet to receive an Android update. Since the time I have owned this device Google has released two more <ahref=\"http://en.wikipedia.org/wiki/Android_version_history\" target=\"_blank\">Android versions 4.3 and 4.4</a>. I am trolling all the Android update sites impatiently reading all the articles where they loosely predict (never correctly I might add) when the Samsung S3 Android release will be available. The answer seems always to be next month.</p>\n\n<p>This is a reoccurring problem with another Samsung device I own as well the Tab 2 we purchased in 2012. Since the day we bought this device we have yet to receive an Android or Samsung update. Over 2 years and no updates!!  </p>\n\n<h2>Whats wrong with Samsung?</h2>  \n\n<p>Samsung has created so many different models of phones, tablets, and electronics period the sheer number of devices per year is mind blowing. Well try to release 100 unique devices a year and still try to maintain updates on these devices. Sounds like a nearly impossible mission.</p>\n\n<p>Samsung is gravitating towards caring less and less about the software than runs on top of their hardware and only focus on current models.</p>\n\n<p>Google has gotten so frustrated with the Android update situation that it has taken matters in its own hands by allowing updates to the new Android 4.4 OS in layers which addresses the <a href=\"http://news.cnet.com/8301-1023_3-57584973-93/google-engineers-were-trying-to-fix-android-fragmentation/\" target=\"_blank\">Android Fragmentation problem</a>. By updating Android in layers this allows Google to push out updates without having to wait on companies like Samsung.  </p>\n\n<h2>Where am I going after Samsung?</h2>  \n\n<p>Just like how PC's operate in conjunction with Operating Systems. Regardless of the hardware that is running underneath, the OS continues to move forward until the hardware cannot cope. Once my contract is up I am moving back to a manufacture like Apple or a Google Nexus device that can continue supporting their device and doesn't leave me out in the dark.</p>","image":"/content/images/2013/12/skeleton_waiting.jpeg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1386188588000,"created_by":1,"updated_at":1430127532130,"updated_by":1,"published_at":1386188588000,"published_by":1},{"id":6,"uuid":"e7fbc4c4-470b-49a7-8c72-cf62322a2df1","title":"Fine tuning your Fresh Nagios Installation","slug":"fine-tuning-fresh-nagios-installation","markdown":"<a href=\"http://awaseroot.files.wordpress.com/2012/11/2012-11-14_090259.png\"><img alt=\"\" src=\"file:///C:\\Users\\tzhbrch9\\AppData\\Local\\Temp\\msohtmlclip1\\02\\clip_image001.png\" width=\"630\" height=\"358\" /></a>Now that you installed Nagios you are not done.  To get rid of all those pesky errors that pop up once installing Nagios you need to be patient and work through them one by one.\n<div>\n<h2>Fixing the error: check_all_disks  .gvfs is not accessible Permission denied</h2>\n&nbsp;\n\nLet's address first the most annoying problem of the /root/.gvfs filesystem is \"not accessible:Permission denied\"  You can either unmount the filesystem as a temporary workaround but once you reboot or mount the filesystem again the problem returns.  Secondly, you can change permissions of the .gvfs filesystem or my personal favorite is to just ignore the filesystem since I don't use it and we are already monitoring the /root filesystem anyway.\n\nNavigate to /etc/nagios-plugins/config and open the disk.cfg file with your favorite editor.\n\nChange the command_line to:\n<pre> /usr/lib/nagios/plugins/check_disk -w $ARG1$ -c $ARG2$ -e -R $ARG3$ -A -i .gvfs</pre>\nThe new flags:\n<pre> -A, --all\n     Explicitly select all paths. This is equivalent to -R '.*'</pre>\n<pre> -i, --ignore-ereg-path=PATH, --ignore-ereg-partition=PARTITION\n     Regular expression to ignore selected path or partition (may be repeated)</pre>\n&nbsp;\n\nIn the /etc/nagios3/conf.d directory edit the localhost_nagios2.cfg  Find the service check_all_disks and change the check_command to:\n<pre>check_disk!20%!10%!/root.gvfs</pre>\n&nbsp;\n\nOnce you complete the files make sure to check the config before continuing\n<pre>&gt; nagios3 -v /etc/nagios3/nagios.cfg</pre>\nOnce you pass the pre-flight check restart Nagios\n<pre>&gt; sudo service nagios3 restart</pre>\n&nbsp;\n<h2>Fixing the Unknow missing -l parameter and no service/process defined errors</h2>\n&nbsp;\n\nOk something is clearly wrong if you get these kind of errors for your windows host…\n\nUNKNOWN – missing -l parameters\n\nUNKNOWN – no service/process specified\n\nCRITICAL – Socet timeout after 10 seconds\n\n&nbsp;\n\nThis indicates that there’s something wrong in my nagios configuration files.\n\nCheck the nt plugin:\n<pre>cat /etc/nagios-plugins/nt.cfg</pre>\n<a href=\"http://awaseroot.files.wordpress.com/2012/11/2012-11-14_090140.png\"><img alt=\"\" src=\"file:///C:\\Users\\tzhbrch9\\AppData\\Local\\Temp\\msohtmlclip1\\02\\clip_image001.png\" width=\"630\" height=\"358\" /></a>\n\nLooks ok but it really isn’t. There’s problems in the command. Let’s make some fixes:\n\n<a href=\"http://awaseroot.files.wordpress.com/2012/11/2012-11-14_090259.png\"><img alt=\"\" src=\"file:///C:\\Users\\tzhbrch9\\AppData\\Local\\Temp\\msohtmlclip1\\02\\clip_image002.png\" width=\"630\" height=\"358\" /></a>\n\nText version for your copypaste needs:\n<pre>define command {\n         command_name    check_nt\n         command_line    /usr/lib/nagios/plugins/check_nt -H $HOSTADDRESS$ -v $ARG1$ $ARG2$\n }</pre>\nCheck your config again and restart the service:\n<pre>sudo nagios3 -v /etc/nagios3/nagios.cfg</pre>\n&nbsp;\n\nAfter the pre-flight checks good restart the Nagios service:\n<pre>sudo service nagios3 restart</pre>\n&nbsp;\n\nDepending how impatient you are for the results you can either wait several minutes for the service to recheck each process or you can go inside each service and under the Service Commands click Re-schedule the next check for this service.\n\nAfter completing hit the Services button on the right side of the screen a few times and you should be golden.\n\nThanks to <a href=\"http://awaseroot.wordpress.com/2012/11/23/monitoring-windows-with-nagios/\" target=\"_blank\">awaseroot</a> for the great article which was the best resource to fix this issue.\n<h2>External Commands not working on your Nagios system?</h2>\nHave no fear.  Follow the very clear instructions here - <a href=\"http://askubuntu.com/questions/145518/how-do-i-install-nagios\">http://askubuntu.com/questions/145518/how-do-i-install-nagios</a>  If it still doesn't work be sure to check your permissions of both the /var/lib/nagios3 directory and the /var/lib/nagios3/rw directory.  If in doubt change the permissions to 775 on both directories just to see if it works and set it back to the requested permissions in the instructions once you get it working.\n\nHappy Nagios Monitoring!\n\n</div>\n&nbsp;","html":"<p><a href=\"http://awaseroot.files.wordpress.com/2012/11/2012-11-14_090259.png\"><img alt=\"\" src=\"file:///C:\\Users\\tzhbrch9\\AppData\\Local\\Temp\\msohtmlclip1\\02\\clip_image001.png\" width=\"630\" height=\"358\" /></a>Now that you installed Nagios you are not done.  To get rid of all those pesky errors that pop up once installing Nagios you need to be patient and work through them one by one.  </p>\n\n<div>  \n<h2>Fixing the error: check_all_disks  .gvfs is not accessible Permission denied</h2>  \n&nbsp;\n\nLet's address first the most annoying problem of the /root/.gvfs filesystem is \"not accessible:Permission denied\"  You can either unmount the filesystem as a temporary workaround but once you reboot or mount the filesystem again the problem returns.  Secondly, you can change permissions of the .gvfs filesystem or my personal favorite is to just ignore the filesystem since I don't use it and we are already monitoring the /root filesystem anyway.\n\nNavigate to /etc/nagios-plugins/config and open the disk.cfg file with your favorite editor.\n\nChange the command_line to:  \n\n\n<pre> /usr/lib/nagios/plugins/check_disk -w $ARG1$ -c $ARG2$ -e -R $ARG3$ -A -i .gvfs</pre>\nThe new flags:  \n\n\n<pre> -A, --all\n     Explicitly select all paths. This is equivalent to -R '.*'</pre>\n\n\n<pre> -i, --ignore-ereg-path=PATH, --ignore-ereg-partition=PARTITION\n     Regular expression to ignore selected path or partition (may be repeated)</pre>\n&nbsp;\n\nIn the /etc/nagios3/conf.d directory edit the localhost_nagios2.cfg  Find the service check_all_disks and change the check_command to:  \n\n\n<pre>check_disk!20%!10%!/root.gvfs</pre>\n&nbsp;\n\nOnce you complete the files make sure to check the config before continuing  \n\n\n<pre>&gt; nagios3 -v /etc/nagios3/nagios.cfg</pre>\nOnce you pass the pre-flight check restart Nagios  \n\n\n<pre>&gt; sudo service nagios3 restart</pre>\n&nbsp;\n<h2>Fixing the Unknow missing -l parameter and no service/process defined errors</h2>  \n&nbsp;\n\nOk something is clearly wrong if you get these kind of errors for your windows host…\n\nUNKNOWN – missing -l parameters\n\nUNKNOWN – no service/process specified\n\nCRITICAL – Socet timeout after 10 seconds\n\n&nbsp;\n\nThis indicates that there’s something wrong in my nagios configuration files.\n\nCheck the nt plugin:  \n\n\n<pre>cat /etc/nagios-plugins/nt.cfg</pre>\n<a href=\"http://awaseroot.files.wordpress.com/2012/11/2012-11-14_090140.png\"><img alt=\"\" src=\"file:///C:\\Users\\tzhbrch9\\AppData\\Local\\Temp\\msohtmlclip1\\02\\clip_image001.png\" width=\"630\" height=\"358\" /></a>\n\nLooks ok but it really isn’t. There’s problems in the command. Let’s make some fixes:\n\n<a href=\"http://awaseroot.files.wordpress.com/2012/11/2012-11-14_090259.png\"><img alt=\"\" src=\"file:///C:\\Users\\tzhbrch9\\AppData\\Local\\Temp\\msohtmlclip1\\02\\clip_image002.png\" width=\"630\" height=\"358\" /></a>\n\nText version for your copypaste needs:  \n\n\n<pre>define command {\n         command_name    check_nt\n         command_line    /usr/lib/nagios/plugins/check_nt -H $HOSTADDRESS$ -v $ARG1$ $ARG2$\n }</pre>\nCheck your config again and restart the service:  \n\n\n<pre>sudo nagios3 -v /etc/nagios3/nagios.cfg</pre>\n&nbsp;\n\nAfter the pre-flight checks good restart the Nagios service:  \n\n\n<pre>sudo service nagios3 restart</pre>\n&nbsp;\n\nDepending how impatient you are for the results you can either wait several minutes for the service to recheck each process or you can go inside each service and under the Service Commands click Re-schedule the next check for this service.\n\nAfter completing hit the Services button on the right side of the screen a few times and you should be golden.\n\nThanks to <a href=\"http://awaseroot.wordpress.com/2012/11/23/monitoring-windows-with-nagios/\" target=\"_blank\">awaseroot</a> for the great article which was the best resource to fix this issue.  \n<h2>External Commands not working on your Nagios system?</h2>  \nHave no fear.  Follow the very clear instructions here - <a href=\"http://askubuntu.com/questions/145518/how-do-i-install-nagios\">http://askubuntu.com/questions/145518/how-do-i-install-nagios</a>  If it still doesn't work be sure to check your permissions of both the /var/lib/nagios3 directory and the /var/lib/nagios3/rw directory.  If in doubt change the permissions to 775 on both directories just to see if it works and set it back to the requested permissions in the instructions once you get it working.\n\nHappy Nagios Monitoring!\n\n</div>  \n\n<p>&nbsp;</p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1389191873000,"created_by":1,"updated_at":1421394333298,"updated_by":1,"published_at":1389191873000,"published_by":1},{"id":7,"uuid":"05791eee-7fa2-46da-8fb1-0c08eeabaff0","title":"Secure your Wordpress site before it is too late","slug":"secure-wordpress-site","markdown":"Well it came as a shock to me to get a hacking notification from my current hosting provider <a href=\"http://www.inmotionhosting.com/\" target=\"_blank\">InMotion Hosting </a>when I tried to login to my other site <a href=\"http://2wheeltuesday.com\" target=\"_blank\">2WheelTuesday.com</a>.  hocked on one hand as this is not a real active site and I only update this site every now and then.  Why in the world would someone want to hack this site?\n\nWell whatever the reason I quickly realised how vulnerable my site is and someone out in cyberspace was trying to Brute Force my Admin account. Lazy me I used the default Admin user which is a big security no no and didn't have a way to monitor or control my logins.\n\nSo what can you do to quickly harden your Wordpress site?<!--more-->\n<h2>How to Rename the Wordpress Admin User</h2>\n<ol>\n\t<li>If this is the case then you should create a new User and assign the Editor Role</li>\n\t<li>Create a new Admin account user and assign the Admin Role</li>\n\t<li>Login as the newly created Admin User and Delete the original Admin user.  Don't worry this won't delete your posts because Wordpress is smart enough to ask you if you want to transfer your posts to another user.  Choose the user you created in step 1.</li>\n</ol>\n<h2>Securing Wordpress Login</h2>\nI highly recommend to use the Wordpress Plugin <a href=\"http://wordpress.org/plugins/login-security-solution/\" target=\"_blank\">Login Security Solution</a>. Not only is this plugin absolutely necessary to slow down Brute Force attacks and make the attackers go after other easier more vulnerable sites. The plugin allows you to Track IP addresses, enforce password complexity, and most importantly sends you an email when someone is trying to brute force a Wordpress account.\n\nAnother nice feature with Login Security Solution Wordpress Plugin is if a login failure uses data matching a past failure, the plugin slows down response times. The more failures, the longer the delay. This limits attackers ability to effectively probe your site, so they'll give up and go find an easier target. Another feature that lets you sleep better night is if an account seems breached, the \"user\" is immediately logged out and forced to use WordPress'password reset utility. This prevents any damage from being done and verifies the user's identity. But if the user is coming in from an IP address they have used in the past, an email is sent to the user making sure it was them logging in. All without intervention by an administrator.\n\nOne day after installing the plugin I received the below email giving me an overview of what was currently occurring with my site. This Plugin is priceless considering it just thwarted a bad guy from trying to get in.\n\nExample Login Security Solution Threat Email:\n<pre>Your website, 2WheelTuesday, is undergoing a brute force attack.\n\nThere have been at least 50 failed attempts to log in during the past 120 minutes that used one or more of the following components:\n\nComponent                    Count     Value from Current Attempt\n------------------------     -----     ------------------------------<wbr />--\nNetwork IP                      47     ###.###.###.###\nUsername                        50     admin\nPassword MD5                     1     12345678901010101010\n\nThe Login Security Solution plugin (0.42.0) for WordPress is repelling the attack by making their login failures take a very long time.  This attacker will also be denied access in the event they stumble upon valid credentials.\n\nFurther notifications about this attacker will only be sent if the attack stops for at least 120 minutes and then resumes.</pre>","html":"<p>Well it came as a shock to me to get a hacking notification from my current hosting provider <a href=\"http://www.inmotionhosting.com/\" target=\"_blank\">InMotion Hosting </a>when I tried to login to my other site <a href=\"http://2wheeltuesday.com\" target=\"_blank\">2WheelTuesday.com</a>.  hocked on one hand as this is not a real active site and I only update this site every now and then.  Why in the world would someone want to hack this site?</p>\n\n<p>Well whatever the reason I quickly realised how vulnerable my site is and someone out in cyberspace was trying to Brute Force my Admin account. Lazy me I used the default Admin user which is a big security no no and didn't have a way to monitor or control my logins.</p>\n\n<p>So what can you do to quickly harden your Wordpress site?<!--more-->  </p>\n\n<h2>How to Rename the Wordpress Admin User</h2>  \n\n<ol>  \n    <li>If this is the case then you should create a new User and assign the Editor Role</li>\n    <li>Create a new Admin account user and assign the Admin Role</li>\n    <li>Login as the newly created Admin User and Delete the original Admin user.  Don't worry this won't delete your posts because Wordpress is smart enough to ask you if you want to transfer your posts to another user.  Choose the user you created in step 1.</li>\n</ol>  \n\n<h2>Securing Wordpress Login</h2>  \n\n<p>I highly recommend to use the Wordpress Plugin <a href=\"http://wordpress.org/plugins/login-security-solution/\" target=\"_blank\">Login Security Solution</a>. Not only is this plugin absolutely necessary to slow down Brute Force attacks and make the attackers go after other easier more vulnerable sites. The plugin allows you to Track IP addresses, enforce password complexity, and most importantly sends you an email when someone is trying to brute force a Wordpress account.</p>\n\n<p>Another nice feature with Login Security Solution Wordpress Plugin is if a login failure uses data matching a past failure, the plugin slows down response times. The more failures, the longer the delay. This limits attackers ability to effectively probe your site, so they'll give up and go find an easier target. Another feature that lets you sleep better night is if an account seems breached, the \"user\" is immediately logged out and forced to use WordPress'password reset utility. This prevents any damage from being done and verifies the user's identity. But if the user is coming in from an IP address they have used in the past, an email is sent to the user making sure it was them logging in. All without intervention by an administrator.</p>\n\n<p>One day after installing the plugin I received the below email giving me an overview of what was currently occurring with my site. This Plugin is priceless considering it just thwarted a bad guy from trying to get in.</p>\n\n<p>Example Login Security Solution Threat Email:  </p>\n\n<pre>Your website, 2WheelTuesday, is undergoing a brute force attack.\n\nThere have been at least 50 failed attempts to log in during the past 120 minutes that used one or more of the following components:\n\nComponent                    Count     Value from Current Attempt\n------------------------     -----     ------------------------------<wbr />--\nNetwork IP                      47     ###.###.###.###\nUsername                        50     admin\nPassword MD5                     1     12345678901010101010\n\nThe Login Security Solution plugin (0.42.0) for WordPress is repelling the attack by making their login failures take a very long time.  This attacker will also be denied access in the event they stumble upon valid credentials.\n\nFurther notifications about this attacker will only be sent if the attack stops for at least 120 minutes and then resumes.</pre>","image":"/content/images/2014/01/wordpress-security-300x182.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1389246348000,"created_by":1,"updated_at":1430127568693,"updated_by":1,"published_at":1389246348000,"published_by":1},{"id":8,"uuid":"f835e73e-2f4b-4882-95e8-b133d1aac420","title":"The Broken American Credit Card System","slug":"difference-european-american-credit-card-systems","markdown":"As everyone by now has heard about the <a href=\"http://baltimore.cbslocal.com/2014/01/13/at-least-4-other-stores-affected-in-target-data-breach/\" target=\"_blank\">Target Credit Card hacking </a>scandal which netted the thieves upwards of 100 Million Credit Card numbers. My friends and I have discussed the broken and outdated American Credit Card System. How can the American Credit Card system be so far behind the rest of the world we always ask? We also know a handful of people each that have had their Credit Card information stolen one way or another.\n\nIt is hard to imagine such a data breach the magnitude of Target but I recently read a book about the Credit Card underworld which highlighted all the ways these thieves work the system. The book <a href=\"http://www.amazon.com/gp/product/B004IK8Q2M/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B004IK8Q2M&amp;linkCode=as2&amp;tag=2wheel-20\">Kingpin: How One Hacker Took Over the Billion-Dollar Cybercrime Underground</a><img style=\"border: none !important; margin: 0px !important;\" alt=\"\" src=\"http://ir-na.amazon-adsystem.com/e/ir?t=2wheel-20&amp;l=as2&amp;o=1&amp;a=B004IK8Q2M\" width=\"1\" height=\"1\" border=\"0\" /> is actually a very good read and actually reads more like an adventure than an Non-Fiction book.  It is scary at the same time at how easy it is to access Credit Card information and systems. The book is a perfect example of one particular crook took it to the next level.\n\nMy wife and I were victims of Credit Card fraud only last year when we visited Florida. Somewhere along the way our Credit Card was copied and sold along to thieves in New York. My wife and I returned to the US for Christmas and New Years and I payed very close attention to the Credit Card process for each transaction we made from stores to restaurants. What was shocking to me was the latent lack of consistency across all the different Point of Sale locations. Below is a list of the different credit card processes we encountered:\n\n<span style=\"text-decoration: underline;\"><strong>Stores</strong></span>\n\nScenario 1 - Swipe Card, the cashier prints a receipt, and asks us to sign the receipt\n\nScenario 2 - Swipe Card, cashier asks for ID, processes the transaction, and either sign on a electronic pad or the receipt\n\nScenario 3 - Cashier takes card and Swipes it and you sign nothing and just get a receipt\n\n<span style=\"text-decoration: underline;\"><strong>Restaurants</strong></span>\n<ul>\n\t<li>Give the server your credit card and they then run into the back room for what seems like an eternity before coming back with your card and the completed transaction receipts</li>\n</ul>\n<span style=\"text-decoration: underline;\"><strong>Gas Stations</strong></span>\n<ul>\n\t<li>Swipe your credit card and input your zip code (The most secure out of all transactions listed)</li>\n</ul>\n<h2> How to fix the Broken Credit Card System</h2>\n<ol>\n\t<li>Start incorporating Smart Cards into Credit Cards.  Europe has been using Smart Cards for a very long time.  Smart Cards added an additional layer to Credit Cards that only open up access to the chip on the card once the pin has been entered.  The pin is always separate from the card and can actually be a dynamically generated number as well.</li>\n\t<li>Require Credit Cards to have pins numbers for each transaction</li>\n\t<li>Require remote Credit Card processing machines. This would allow you to view your credit card at all times. For example, a restaurant server must bring the device to your table to process your payment.</li>\n\t<li>Two-Factor authentication - This is where I believe will make the largest impact on Credit Cards.  What if every Credit Card transaction sent you a SMS/Text Message/Automated Phone call with the transactions details and a 6 digit code which you must type in the Credit Card terminal to complete the transaction.</li>\n</ol>\nObviously, the list above will not eliminate Credit Card System fraud but it will make it much more difficult to have all the pieces to the puzzle to complete a transactions. In order to complete a transaction with the above mentioned points a Smart Card Credit Card, Pin Number, and a mobile phone linked to this credit card.","html":"<p>As everyone by now has heard about the <a href=\"http://baltimore.cbslocal.com/2014/01/13/at-least-4-other-stores-affected-in-target-data-breach/\" target=\"_blank\">Target Credit Card hacking </a>scandal which netted the thieves upwards of 100 Million Credit Card numbers. My friends and I have discussed the broken and outdated American Credit Card System. How can the American Credit Card system be so far behind the rest of the world we always ask? We also know a handful of people each that have had their Credit Card information stolen one way or another.</p>\n\n<p>It is hard to imagine such a data breach the magnitude of Target but I recently read a book about the Credit Card underworld which highlighted all the ways these thieves work the system. The book <a href=\"http://www.amazon.com/gp/product/B004IK8Q2M/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=B004IK8Q2M&amp;linkCode=as2&amp;tag=2wheel-20\">Kingpin: How One Hacker Took Over the Billion-Dollar Cybercrime Underground</a><img style=\"border: none !important; margin: 0px !important;\" alt=\"\" src=\"http://ir-na.amazon-adsystem.com/e/ir?t=2wheel-20&amp;l=as2&amp;o=1&amp;a=B004IK8Q2M\" width=\"1\" height=\"1\" border=\"0\" /> is actually a very good read and actually reads more like an adventure than an Non-Fiction book.  It is scary at the same time at how easy it is to access Credit Card information and systems. The book is a perfect example of one particular crook took it to the next level.</p>\n\n<p>My wife and I were victims of Credit Card fraud only last year when we visited Florida. Somewhere along the way our Credit Card was copied and sold along to thieves in New York. My wife and I returned to the US for Christmas and New Years and I payed very close attention to the Credit Card process for each transaction we made from stores to restaurants. What was shocking to me was the latent lack of consistency across all the different Point of Sale locations. Below is a list of the different credit card processes we encountered:</p>\n\n<p><span style=\"text-decoration: underline;\"><strong>Stores</strong></span></p>\n\n<p>Scenario 1 - Swipe Card, the cashier prints a receipt, and asks us to sign the receipt</p>\n\n<p>Scenario 2 - Swipe Card, cashier asks for ID, processes the transaction, and either sign on a electronic pad or the receipt</p>\n\n<p>Scenario 3 - Cashier takes card and Swipes it and you sign nothing and just get a receipt</p>\n\n<p><span style=\"text-decoration: underline;\"><strong>Restaurants</strong></span>  </p>\n\n<ul>  \n    <li>Give the server your credit card and they then run into the back room for what seems like an eternity before coming back with your card and the completed transaction receipts</li>\n</ul>  \n\n<p><span style=\"text-decoration: underline;\"><strong>Gas Stations</strong></span>  </p>\n\n<ul>  \n    <li>Swipe your credit card and input your zip code (The most secure out of all transactions listed)</li>\n</ul>  \n\n<h2> How to fix the Broken Credit Card System</h2>  \n\n<ol>  \n    <li>Start incorporating Smart Cards into Credit Cards.  Europe has been using Smart Cards for a very long time.  Smart Cards added an additional layer to Credit Cards that only open up access to the chip on the card once the pin has been entered.  The pin is always separate from the card and can actually be a dynamically generated number as well.</li>\n    <li>Require Credit Cards to have pins numbers for each transaction</li>\n    <li>Require remote Credit Card processing machines. This would allow you to view your credit card at all times. For example, a restaurant server must bring the device to your table to process your payment.</li>\n    <li>Two-Factor authentication - This is where I believe will make the largest impact on Credit Cards.  What if every Credit Card transaction sent you a SMS/Text Message/Automated Phone call with the transactions details and a 6 digit code which you must type in the Credit Card terminal to complete the transaction.</li>\n</ol>  \n\n<p>Obviously, the list above will not eliminate Credit Card System fraud but it will make it much more difficult to have all the pieces to the puzzle to complete a transactions. In order to complete a transaction with the above mentioned points a Smart Card Credit Card, Pin Number, and a mobile phone linked to this credit card.</p>","image":"/content/images/2014/01/credit_card_security-300x200.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1389720827000,"created_by":1,"updated_at":1430127596927,"updated_by":1,"published_at":1389720827000,"published_by":1},{"id":9,"uuid":"f524f9c1-8a1d-4bfc-aa2a-e9ce08ad1d96","title":"Wordpress Performance Comparison Shared Hosting vs Digital Ocean","slug":"wordpress-performance-comparison","markdown":"So one of my goals for 2014 was to move my website [2WheelTuesday](www.2wheeltuesday.com) from InMotion Hosting to <a href=\"https://www.digitalocean.com/?refcode=e30c53d3355c\" target=\"_blank\">Digital Ocean</a>. Well check. It is off my To Do list.\n\nI took the migration one step further. I not only migrated to Digital Ocean but I also converted from Apache webserver to <a href=\"http://nginx.org/\" target=\"_blank\">NGINX</a>. I can honestly say I am over the moon with the performance improvement and the sheer control I have over my server now.\n<h2>Downside of Shared Hosting</h2>\nThe troubling point with Shared Hosting is well it is shared.   I had quite some performance issues while using InMotion Hosting. I originally started with a normal hosting account until my website grew to the point it needed more performance.  After talking a long time with a Sales Consultant I decided to buy a VPS (Virtual Private Server) account.  Since I work every day with Virtual Machines/Server I thought this was a no brainer. Boy was I wrong. Performance was all over the place. Even though it was a VPS server I had limited permissions on the server itself to tune or install software.\n\nAfter sometime I didn't have time to maintain the website so I downgraded the hosting to a Reseller Account since I wanted to keep a few sites parked here..  Since my site was down from 4,000 hits a day to roughly 400 I thought this was sufficient step to park my website while keeping my Google rankings.\n\nAlmost every time I logged into my site it was down or the load times were off the scale. I couldn't believe how loading the site degraded so badly. I called the support desk and they informed me that my site was using to much resources. When I asked what specifically was wrong with performance they couldn't answer.\n\nIt was time to take action. Shared Hosting is great for small websites with little traffic.  Once your site grows and you have a lot of content and several hundred visitors it is time to consider an upgrade.  I checked the performance on my VPS and it was insanely slow.\n<h2>Wordpress Performance Comparison between Shared Hosting and Digital Ocean</h2>\nThis is not a 1 to 1 comparison just at the hosting level. But the comparison covers both a migration to Digital Ocean and switching to the webserver NGINX. If and when you plan a migration this a the perfect opportunity to tweak performance and do some house keeping.\n\nSo I installed a new droplet which is what Digital Ocean calls an instance.  I chose an image containing Wordpress with Ubuntu.  I then migrated this image from the Apache Server to the NGINX. Digital Ocean actually has a great instructions for <a href=\"https://www.digitalocean.com/community/articles/how-to-install-wordpress-with-nginx-on-ubuntu-12-04\" target=\"_blank\">Apache to NGINX migrations</a>.\n\nOK OK enough of the build up show us the facts.  **Right?**\n\nBefore with brianchristner.io running on InMotion Hosting, Wordpress, on a Reseller account with very few plugins.  This site is a very bog standard installation with very few posts and images.\n\nI ran the tests using [Load Impact](http://loadimpact.com/) in order to get unbiased 3rd party results. Load Impact is a stand alone service which measures website performance from different locations. I use this tool quite frequently for other projects as well.\n\n<img class=\"aligncenter size-full wp-image-225\" src=\"/content/images/2014/02/brianchristner.io_.png\" width=\"938\" height=\"501\" /></a>\n\n*Digital Ocean running 2WheelTuesday.com with NGINX with over 2000 Articles and 3600 pictures.*\n\n<img class=\"aligncenter size-full wp-image-226\" alt=\"2wheeltuesday with NGINX and Digital Ocean Hosting\" src=\"/content/images/2014/02/2wheeltuesday.png\" width=\"934\" height=\"498\" /></a>\n\nConclusion for less money than the Reseller package you get a shit ton better performance. As you see in the charts the Shared Hosting is sitting around 6.5 seconds load time versus the 2 seconds load time from Digital Ocean. It's also worth noting how much more consistent Digital Oceans graph is in comparison to InMotion.\n\nDigital Ocean $10 per month -\n<ul>\n\t<li>1 GB RAM</li>\n\t<li>1 CPU Core</li>\n\t<li>30GB SSD Disk</li>\n\t<li>2 TB Bandwidth</li>\n</ul>\nvs\n\nInMotion Reseller R-1000 $13.99 per month\n<ul>\n\t<li>Unknown CPU/Memory size and support would not confirm sizes to me</li>\n\t<li>60GB SAS 15,000 RPM Disks on RAID 5</li>\n\t<li>600 GB Bandwidth</li>\n</ul>\nSo a few bucks a month cheaper and far better performance with Digital Ocean.  One huge advantage is the ability to easily grow or shrink the size of your server with ease.  The only advantge with the Shared Hosting is most applications are built to install automatically where as by Digital Ocean you must setup most applications yourself.  The advantage with this is you can customise all the settings for your particular use.\n<h2>Converting Wordpress from Apache to NGINX</h2>\nLet's talk about the Apache vs NGINX configuration.  I have migrated to NGINX from Apache.  I do admit it required a lot of configuration in order to get the NGINX running exactly how I wanted it.  Once it is up and running I am amazed at the performance improvement and the ability to handle multiple connections.\n\nApache -\n\nThis is a great web server. I have used it for a very long time without complaints.  It works right out of the box and it is easy to configure and use. The disadvantage is that Apache is a bit of a memory hog and tends to use a lot of memory when your website starts receiving a lot of requests.\n\nNGINX -\n\nThe new kid on the block and one the fastest growing webserver on the market. Also, to mention Worpress.org is now using NGINX as their webserver to put things in perspective. The pros are huge with NGINX handling multiple connections with ease all while maintainaing a very small ressource footprint. The con is it requires a lot of configuration to get all your plugins running and tuned the way you want. But once running you will be smiling ear to ear with the performance gains.","html":"<p>So one of my goals for 2014 was to move my website <a href=\"www.2wheeltuesday.com\">2WheelTuesday</a> from InMotion Hosting to <a href=\"https://www.digitalocean.com/?refcode=e30c53d3355c\" target=\"_blank\">Digital Ocean</a>. Well check. It is off my To Do list.</p>\n\n<p>I took the migration one step further. I not only migrated to Digital Ocean but I also converted from Apache webserver to <a href=\"http://nginx.org/\" target=\"_blank\">NGINX</a>. I can honestly say I am over the moon with the performance improvement and the sheer control I have over my server now.  </p>\n\n<h2>Downside of Shared Hosting</h2>  \n\n<p>The troubling point with Shared Hosting is well it is shared.   I had quite some performance issues while using InMotion Hosting. I originally started with a normal hosting account until my website grew to the point it needed more performance.  After talking a long time with a Sales Consultant I decided to buy a VPS (Virtual Private Server) account.  Since I work every day with Virtual Machines/Server I thought this was a no brainer. Boy was I wrong. Performance was all over the place. Even though it was a VPS server I had limited permissions on the server itself to tune or install software.</p>\n\n<p>After sometime I didn't have time to maintain the website so I downgraded the hosting to a Reseller Account since I wanted to keep a few sites parked here..  Since my site was down from 4,000 hits a day to roughly 400 I thought this was sufficient step to park my website while keeping my Google rankings.</p>\n\n<p>Almost every time I logged into my site it was down or the load times were off the scale. I couldn't believe how loading the site degraded so badly. I called the support desk and they informed me that my site was using to much resources. When I asked what specifically was wrong with performance they couldn't answer.</p>\n\n<p>It was time to take action. Shared Hosting is great for small websites with little traffic.  Once your site grows and you have a lot of content and several hundred visitors it is time to consider an upgrade.  I checked the performance on my VPS and it was insanely slow.  </p>\n\n<h2>Wordpress Performance Comparison between Shared Hosting and Digital Ocean</h2>  \n\n<p>This is not a 1 to 1 comparison just at the hosting level. But the comparison covers both a migration to Digital Ocean and switching to the webserver NGINX. If and when you plan a migration this a the perfect opportunity to tweak performance and do some house keeping.</p>\n\n<p>So I installed a new droplet which is what Digital Ocean calls an instance.  I chose an image containing Wordpress with Ubuntu.  I then migrated this image from the Apache Server to the NGINX. Digital Ocean actually has a great instructions for <a href=\"https://www.digitalocean.com/community/articles/how-to-install-wordpress-with-nginx-on-ubuntu-12-04\" target=\"_blank\">Apache to NGINX migrations</a>.</p>\n\n<p>OK OK enough of the build up show us the facts.  <strong>Right?</strong></p>\n\n<p>Before with brianchristner.io running on InMotion Hosting, Wordpress, on a Reseller account with very few plugins.  This site is a very bog standard installation with very few posts and images.</p>\n\n<p>I ran the tests using <a href=\"http://loadimpact.com/\">Load Impact</a> in order to get unbiased 3rd party results. Load Impact is a stand alone service which measures website performance from different locations. I use this tool quite frequently for other projects as well.</p>\n\n<p><img class=\"aligncenter size-full wp-image-225\" src=\"/content/images/2014/02/brianchristner.io_.png\" width=\"938\" height=\"501\" /></a></p>\n\n<p><em>Digital Ocean running 2WheelTuesday.com with NGINX with over 2000 Articles and 3600 pictures.</em></p>\n\n<p><img class=\"aligncenter size-full wp-image-226\" alt=\"2wheeltuesday with NGINX and Digital Ocean Hosting\" src=\"/content/images/2014/02/2wheeltuesday.png\" width=\"934\" height=\"498\" /></a></p>\n\n<p>Conclusion for less money than the Reseller package you get a shit ton better performance. As you see in the charts the Shared Hosting is sitting around 6.5 seconds load time versus the 2 seconds load time from Digital Ocean. It's also worth noting how much more consistent Digital Oceans graph is in comparison to InMotion.</p>\n\n<p>Digital Ocean $10 per month -  </p>\n\n<ul>  \n    <li>1 GB RAM</li>\n    <li>1 CPU Core</li>\n    <li>30GB SSD Disk</li>\n    <li>2 TB Bandwidth</li>\n</ul>  \n\n<p>vs</p>\n\n<p>InMotion Reseller R-1000 $13.99 per month  </p>\n\n<ul>  \n    <li>Unknown CPU/Memory size and support would not confirm sizes to me</li>\n    <li>60GB SAS 15,000 RPM Disks on RAID 5</li>\n    <li>600 GB Bandwidth</li>\n</ul>  \n\n<p>So a few bucks a month cheaper and far better performance with Digital Ocean.  One huge advantage is the ability to easily grow or shrink the size of your server with ease.  The only advantge with the Shared Hosting is most applications are built to install automatically where as by Digital Ocean you must setup most applications yourself.  The advantage with this is you can customise all the settings for your particular use.  </p>\n\n<h2>Converting Wordpress from Apache to NGINX</h2>  \n\n<p>Let's talk about the Apache vs NGINX configuration.  I have migrated to NGINX from Apache.  I do admit it required a lot of configuration in order to get the NGINX running exactly how I wanted it.  Once it is up and running I am amazed at the performance improvement and the ability to handle multiple connections.</p>\n\n<p>Apache -</p>\n\n<p>This is a great web server. I have used it for a very long time without complaints.  It works right out of the box and it is easy to configure and use. The disadvantage is that Apache is a bit of a memory hog and tends to use a lot of memory when your website starts receiving a lot of requests.</p>\n\n<p>NGINX -</p>\n\n<p>The new kid on the block and one the fastest growing webserver on the market. Also, to mention Worpress.org is now using NGINX as their webserver to put things in perspective. The pros are huge with NGINX handling multiple connections with ease all while maintainaing a very small ressource footprint. The con is it requires a lot of configuration to get all your plugins running and tuned the way you want. But once running you will be smiling ear to ear with the performance gains.</p>","image":"/content/images/2014/02/digital-ocean-logo-300x225.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1391465542000,"created_by":1,"updated_at":1430127634173,"updated_by":1,"published_at":1391465542000,"published_by":1},{"id":10,"uuid":"0f2602c4-f510-4489-9ad9-9cfb8b8dd1e1","title":"How to Recover your Root Ubuntu Password","slug":"ubuntu-password-recovery","markdown":"So I changed my Ubuntu password via my Cloud interface and next thing I know my Ubuntu password didn't take and the old one was some randomly generated password from my Ubuntu template. Shit! So how do you recover a root Ubuntu password?\n\nWell the trick I learned is only applicable to people who can reboot the Linux machine and view the GRUB menu on start-up. If this is you then by golly you are also in luck. The example below drops into the root shell in order to change the password.\n\nReboot your Ubuntu machine. While Ubuntu is starting starting hit the *SHIFT* until you see the GNU GRUB menu loading.  Once the menu displays as shown below hit the <em>e </em>in order to edit the boot options.\n\n<img class=\"aligncenter size-full wp-image-233\" alt=\"gnu_grub\" src=\"/content/images/2014/02/gnu_grub.png\" width=\"640\" height=\"275\" /></a>\n\nOnce the Edit Boot Option menu opens locate the line that starts with: linux /boot/vmlinuz (The second to last line in the screenshot below).  At the end of this line add the following: rw\\ init=/bin/bash.  Hit F10 or CTRL-X to reboot Ubuntu.  Ubuntu will now start with these options taking directly to the shell as the root user.\n\n<a href=\"/content/images/2014/02/grub_menu.png\"><img class=\"aligncenter size-full wp-image-234\" alt=\"grub_menu\" src=\"/content/images/2014/02/grub_menu.png\" width=\"971\" height=\"552\" /></a>\n\nOnce the shell has come up type the following commands to reset your Ubuntu root password:\n\nAt the command prompt type: <em>passwd</em>\n\nThis will trigger the reset password procedure for the root user.\n\nFinish the Ubuntu password recovery process by rebooting once more. This will boot the Ubuntu machine back into normal boot mode.\n\nGood luck and I hope you recover your Ubuntu Password!","html":"<p>So I changed my Ubuntu password via my Cloud interface and next thing I know my Ubuntu password didn't take and the old one was some randomly generated password from my Ubuntu template. Shit! So how do you recover a root Ubuntu password?</p>\n\n<p>Well the trick I learned is only applicable to people who can reboot the Linux machine and view the GRUB menu on start-up. If this is you then by golly you are also in luck. The example below drops into the root shell in order to change the password.</p>\n\n<p>Reboot your Ubuntu machine. While Ubuntu is starting starting hit the <em>SHIFT</em> until you see the GNU GRUB menu loading.  Once the menu displays as shown below hit the <em>e </em>in order to edit the boot options.</p>\n\n<p><img class=\"aligncenter size-full wp-image-233\" alt=\"gnu_grub\" src=\"/content/images/2014/02/gnu_grub.png\" width=\"640\" height=\"275\" /></a></p>\n\n<p>Once the Edit Boot Option menu opens locate the line that starts with: linux /boot/vmlinuz (The second to last line in the screenshot below).  At the end of this line add the following: rw\\ init=/bin/bash.  Hit F10 or CTRL-X to reboot Ubuntu.  Ubuntu will now start with these options taking directly to the shell as the root user.</p>\n\n<p><a href=\"/content/images/2014/02/grub_menu.png\"><img class=\"aligncenter size-full wp-image-234\" alt=\"grub_menu\" src=\"/content/images/2014/02/grub_menu.png\" width=\"971\" height=\"552\" /></a></p>\n\n<p>Once the shell has come up type the following commands to reset your Ubuntu root password:</p>\n\n<p>At the command prompt type: <em>passwd</em></p>\n\n<p>This will trigger the reset password procedure for the root user.</p>\n\n<p>Finish the Ubuntu password recovery process by rebooting once more. This will boot the Ubuntu machine back into normal boot mode.</p>\n\n<p>Good luck and I hope you recover your Ubuntu Password!</p>","image":"/content/images/2014/02/gnu_grub.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1393438279000,"created_by":1,"updated_at":1430127671520,"updated_by":1,"published_at":1393438279000,"published_by":1},{"id":11,"uuid":"0cd4cf2b-b9c7-4d25-92a9-6bb6fd44955a","title":"vCloud Networking Security Best Practices","slug":"vcloud-networking-security-best-practices","markdown":"vCloud networking is often overlooked when considering security best practices. However, networking architecture has a lot of aspects to consider. By creating Internal Organization Networks (ION), External Organization Networks (EON), vApp Networks, and Demilitarized Zones (DMZ) this enables the administrator to separate servers based on role or application. By using a mix of both ION’s, EON’s, vApp networks, and DMZ’s enables a network design that allows for the most secure and logical network by separating server roles and applications.\n\n**Figure 1** illustrates the combination of all three of these networks. Limiting the amount of connections externally to the internet and using the vShield or third party firewall reduces your visible footprint to outside networks.\n\nUtilizing DMZ’s in combination with the vShield Load Balancing allows the Administrator to create secure DMZ networks while removing exposure to other VM’s or resources.\n\n<center><img class=\"aligncenter size-full wp-image-271\" src=\"/content/images/2014/06/vApp_Network.jpg\" alt=\"vApp Network Diagramm\" width=\"366\" height=\"254\" /></a>\n\n*Figure1 Source: VMware*</center>\n\n<h3>vApp Networks</h3>\n\nA vApp network is contained within a vApp and allows virtual machines in the vApp to communicate with each other. You can also connect a vApp network to an organization vDC network to allow the vApp to communicate with other vApps in the organization and outside of the organization, if the organization vDC network is connected to an external network.\n\n<h3>Internal Organization Networks (ION)</h3>\n\nThe ION is sometimes referred to as a Data Center connect network or a Private Network. The role of this network is to connect multiple Data Centers, vApps, and VM’s. This network has no external connectivity.\n\nION’s are most commonly used for:\n<ol>\n\t<li>Virtual Machine to Virtual Machine</li>\n\t<li>vApp to vApp</li>\n\t<li>Data Center to Data Center</li>\n</ol>\n<h3>External Organization Networks (EON)</h3>\n\nThe EON functions exactly like the ION.  The difference is the EON network is connected to External Provider Network (EPN) or better known as your internet connection. The EON still allows for connection directly to VM’s, vApp’s, or Data Centers.\n\n<h3>Demilitarized Zone (DMZ)</h3>\n\nA DMZ (demilitarized zone) is a generic term for a subnetwork that contains and exposes an organization’s external services to a larger untrusted network, usually the Internet. The purpose of a DMZ is to add an additional layer of security to an organization’s Local Area Network (LAN); an external attacker only has access to equipment in the DMZ, rather than any other part of the network. (Source VMware)\n\n**In figure 2** the vShield provides the load balancing functionality and firewall needed to secure the vApp workloads.  The DMZ network should be an isolated vApp or ION network, but the public network should be an EON network. The vShield separates the public network or internet from the internal resources behind the vShield Firewall and Load Balancer thus protecting the workloads.\n\nThe DMZ network should be an isolated vApp or ION, but the public network should be a vApp or EON network that routes to client locations.  The DMZ should be isolated from the rest of the organization’s network\n\n<center><img class=\"aligncenter size-full wp-image-272\" src=\"/content/images/2014/06/vCloud_DMZ.jpg\" alt=\"vCloud DMZ Diagramm\" width=\"327\" height=\"386\" /></a>\n\nFigure 2 Source: VMware </center>\n\n\n<h2>vCloud Firewall Best Practices</h2>\n\nThe Firewall is one of the most critical components of the DCS infrastructure in regards to security. It is recommended to use the vShield Edge firewall included inside of DCS or to use a third-party firewall like Fortigate, Checkpoint, Barracuda, or Juniper are just some of the firewalls that are currently in use. Regardless of the firewall selected it is important that a firewall is installed, activated, and configured correctly.\n\nThe vShield Edge or 3rd Party Appliance provides network security and gateway services to isolate virtual machines. These Firewalls provide services such as Firewall, DHCP, VPN, NAT, and Load Balancer\n\n<h3>Firewall</h3>\n\nThe Firewall supports rules based on IP address and Port ranges for inspection of TCP, UDP, and ICMP traffic.  These firewall rules can be assigned to a specific IP or Port or ranges of IP’s and Ports.\n<h3>vShield Firewall Best Practices</h3>\n<ol>\n\t<li>Name rules so that they are clear to understand and quick to navigate to in case of urgent situations.  This makes administration and auditing of the rules much easier.</li>\n\t<li>Don’t create wide ranges or IP’s spanning the entire IP pool.  Rather it would be better to include a rule just for the VM or VM’s that require the port or protocol to be opened.  This is both a safer practice and easier to audit.</li>\n\t<li>Another important configuration is to ensure that the default action of the Firewall is to block by default traffic that does not match the rules list.</li>\n</ol>\n<img class=\"aligncenter size-full wp-image-274\" src=\"/content/images/2014/06/vShield_Firewall_Configuration.png\" width=\"423\" height=\"226\" /></a>\n<ol start=\"4\">\n\t<li>Lock down Protocols to the actual protocol (TCP, UDP, ICMP) and don’t use ANY as a protocol as this allows all traffic for this specific rule which is both not best practice or advised.<img class=\"aligncenter size-full wp-image-275\" src=\"/content/images/2014/06/vShield_Firewall_Rules_Configuration.png\" width=\"101\" height=\"141\" /></a></li>\n<li>Disable rules that are no longer in use\n</ol>\n<h3>Network Address Translation (NAT)</h3>\n\nNetwork Address Translation (NAT) translates a private internal IP address from the protect subnet into a public IP address on the External Network for outbound traffic.  The rules include Source and Destination IP address and TCP/UDP port translation.  If Source Network Address Translation (SNAT) or Destination Network Address Translation are configured incorrectly this could cause security and/or connectivity issues.\n\n<h3>SNAT Rules</h3> controls traffic originating from within DCS.\n\n<strong>DNAT Rules</strong> controls traffic originating from outside of DCS.  You should perform DNAT configurations cautiously as poorly configured DNAT rules could allow unsolicited traffic from outside the network to inside.\n<h3>vShield NAT Best Practices</h3>\n<ol>\n\t<li>Name SNAT &amp; DNAT rules so that they are clear to understand and quick to navigate to in case of urgent situations.  This makes administration and auditing of the rules much easier.</li>\n\t<li>Disable unused SNAT or DNAT rules</li>\n\t<li>It is best practice not to set Protocol or ports to ANY.</li>\n\t<li>Limit port/IP ranges to the minimum required.  The broader the range the less secure the rule becomes.</li>\n</ol>\n<h3>Virtual Private Network (VPN)</h3>\n\nThe IPsec VPN service included with the vShield Edge provides a secure VPN tunnel between other vShield Gateways in the same organization, across several organizations, or third party VPN gateways.\n\nThe vShield Edge Gateway is contains the Site-to-Site Virtual Private Network functionality.  This uses standard protocols and settings that interoperate with all major firewall vendors.  vShield Edge modules support site-to-site IPSec VPN between a vShield Edge and remote sites.  vShield Edge supports pre-shared key mode, AES or 3DES encryption, IP unicast traffic, and no dynamic routing protocol between the vShield Edge and remote VPN routers. Behind each remote VPN router, you can configure multiple subnets to connect to the internal network behind a vShield Edge through IPSec tunnels.  These subnets and the internal network behind a vShield Edge must have nonoverlapping address ranges.\n\n<center><img class=\"aligncenter wp-image-278 \" src=\"/content/images/2014/06/vShield_site-to-site-vpn-300x99.png\" alt=\"vShield site-to-site vpn\" width=\"450\" height=\"220\" /></a></center>","html":"<p>vCloud networking is often overlooked when considering security best practices. However, networking architecture has a lot of aspects to consider. By creating Internal Organization Networks (ION), External Organization Networks (EON), vApp Networks, and Demilitarized Zones (DMZ) this enables the administrator to separate servers based on role or application. By using a mix of both ION’s, EON’s, vApp networks, and DMZ’s enables a network design that allows for the most secure and logical network by separating server roles and applications.</p>\n\n<p><strong>Figure 1</strong> illustrates the combination of all three of these networks. Limiting the amount of connections externally to the internet and using the vShield or third party firewall reduces your visible footprint to outside networks.</p>\n\n<p>Utilizing DMZ’s in combination with the vShield Load Balancing allows the Administrator to create secure DMZ networks while removing exposure to other VM’s or resources.</p>\n\n<p><center><img class=\"aligncenter size-full wp-image-271\" src=\"/content/images/2014/06/vApp_Network.jpg\" alt=\"vApp Network Diagramm\" width=\"366\" height=\"254\" /></a></p>\n\n<p><em>Figure1 Source: VMware</em></center></p>\n\n<h3>vApp Networks</h3>\n\n<p>A vApp network is contained within a vApp and allows virtual machines in the vApp to communicate with each other. You can also connect a vApp network to an organization vDC network to allow the vApp to communicate with other vApps in the organization and outside of the organization, if the organization vDC network is connected to an external network.</p>\n\n<h3>Internal Organization Networks (ION)</h3>\n\n<p>The ION is sometimes referred to as a Data Center connect network or a Private Network. The role of this network is to connect multiple Data Centers, vApps, and VM’s. This network has no external connectivity.</p>\n\n<p>ION’s are most commonly used for:  </p>\n\n<ol>  \n    <li>Virtual Machine to Virtual Machine</li>\n    <li>vApp to vApp</li>\n    <li>Data Center to Data Center</li>\n</ol>  \n\n<h3>External Organization Networks (EON)</h3>\n\n<p>The EON functions exactly like the ION.  The difference is the EON network is connected to External Provider Network (EPN) or better known as your internet connection. The EON still allows for connection directly to VM’s, vApp’s, or Data Centers.</p>\n\n<h3>Demilitarized Zone (DMZ)</h3>\n\n<p>A DMZ (demilitarized zone) is a generic term for a subnetwork that contains and exposes an organization’s external services to a larger untrusted network, usually the Internet. The purpose of a DMZ is to add an additional layer of security to an organization’s Local Area Network (LAN); an external attacker only has access to equipment in the DMZ, rather than any other part of the network. (Source VMware)</p>\n\n<p><strong>In figure 2</strong> the vShield provides the load balancing functionality and firewall needed to secure the vApp workloads.  The DMZ network should be an isolated vApp or ION network, but the public network should be an EON network. The vShield separates the public network or internet from the internal resources behind the vShield Firewall and Load Balancer thus protecting the workloads.</p>\n\n<p>The DMZ network should be an isolated vApp or ION, but the public network should be a vApp or EON network that routes to client locations.  The DMZ should be isolated from the rest of the organization’s network</p>\n\n<p><center><img class=\"aligncenter size-full wp-image-272\" src=\"/content/images/2014/06/vCloud_DMZ.jpg\" alt=\"vCloud DMZ Diagramm\" width=\"327\" height=\"386\" /></a></p>\n\n<p>Figure 2 Source: VMware </center></p>\n\n<h2>vCloud Firewall Best Practices</h2>\n\n<p>The Firewall is one of the most critical components of the DCS infrastructure in regards to security. It is recommended to use the vShield Edge firewall included inside of DCS or to use a third-party firewall like Fortigate, Checkpoint, Barracuda, or Juniper are just some of the firewalls that are currently in use. Regardless of the firewall selected it is important that a firewall is installed, activated, and configured correctly.</p>\n\n<p>The vShield Edge or 3rd Party Appliance provides network security and gateway services to isolate virtual machines. These Firewalls provide services such as Firewall, DHCP, VPN, NAT, and Load Balancer</p>\n\n<h3>Firewall</h3>\n\n<p>The Firewall supports rules based on IP address and Port ranges for inspection of TCP, UDP, and ICMP traffic.  These firewall rules can be assigned to a specific IP or Port or ranges of IP’s and Ports.  </p>\n\n<h3>vShield Firewall Best Practices</h3>  \n\n<ol>  \n    <li>Name rules so that they are clear to understand and quick to navigate to in case of urgent situations.  This makes administration and auditing of the rules much easier.</li>\n    <li>Don’t create wide ranges or IP’s spanning the entire IP pool.  Rather it would be better to include a rule just for the VM or VM’s that require the port or protocol to be opened.  This is both a safer practice and easier to audit.</li>\n    <li>Another important configuration is to ensure that the default action of the Firewall is to block by default traffic that does not match the rules list.</li>\n</ol>  \n\n<p><img class=\"aligncenter size-full wp-image-274\" src=\"/content/images/2014/06/vShield_Firewall_Configuration.png\" width=\"423\" height=\"226\" /></a>  </p>\n\n<ol start=\"4\">  \n    <li>Lock down Protocols to the actual protocol (TCP, UDP, ICMP) and don’t use ANY as a protocol as this allows all traffic for this specific rule which is both not best practice or advised.<img class=\"aligncenter size-full wp-image-275\" src=\"/content/images/2014/06/vShield_Firewall_Rules_Configuration.png\" width=\"101\" height=\"141\" /></a></li>\n<li>Disable rules that are no longer in use  \n</ol>  \n\n<h3>Network Address Translation (NAT)</h3>\n\n<p>Network Address Translation (NAT) translates a private internal IP address from the protect subnet into a public IP address on the External Network for outbound traffic.  The rules include Source and Destination IP address and TCP/UDP port translation.  If Source Network Address Translation (SNAT) or Destination Network Address Translation are configured incorrectly this could cause security and/or connectivity issues.</p>\n\n<h3>SNAT Rules</h3> controls traffic originating from within DCS.\n\n<strong>DNAT Rules</strong> controls traffic originating from outside of DCS.  You should perform DNAT configurations cautiously as poorly configured DNAT rules could allow unsolicited traffic from outside the network to inside.  \n<h3>vShield NAT Best Practices</h3>  \n\n<ol>  \n    <li>Name SNAT &amp; DNAT rules so that they are clear to understand and quick to navigate to in case of urgent situations.  This makes administration and auditing of the rules much easier.</li>\n    <li>Disable unused SNAT or DNAT rules</li>\n    <li>It is best practice not to set Protocol or ports to ANY.</li>\n    <li>Limit port/IP ranges to the minimum required.  The broader the range the less secure the rule becomes.</li>\n</ol>  \n\n<h3>Virtual Private Network (VPN)</h3>\n\n<p>The IPsec VPN service included with the vShield Edge provides a secure VPN tunnel between other vShield Gateways in the same organization, across several organizations, or third party VPN gateways.</p>\n\n<p>The vShield Edge Gateway is contains the Site-to-Site Virtual Private Network functionality.  This uses standard protocols and settings that interoperate with all major firewall vendors.  vShield Edge modules support site-to-site IPSec VPN between a vShield Edge and remote sites.  vShield Edge supports pre-shared key mode, AES or 3DES encryption, IP unicast traffic, and no dynamic routing protocol between the vShield Edge and remote VPN routers. Behind each remote VPN router, you can configure multiple subnets to connect to the internal network behind a vShield Edge through IPSec tunnels.  These subnets and the internal network behind a vShield Edge must have nonoverlapping address ranges.</p>\n\n<p><center><img class=\"aligncenter wp-image-278 \" src=\"/content/images/2014/06/vShield_site-to-site-vpn-300x99.png\" alt=\"vShield site-to-site vpn\" width=\"450\" height=\"220\" /></a></center></p>","image":"/content/images/2014/06/vApp_Network.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1402663431000,"created_by":1,"updated_at":1430127709821,"updated_by":1,"published_at":1402663431000,"published_by":1},{"id":13,"uuid":"8906356c-7fa5-47fc-a52b-51e05c329dbd","title":"What I've learned about living in Europe so far...","slug":"what-i-learned-living-europe","markdown":"Moving from Las Vegas to a tiny village outside of Amsterdam called Hoofddorp was quite a shock.  After spending the last <del>days</del> I mean weeks hitting all my favorite bars and clubs in Las Vegas with my buddies before I flew to the Netherlands. I arrived in Netherlands at my hotel on a Saturday night and got settled in. After taking a shower I <span style=\"text-decoration: underline;\">thought</span> I would take a stroll around town and see what was happening. Still rocking my American style with a big fat goatee, Airwalks, baggy Jeans, Ray Bans, and a baseball hat turned backwards. I stood out like a sore thumb and received quite some interesting looks.  The shell shock started settling in that this is nothing like I was prepared for. Welcome to Europe!\n<h2>Living in The Netherlands</h2>\nSo after living in this hotel room off and on in Hoofddorp for close to 6 months I finally moved out into the wild. I found a room for rent in Amsterdam by a really cool British girl. She showed me around town and introduced me to some cool places and people. My job kept me on the road so I didn't spend a lot of time in The Netherlands the first year. I was travelling around Europe working in casinos in various amazing locations that I would have never imagined or thought of traveling to. What struck me instantly was the laid back attitude, slower pace of life, and people really just seemed to be taking time to enjoy life. A huge emphasis is put on holidays even though it always felt like The Netherlands has the least amount of public holidays in the world! What I started to learn from living in The Netherlands and travelling Europe/World is to accept new cultures, open my mind to new ideas, and of course try all sorts of new cuisines and beers along the way. The Dutch are nice people and The Netherlands was perfect introduction to European living. I knew once I spent sometime in The Netherlands that this was not a place I would spend the rest of my life. I particularly didn't care for the horrible year round weather, I missed the outdoors, mountains, and was not a big fan of the extremely high taxes. Next stop Switzerland!\n<center><img class=\"alignleft size-medium wp-image-304\" src=\"/content/images/2014/08/swiss-flag-300x300.jpg\" alt=\"swiss flag\" width=\"300\" height=\"300\" /></a></center>\n<h2>Moving &amp; Living in Switzerland</h2>\nSo after a ton of discussions with my Swiss wife the decision of our next move came down to either the US or Switzerland. We decided on Switzerland over the US because our reasoning is that it would be easy for us to go to the US at anytime but it would be more difficult to move back to Europe from the US. Switzerland was an excellent move for the both us personally and professionally. However, I quickly realised unlike The Netherlands where everyone's English comprehension was excellent. Switzerland is very different.  In Zürich and Zug English levels are OK but quickly dissipate once outside these cities. I made it a mission of mine to start learning German right away. I took 3 months off from work just to learn German full time. Once I had a basic grasp on the German language I found a job at an international Finance company in Zug, Switzerland. I continued my German courses until I switched jobs to [Swisscom](http://Swisscom.com) where I am now using German the entire day. Wow it shocks me to think that I would ever be living or working in Switzerland let alone working in a totally different language. Now that we have settled into Switzerland we love it. The outdoors are right out of our back door and snow skiing is everywhere. We are also a couple hours from France, Germany, or Italy making for easy weekend getaways. People are easy to meet and we have actually become much more active in the community and surrounding areas. We also love the fact of buying everything directly from the farms around the city we live in. Needless to say we are very happy with our choice to move to Switzerland and oh the weather, food, and taxes are so much better here than The Netherlands. More to come on life in Switzerland","html":"<p>Moving from Las Vegas to a tiny village outside of Amsterdam called Hoofddorp was quite a shock.  After spending the last <del>days</del> I mean weeks hitting all my favorite bars and clubs in Las Vegas with my buddies before I flew to the Netherlands. I arrived in Netherlands at my hotel on a Saturday night and got settled in. After taking a shower I <span style=\"text-decoration: underline;\">thought</span> I would take a stroll around town and see what was happening. Still rocking my American style with a big fat goatee, Airwalks, baggy Jeans, Ray Bans, and a baseball hat turned backwards. I stood out like a sore thumb and received quite some interesting looks.  The shell shock started settling in that this is nothing like I was prepared for. Welcome to Europe!  </p>\n\n<h2>Living in The Netherlands</h2>  \n\n<p>So after living in this hotel room off and on in Hoofddorp for close to 6 months I finally moved out into the wild. I found a room for rent in Amsterdam by a really cool British girl. She showed me around town and introduced me to some cool places and people. My job kept me on the road so I didn't spend a lot of time in The Netherlands the first year. I was travelling around Europe working in casinos in various amazing locations that I would have never imagined or thought of traveling to. What struck me instantly was the laid back attitude, slower pace of life, and people really just seemed to be taking time to enjoy life. A huge emphasis is put on holidays even though it always felt like The Netherlands has the least amount of public holidays in the world! What I started to learn from living in The Netherlands and travelling Europe/World is to accept new cultures, open my mind to new ideas, and of course try all sorts of new cuisines and beers along the way. The Dutch are nice people and The Netherlands was perfect introduction to European living. I knew once I spent sometime in The Netherlands that this was not a place I would spend the rest of my life. I particularly didn't care for the horrible year round weather, I missed the outdoors, mountains, and was not a big fan of the extremely high taxes. Next stop Switzerland! <br />\n<center><img class=\"alignleft size-medium wp-image-304\" src=\"/content/images/2014/08/swiss-flag-300x300.jpg\" alt=\"swiss flag\" width=\"300\" height=\"300\" /></a></center>  </p>\n\n<h2>Moving &amp; Living in Switzerland</h2>  \n\n<p>So after a ton of discussions with my Swiss wife the decision of our next move came down to either the US or Switzerland. We decided on Switzerland over the US because our reasoning is that it would be easy for us to go to the US at anytime but it would be more difficult to move back to Europe from the US. Switzerland was an excellent move for the both us personally and professionally. However, I quickly realised unlike The Netherlands where everyone's English comprehension was excellent. Switzerland is very different.  In Zürich and Zug English levels are OK but quickly dissipate once outside these cities. I made it a mission of mine to start learning German right away. I took 3 months off from work just to learn German full time. Once I had a basic grasp on the German language I found a job at an international Finance company in Zug, Switzerland. I continued my German courses until I switched jobs to <a href=\"http://Swisscom.com\">Swisscom</a> where I am now using German the entire day. Wow it shocks me to think that I would ever be living or working in Switzerland let alone working in a totally different language. Now that we have settled into Switzerland we love it. The outdoors are right out of our back door and snow skiing is everywhere. We are also a couple hours from France, Germany, or Italy making for easy weekend getaways. People are easy to meet and we have actually become much more active in the community and surrounding areas. We also love the fact of buying everything directly from the farms around the city we live in. Needless to say we are very happy with our choice to move to Switzerland and oh the weather, food, and taxes are so much better here than The Netherlands. More to come on life in Switzerland</p>","image":"/content/images/2014/08/leaving_las_vegas.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1408188809000,"created_by":1,"updated_at":1421394234837,"updated_by":1,"published_at":1408188809000,"published_by":1},{"id":14,"uuid":"b7bc1c06-29f6-43f5-9606-706ed4c41950","title":"How to block Semalt.com from crawling your Wordpress site","slug":"how-to-block-semalt-crawling-nginx-wordpress-site","markdown":"I have noticed in all of my Wordpress sites over the last few months that a new referrer *.semalt.com keeps crawling my site. Usually I don't bother with most crawlers as they are indexing your site for the benefit of the internet right? <b>Wrong!</b>\n\nIt appears Semalt is indexing sites to collect backlinks and keywords to deliver more powerful sneaky spam techniques to use against your sites.  Unlike most crawlers on the internet Selmalt does not follow your robots.txt file. So even if you block it via your robots.txt file it will circumvent this rule and continue crawling your site. Well shit!\n\n<a href=\"http://clicky.com/\" target=\"_blank\">Clicky</a> realtime web analytics announced on their Twitter they have now blocked Semalt.  Wordpress.com is also\n<blockquote class=\"twitter-tweet\" lang=\"en\">\"Visitors\" from <a href=\"http://t.co/E532GqJzYW\">http://t.co/E532GqJzYW</a> referrers are now ignored by default. See ya, spammers!\n\n— Clicky Web Analytics (@clicky) <a href=\"https://twitter.com/clicky/statuses/445704464750501890\">March 17, 2014</a></blockquote>\n<script src=\"//platform.twitter.com/widgets.js\" async=\"\" charset=\"utf-8\"></script>\n\nOK enough with the blabbering. So how do I block these bastards from crawling my site?\n<h2>How to block Semalt.com from crawling your NGINX Wordpress site</h2>\n<ol>\n<ol>\n<ol>\n\t<li style=\"text-align: left;\">You can try to Opt out of the samalt index but I am doubting this works (Bottom of the page) - <a title=\"Opt Out Semalt\" href=\"http://semalt.com/project_crawler.php\" target=\"_blank\">Opt Out Semalt</a></li>\n\t<li style=\"text-align: left;\">Navigate to your NGINX sites-enabled directory.  Usually in /etc/nginx/sites-enabled</li>\n\t<li>Open your domains config file in this directory</li>\n\t<li>Add the below code to your domains config file.  If you want to add additional crawlers to this list separate the crawlers with a pipe ¦</li>\n</ol>\n</ol>\n</ol>\n<code>if ($http_user_agent ~ \"semalt.com\") { </code>\n\n<code>return 403; </code>\n\n<code>break; </code>\n\n<code>}</code>\n<ol>\n\t<li>Once you have added the above code to your domain config file run a <strong><em>nginx -t </em></strong><em>(Tests your config)</em> to ensure that you made no typos in the file and that NGINX is happy with the new config</li>\n\t<li>Once NGINX reports that everything is OK reload NGINX config files:</li>\n</ol>\n<code>$service nginx reload</code>\nIf your running an Apache Wordpress website check out  the <a href=\"http://wordpress.org/support/topic/how-to-block-semaltcom-from-visiting-your-wordpress-website\" target=\"_blank\">Wordpress Support Forum</a>.\n<h2>UPDATE:</h2>\nTo check the status of your site within the Selmalt crawler use this url but replace my URL with yours:\n<pre>http://semalt.semalt.com/crawler.php?u=http://brianchristner.io</pre>","html":"<p>I have noticed in all of my Wordpress sites over the last few months that a new referrer *.semalt.com keeps crawling my site. Usually I don't bother with most crawlers as they are indexing your site for the benefit of the internet right? <b>Wrong!</b></p>\n\n<p>It appears Semalt is indexing sites to collect backlinks and keywords to deliver more powerful sneaky spam techniques to use against your sites.  Unlike most crawlers on the internet Selmalt does not follow your robots.txt file. So even if you block it via your robots.txt file it will circumvent this rule and continue crawling your site. Well shit!</p>\n\n<p><a href=\"http://clicky.com/\" target=\"_blank\">Clicky</a> realtime web analytics announced on their Twitter they have now blocked Semalt.  Wordpress.com is also  </p>\n\n<blockquote class=\"twitter-tweet\" lang=\"en\">\"Visitors\" from <a href=\"http://t.co/E532GqJzYW\">http://t.co/E532GqJzYW</a> referrers are now ignored by default. See ya, spammers!\n\n— Clicky Web Analytics (@clicky) <a href=\"https://twitter.com/clicky/statuses/445704464750501890\">March 17, 2014</a></blockquote>\n\n<script src=\"//platform.twitter.com/widgets.js\" async=\"\" charset=\"utf-8\"></script>\n\n<p>OK enough with the blabbering. So how do I block these bastards from crawling my site?  </p>\n\n<h2>How to block Semalt.com from crawling your NGINX Wordpress site</h2>  \n\n<ol>  \n<ol>  \n<ol>  \n    <li style=\"text-align: left;\">You can try to Opt out of the samalt index but I am doubting this works (Bottom of the page) - <a title=\"Opt Out Semalt\" href=\"http://semalt.com/project_crawler.php\" target=\"_blank\">Opt Out Semalt</a></li>\n    <li style=\"text-align: left;\">Navigate to your NGINX sites-enabled directory.  Usually in /etc/nginx/sites-enabled</li>\n    <li>Open your domains config file in this directory</li>\n    <li>Add the below code to your domains config file.  If you want to add additional crawlers to this list separate the crawlers with a pipe ¦</li>\n</ol>  \n\n<p></ol> <br />\n</ol> <br />\n<code>if ($http<em>user</em>agent ~ \"semalt.com\") { </code></p>\n\n<p><code>return 403; </code></p>\n\n<p><code>break; </code></p>\n\n<p><code>}</code>  </p>\n\n<ol>  \n    <li>Once you have added the above code to your domain config file run a <strong><em>nginx -t </em></strong><em>(Tests your config)</em> to ensure that you made no typos in the file and that NGINX is happy with the new config</li>\n    <li>Once NGINX reports that everything is OK reload NGINX config files:</li>\n</ol>  \n\n<p><code>$service nginx reload</code> <br />\nIf your running an Apache Wordpress website check out  the <a href=\"http://wordpress.org/support/topic/how-to-block-semaltcom-from-visiting-your-wordpress-website\" target=\"_blank\">Wordpress Support Forum</a>.  </p>\n\n<h2>UPDATE:</h2>  \n\n<p>To check the status of your site within the Selmalt crawler use this url but replace my URL with yours:  </p>\n\n<pre>http://semalt.semalt.com/crawler.php?u=http://brianchristner.io</pre>","image":"/content/images/2014/08/block_semalt_wordpress_nginx.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to block Semalt.com from crawling your Wordpress site","meta_description":"Are you getting strange visits from Semalt.com in your Wordpress states? If so we explain how to block them from visiting in the future.","author_id":1,"created_at":1408434232000,"created_by":1,"updated_at":1430127390133,"updated_by":1,"published_at":1408434232000,"published_by":1},{"id":15,"uuid":"4db1c08e-6a27-4b59-a2d1-7256e64290b9","title":"How to Block Spammers based on keywords in NGINX","slug":"how-to-block-spammers-based-on-keywords-in-nginx","markdown":"It seems I spend most of my time moderating comments on my websites just to delete spam.  It is still a daily task which sometimes is amazing how much the [Wordpress Askimet](https://wordpress.org/plugins/akismet/) plugin catches.  It works amazingly well but it still requires time to sort through all the junk mail to ensure nothing was caught by accident.\n\nI stumbled across a feature in NGINX that helps you block website visitors based on the keywords they have in their HTTP header.  For example, if a spammer posts a comment about Viagra.  NGINX catches the keyword Viagra in the HTTP header and redirects the user to another page.\n\n**Brilliant right?**\n<h2>Steps for blocking Spam with NGINX</h2>\n<ul>\n\t<li>Navigate to your NGINX sites-enabled config file.  Usually located in: /etc/nginx/sites-enabled/&lt;config file name&gt;</li>\n\t<li>Edit the config file with your preferred editor</li>\n\t<li>Copy the below code to your config file:</li>\n</ul>\n`# Block HTTP Headers based on keywords and redirect to 403\nif ($http_referer ~* (viagra¦cialis¦levitra¦mulberry¦laurent) ) {\nreturn 403;\n}`\n<ul>\n\t<li>Modify the keywords to block specific keywords which are giving you trouble. Be sure to separate the keywords with a pipe ¦</li>\n\t<li>Save your changes</li>\n\t<li>Run the command <strong><em>nginx -t</em></strong> to test the config file for errors.  Only if it passes successfully should you continue to the next step.  If not go back to the config and fix the problems first</li>\n\t<li>Reload NGINX by running : <strong><em>service nginx reload</em></strong></li>\n</ul>","html":"<p>It seems I spend most of my time moderating comments on my websites just to delete spam.  It is still a daily task which sometimes is amazing how much the <a href=\"https://wordpress.org/plugins/akismet/\">Wordpress Askimet</a> plugin catches.  It works amazingly well but it still requires time to sort through all the junk mail to ensure nothing was caught by accident.</p>\n\n<p>I stumbled across a feature in NGINX that helps you block website visitors based on the keywords they have in their HTTP header.  For example, if a spammer posts a comment about Viagra.  NGINX catches the keyword Viagra in the HTTP header and redirects the user to another page.</p>\n\n<p><strong>Brilliant right?</strong></p>\n\n<h2>Steps for blocking Spam with NGINX</h2>  \n\n<ul>  \n    <li>Navigate to your NGINX sites-enabled config file.  Usually located in: /etc/nginx/sites-enabled/&lt;config file name&gt;</li>\n    <li>Edit the config file with your preferred editor</li>\n    <li>Copy the below code to your config file:</li>\n</ul>  \n\n<p><code># Block HTTP Headers based on keywords and redirect to 403\nif ($http_referer ~* (viagra¦cialis¦levitra¦mulberry¦laurent) ) { <br />\nreturn 403; <br />\n}</code></p>\n\n<ul>  \n    <li>Modify the keywords to block specific keywords which are giving you trouble. Be sure to separate the keywords with a pipe ¦</li>\n    <li>Save your changes</li>\n    <li>Run the command <strong><em>nginx -t</em></strong> to test the config file for errors.  Only if it passes successfully should you continue to the next step.  If not go back to the config and fix the problems first</li>\n    <li>Reload NGINX by running : <strong><em>service nginx reload</em></strong></li>\n</ul>","image":"/content/images/2014/08/block_nginx-website-spam.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1408515702000,"created_by":1,"updated_at":1421394203912,"updated_by":1,"published_at":1408515702000,"published_by":1},{"id":16,"uuid":"de7be8a8-3451-4001-a37c-d6b2249227b4","title":"Will WhatsApp Merge into Facebook Messenger?","slug":"will-whatsapp-merge-into-facebook-messeneger","markdown":"The entire tech community was up in arms with Facebook moving Facebook Messenger off to its own app recently. What people are failing to see is the future vision of Facebook Messenger. People have forgotten about the recent purchase of WhatsApp and how this is now a direct competitor of the Facebook Messenger.  \n\nWait, What!? Yes, you read that correctly. So why would Facebook design and release an application that would directly compete with a company they just purchased unless....  Unless Facebook plans to merge WhatsApp into Facebook Messenger.\n\nBefore Facebook purchased WhatsApp it was believed that the WhatsApp messages were encrypted between your cell phone and the WhatsApp servers. WhatsApp also claimed to never store messages on their servers thus making it very difficult for Facebook to advertise efficiently on the WhatsApp platform / monetize WhatsApp.  It is possible that since the Facebook aquistion that WhatsApp messages are now decoded by Facebook thus debunking this theory completely.  But read on as it may still happen.\n\nBy merging WhatsApp into the Facebook messenger not only will combine the two apps but joining users, additional cell phone data, and most importantly rip open the WhatsApp messages to be crawled by Facebook's Advertising engine.  Will we start seeing WhatsApp features slowly but steady move across to Facebook Messenger?\n\nIt doesn't make sense not to merge these two products and thus eliminating internal competition.  However, Facebook has already proven with Instagram that they will keep a product alive and slowly try monetize it.  But in WhatsApps case as mentioned above a merger could be the only means to monetize WhatsApp.  I hope I am wrong but this seems like the next logical step.","html":"<p>The entire tech community was up in arms with Facebook moving Facebook Messenger off to its own app recently. What people are failing to see is the future vision of Facebook Messenger. People have forgotten about the recent purchase of WhatsApp and how this is now a direct competitor of the Facebook Messenger.  </p>\n\n<p>Wait, What!? Yes, you read that correctly. So why would Facebook design and release an application that would directly compete with a company they just purchased unless....  Unless Facebook plans to merge WhatsApp into Facebook Messenger.</p>\n\n<p>Before Facebook purchased WhatsApp it was believed that the WhatsApp messages were encrypted between your cell phone and the WhatsApp servers. WhatsApp also claimed to never store messages on their servers thus making it very difficult for Facebook to advertise efficiently on the WhatsApp platform / monetize WhatsApp.  It is possible that since the Facebook aquistion that WhatsApp messages are now decoded by Facebook thus debunking this theory completely.  But read on as it may still happen.</p>\n\n<p>By merging WhatsApp into the Facebook messenger not only will combine the two apps but joining users, additional cell phone data, and most importantly rip open the WhatsApp messages to be crawled by Facebook's Advertising engine.  Will we start seeing WhatsApp features slowly but steady move across to Facebook Messenger?</p>\n\n<p>It doesn't make sense not to merge these two products and thus eliminating internal competition.  However, Facebook has already proven with Instagram that they will keep a product alive and slowly try monetize it.  But in WhatsApps case as mentioned above a merger could be the only means to monetize WhatsApp.  I hope I am wrong but this seems like the next logical step.</p>","image":"/content/images/2014/08/whatsapp_fb_messenger.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1409337428000,"created_by":1,"updated_at":1421394192044,"updated_by":1,"published_at":1409337428000,"published_by":1},{"id":17,"uuid":"c446d3a6-1134-4d7b-bd06-f592b499708d","title":"How to hide your Wordpress Login page","slug":"how-to-hide-your-wordpress-login-page","markdown":"It appears the amount of Brute Force password attacks is increasing exponentially lately. Several of my Wordpress sites have been getting hammered almost daily without fail.\n\nPreviously, we discussed <a style=\"color: #5597b2;\" href=\"http://brianchristner.io/secure-wordpress-site/\">how to secure your Wordpress site</a>.  But hackers are getting clever and we must stay in front of the ball in order to keep from getting knocked out of the game.\n\nAfter some investigation of what I could do to block would be hackers from attacking my site I went through a list of possibilities.\n<ol>\n\t<li> Add another Wordpress Plugin to add more security. <span style=\"color: #ff9900;\"><em>The downside is this could slow down my websites, another plugin to maintain, and it could just not work</em></span></li>\n\t<li>Create a Webserver level Password to block hackers.  <span style=\"color: #ff9900;\">Well this sounds good in principal but the hackers will just run their brute force password cracker on this password next.</span></li>\n\t<li><span style=\"color: #339966;\">So just like most spy movies is the term what people can't see they won't find.</span></li>\n</ol>\nSo number 3 is what I decided on. So by default and practically every Wordpress site on the internet the login page is in the default place (www.yourdomain.com/wp-admin). So why don't we move the \"wp-admin\" login page to another name? This not only makes your site a non-default installation but it will take a hacker a considerable more amount of time to find the new name of the login page. Kinda brilliant huh?\n\nFirst, I started hacking my webserver and changing things around when a lightbulb went off.  Yeah, hello! I asked myself? Stop trying to reinvent the wheel and look to see if someone else has already done the work.\n\nWell I found the plugin <a style=\"color: #5597b2;\" href=\"https://wordpress.org/plugins/rename-wp-login/\">rename wp-login.php</a>.  It works great.  I installed it and almost immediately my webserver logs went back to normal event traffic.  Wow what a relief.  So since renaming the wp-admin on my sites I have yet to receive an alert of a Brute Force attack.","html":"<p>It appears the amount of Brute Force password attacks is increasing exponentially lately. Several of my Wordpress sites have been getting hammered almost daily without fail.</p>\n\n<p>Previously, we discussed <a style=\"color: #5597b2;\" href=\"http://brianchristner.io/secure-wordpress-site/\">how to secure your Wordpress site</a>.  But hackers are getting clever and we must stay in front of the ball in order to keep from getting knocked out of the game.</p>\n\n<p>After some investigation of what I could do to block would be hackers from attacking my site I went through a list of possibilities.  </p>\n\n<ol>  \n    <li> Add another Wordpress Plugin to add more security. <span style=\"color: #ff9900;\"><em>The downside is this could slow down my websites, another plugin to maintain, and it could just not work</em></span></li>\n    <li>Create a Webserver level Password to block hackers.  <span style=\"color: #ff9900;\">Well this sounds good in principal but the hackers will just run their brute force password cracker on this password next.</span></li>\n    <li><span style=\"color: #339966;\">So just like most spy movies is the term what people can't see they won't find.</span></li>\n</ol>  \n\n<p>So number 3 is what I decided on. So by default and practically every Wordpress site on the internet the login page is in the default place (www.yourdomain.com/wp-admin). So why don't we move the \"wp-admin\" login page to another name? This not only makes your site a non-default installation but it will take a hacker a considerable more amount of time to find the new name of the login page. Kinda brilliant huh?</p>\n\n<p>First, I started hacking my webserver and changing things around when a lightbulb went off.  Yeah, hello! I asked myself? Stop trying to reinvent the wheel and look to see if someone else has already done the work.</p>\n\n<p>Well I found the plugin <a style=\"color: #5597b2;\" href=\"https://wordpress.org/plugins/rename-wp-login/\">rename wp-login.php</a>.  It works great.  I installed it and almost immediately my webserver logs went back to normal event traffic.  Wow what a relief.  So since renaming the wp-admin on my sites I have yet to receive an alert of a Brute Force attack.</p>","image":"/content/images/2014/Sep/cat-hiding.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1410292939000,"created_by":1,"updated_at":1430127296307,"updated_by":1,"published_at":1410292939000,"published_by":1},{"id":18,"uuid":"e49d88ff-ad79-433c-a25c-f5a019579997","title":"Migrating Wordpress to a Load Balanced Ghost Docker","slug":"migrating-from-wordpress-to-dockerized-ghost","markdown":"I am always stiving to be different and play with new technologies. So what is the next step? Well since Docker is the hot topic and I am keen to learn more so I decided to dive in head first.\n\nThis site BrianChrister.io is hosted with Digital Ocean on an Ubuntu droplet with NGINX and Wordpress on top. Nothing quite out of the ordinary besides making it a multi-site Wordpress with NGINX.\n\n<h2>The Mission</h2>\nBuild a [Docker](http://docker.com) based system that is load balanced behind a NGINX Proxy. Instead of migrating Wordpress into Docker containeres I decided to also switch to [Ghost CMS](https://github.com/tryghost/Ghost) as it is running Node.js and it seemed like a very interesting project.\n\n<h2>Getting from A --> B</h2>\nSo first we need to lay down the ground work. The great thing about Docker is the amount of pre-configured images available. Simply install them and BAM! You're running.\n\n1. I'm using Digital Ocean so I spun up a new Droplet with Docker already installed. So easy! If you don't have Digital Ocean which you should then [RTFM](https://docs.docker.com/installation/#installation)\n\n2. Install the NGINX proxy by typing `docker pull jwilder/nginx-proxy`\nThe image provided by [Jwilder](https://github.com/jwilder/nginx-proxy) is an amazing peice of kit. It is an NGINX reverse proxy that monitors docker containers via the API. Once a docker container starts with the -e VIRTUAL_HOST=www.example.com variable it assigns it to the proxy automagically.\n\n3. Once the image is installed fire it up. `docker run -d -p 80:80` \n`-v /var/run/docker.sock:/tmp/docker.sock` `jwilder/nginx-proxy` \n\n4. Next I installed the Docker Ghost image `docker pull dockerfile/ghost`\n\n5. Time to start firing up Ghost containers. `docker run -e VIRTUAL_HOST=www.example.com` \n`-v /localhost/directory --name container_name` \n`-d -p 49154:2368 -v ~/blog:/ghost-override dockerfile/ghost` which will pull the Ghost image from the registry and fire it up \n\n6. I then repeated step 5 and renamed the container and incremented the port number by 1. \n\nCheck out [Stack Overflow](http://stackoverflow.com/a/20652410) on how to configure your Ghost containter to store the data locally in a seperate Docker container.\n\n###Conclusion\nBam! Now you have 2 Docker containers load balanced behind a reverse proxy.","html":"<p>I am always stiving to be different and play with new technologies. So what is the next step? Well since Docker is the hot topic and I am keen to learn more so I decided to dive in head first.</p>\n\n<p>This site BrianChrister.io is hosted with Digital Ocean on an Ubuntu droplet with NGINX and Wordpress on top. Nothing quite out of the ordinary besides making it a multi-site Wordpress with NGINX.</p>\n\n<h2>The Mission</h2>  \n\n<p>Build a <a href=\"http://docker.com\">Docker</a> based system that is load balanced behind a NGINX Proxy. Instead of migrating Wordpress into Docker containeres I decided to also switch to <a href=\"https://github.com/tryghost/Ghost\">Ghost CMS</a> as it is running Node.js and it seemed like a very interesting project.</p>\n\n<h2>Getting from A --> B</h2>  \n\n<p>So first we need to lay down the ground work. The great thing about Docker is the amount of pre-configured images available. Simply install them and BAM! You're running.</p>\n\n<ol>\n<li><p>I'm using Digital Ocean so I spun up a new Droplet with Docker already installed. So easy! If you don't have Digital Ocean which you should then <a href=\"https://docs.docker.com/installation/#installation\">RTFM</a></p></li>\n<li><p>Install the NGINX proxy by typing <code>docker pull jwilder/nginx-proxy</code> <br />\nThe image provided by <a href=\"https://github.com/jwilder/nginx-proxy\">Jwilder</a> is an amazing peice of kit. It is an NGINX reverse proxy that monitors docker containers via the API. Once a docker container starts with the -e VIRTUAL_HOST=www.example.com variable it assigns it to the proxy automagically.</p></li>\n<li><p>Once the image is installed fire it up. <code>docker run -d -p 80:80</code> <br />\n<code>-v /var/run/docker.sock:/tmp/docker.sock</code> <code>jwilder/nginx-proxy</code> </p></li>\n<li><p>Next I installed the Docker Ghost image <code>docker pull dockerfile/ghost</code></p></li>\n<li><p>Time to start firing up Ghost containers. <code>docker run -e VIRTUAL_HOST=www.example.com</code> <br />\n<code>-v /localhost/directory --name container_name</code> \n<code>-d -p 49154:2368 -v ~/blog:/ghost-override dockerfile/ghost</code> which will pull the Ghost image from the registry and fire it up </p></li>\n<li><p>I then repeated step 5 and renamed the container and incremented the port number by 1. </p></li>\n</ol>\n\n<p>Check out <a href=\"http://stackoverflow.com/a/20652410\">Stack Overflow</a> on how to configure your Ghost containter to store the data locally in a seperate Docker container.</p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>Bam! Now you have 2 Docker containers load balanced behind a reverse proxy.</p>","image":"/content/images/2014/Sep/hostghost_logo_square.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1411579437677,"created_by":1,"updated_at":1430127338205,"updated_by":1,"published_at":1411675142913,"published_by":1},{"id":19,"uuid":"97758bdb-c3ba-41f2-a656-4f556c945433","title":"Updating your Docker for Shellshock","slug":"updating-your-docker-containers-for-shellshock","markdown":"What a week. Starting my workday early Thursday (25 September) morning I came across a Tweet from someone I follow that he spent the entire night updating his Linux systems. Hmmm this doesn't look good. After quickly getting up to speed with the [Shellshock Bug](http://www.troyhunt.com/2014/09/everything-you-need-to-know-about.html) it was time to make a plan.\n\n## Reviewing the Landscape\n\nI quickly evalutated all my webservers spread around the world and made a plan to update. Updating my webservers was relatively uneventful and fast but required quite sometime to ssh to each one and run the commands.\n\nSince my last article about launching a [Dockerized Blog](http://brianchristner.io/migrating-from-wordpress-to-dockerized-ghost/) solution this adds a new aspect to updating Docker for this Bash patch as I need to update the base Docker image.\n\nI have 3 Docker containers:\n1 x NGINX Proxy\n2 x Nodejs + Ghost CMS\n\n## How to update Docker Images & Containers\n\n\nWhat I did is deploy a new container for both the NGINX Proxy & Ghost CMS. I started both containers in interactive mode with /bin/bash enabled. I then updated Bash inside the containers, Committed the Container as a new image, and then deployed the new image.\n\nSo let's take a look at the process step-by-step:\n\n1. Deploy a new Docker container for both NGINX and Ghost\nNGINX -> `docker run -i -p 80:80 -v \\ /var/run/docker.sock:/tmp/docker.sock \\`\n`--name proxy jwilder/nginx-proxy /bin/bash`\nOnce the container is running and you are attached run: `apt-get update`\n`apt-get install --only-upgrade bash`\n2. Now repeat the process for the Ghost containers\nGhost ->`docker run -i -p 49157:2368 -v \\ \t\t\t\t/var/docker/directory_name:/ghost-override \\`\n`-e VIRTUAL_HOST=www.example.com \\`\n`dockerfile/ghost /bin/bash`\n`apt-get update`\n`apt-get install --only-upgrade bash`\n3. Next let's commit the containers as new Docker Images\n`docker commit -m\"Updated Bash\" -a=\"Brian\" \\`\n`proxy jwilder/nginx-proxy:v2`\n4. Repeat the process for Ghost image by changing the image and container names in the command.\n5. Stop the running containers for proxy and Ghost\n`docker stop proxy ghost1 ghost2`\n6. Deploy the newly created proxy container\n`docker run -i -p 80:80 -v \\ /var/run/docker.sock:/tmp/docker.sock \\`\n`--name proxy jwilder/nginx-proxy:v2 forego start -r`\n7. Same for the Ghost image\n`docker run -i -p 49157:2368 -v \\ \t\t\t\t/var/docker/directory_name:/ghost-override \\`\n`-e VIRTUAL_HOST=www.example.com \\`\n`dockerfile/ghost bash /ghost-start`\n\nHappy Dockering!\n","html":"<p>What a week. Starting my workday early Thursday (25 September) morning I came across a Tweet from someone I follow that he spent the entire night updating his Linux systems. Hmmm this doesn't look good. After quickly getting up to speed with the <a href=\"http://www.troyhunt.com/2014/09/everything-you-need-to-know-about.html\">Shellshock Bug</a> it was time to make a plan.</p>\n\n<h2 id=\"reviewingthelandscape\">Reviewing the Landscape</h2>\n\n<p>I quickly evalutated all my webservers spread around the world and made a plan to update. Updating my webservers was relatively uneventful and fast but required quite sometime to ssh to each one and run the commands.</p>\n\n<p>Since my last article about launching a <a href=\"http://brianchristner.io/migrating-from-wordpress-to-dockerized-ghost/\">Dockerized Blog</a> solution this adds a new aspect to updating Docker for this Bash patch as I need to update the base Docker image.</p>\n\n<p>I have 3 Docker containers: <br />\n1 x NGINX Proxy <br />\n2 x Nodejs + Ghost CMS</p>\n\n<h2 id=\"howtoupdatedockerimagescontainers\">How to update Docker Images &amp; Containers</h2>\n\n<p>What I did is deploy a new container for both the NGINX Proxy &amp; Ghost CMS. I started both containers in interactive mode with /bin/bash enabled. I then updated Bash inside the containers, Committed the Container as a new image, and then deployed the new image.</p>\n\n<p>So let's take a look at the process step-by-step:</p>\n\n<ol>\n<li>Deploy a new Docker container for both NGINX and Ghost <br />\nNGINX -> <code>docker run -i -p 80:80 -v \\ /var/run/docker.sock:/tmp/docker.sock \\</code> <br />\n<code>--name proxy jwilder/nginx-proxy /bin/bash</code>\nOnce the container is running and you are attached run: <code>apt-get update</code> <br />\n<code>apt-get install --only-upgrade bash</code></li>\n<li>Now repeat the process for the Ghost containers <br />\nGhost -><code>docker run -i -p 49157:2368 -v \\                 /var/docker/directory_name:/ghost-override \\</code> <br />\n<code>-e VIRTUAL_HOST=www.example.com \\</code>\n<code>dockerfile/ghost /bin/bash</code>\n<code>apt-get update</code>\n<code>apt-get install --only-upgrade bash</code></li>\n<li>Next let's commit the containers as new Docker Images <br />\n<code>docker commit -m\"Updated Bash\" -a=\"Brian\" \\</code>\n<code>proxy jwilder/nginx-proxy:v2</code></li>\n<li>Repeat the process for Ghost image by changing the image and container names in the command.  </li>\n<li>Stop the running containers for proxy and Ghost <br />\n<code>docker stop proxy ghost1 ghost2</code></li>\n<li>Deploy the newly created proxy container <br />\n<code>docker run -i -p 80:80 -v \\ /var/run/docker.sock:/tmp/docker.sock \\</code>\n<code>--name proxy jwilder/nginx-proxy:v2 forego start -r</code></li>\n<li>Same for the Ghost image <br />\n<code>docker run -i -p 49157:2368 -v \\                 /var/docker/directory_name:/ghost-override \\</code>\n<code>-e VIRTUAL_HOST=www.example.com \\</code>\n<code>dockerfile/ghost bash /ghost-start</code></li>\n</ol>\n\n<p>Happy Dockering!</p>","image":"/content/images/2014/Sep/shellshock.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1411732498995,"created_by":1,"updated_at":1430127248099,"updated_by":1,"published_at":1411737295903,"published_by":1},{"id":20,"uuid":"e078fbbf-edc5-4d40-9a0e-5b596f9d500f","title":"vCloud ISO Images Appear with Question Marks","slug":"vcloud-iso-images-appear-with-question-marks","markdown":"![](/content/images/2014/Oct/unknown_iso_vcloud.jpg)\n <--This issue drove me nuts this week. Someone uploaded a bunch of ISO images with vCloud Director 5.5. The ISO's images uploaded fine but some images appeared as normal and others appeared as icons with a question mark that are unmountable on VM's. WTF?\n\nSo I tried a couple things. I noticed that the ISO images were missing the .iso file extension. I tried renaming the ISO images through vCloud. No Love!\n\n## How to fix Unknown ISO files in vCloud\n\nIn order to fix this annoying issue ensure your ISO images have the .iso extension **before uploading**. vCloud 5.1 and lowerer this was not an issue and vCloud automatically recognized the file type. Now we must tell it before the upload.","html":"<p><img src=\"/content/images/2014/Oct/unknown_iso_vcloud.jpg\" alt=\"\" />\n &lt;--This issue drove me nuts this week. Someone uploaded a bunch of ISO images with vCloud Director 5.5. The ISO's images uploaded fine but some images appeared as normal and others appeared as icons with a question mark that are unmountable on VM's. WTF?</p>\n\n<p>So I tried a couple things. I noticed that the ISO images were missing the .iso file extension. I tried renaming the ISO images through vCloud. No Love!</p>\n\n<h2 id=\"howtofixunknownisofilesinvcloud\">How to fix Unknown ISO files in vCloud</h2>\n\n<p>In order to fix this annoying issue ensure your ISO images have the .iso extension <strong>before uploading</strong>. vCloud 5.1 and lowerer this was not an issue and vCloud automatically recognized the file type. Now we must tell it before the upload.</p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1414058058841,"created_by":1,"updated_at":1421394125147,"updated_by":1,"published_at":1414059528807,"published_by":1},{"id":21,"uuid":"76af8189-02f1-4349-a0fc-0c0668ad9065","title":"Upgrading Docker Containers running Ghost CMS","slug":"upgrading-ghost-to-0-5-3-with-docker","markdown":"\n\n##The next step with Ghost\nThe [Ghost](https://github.com/TryGhost/Ghost/releases) crew released a new version of the Ghost CMS system which is 0.5.3. This release includes some nice to have features seen below. So the next question is how difficult is it to upgrade Ghost while running on Docker? Well it is so simple I had to go back and check twice to make sure I didn't miss anything.\n\n## Upgrading Docker Container to Ghost 0.5.3\nSince Ghost is a maintained image in the [Docker Repository](https://registry.hub.docker.com/u/dockerfile/ghost/) it makes life a lot easier. In my current setup I have 2 containers running behind a NGINX proxy container. Take a look at my [Ghost setup post](http://brianchristner.io/migrating-from-wordpress-to-dockerized-ghost/) for a better understanding. \n\nThe first step we need to download the latest version of the Ghost image.\n1. `docker pull dockerfile/ghost`\n2. start the new image  `docker run -d -p 49150:2368 -v /var/docker/b2:/ghost-override -e ` `VIRTUAL_HOST=www.yourdomain.com,yourdomain.com --name` `image_name dockerfile/ghost:latest bash /ghost-start`\n3. Stop the old Ghost instances `docker stop ghost1 ghost2`\n4. Start additonal containers if you want load balancing.\n\nDone! Yes, that is all. Be sure to due some housekeeping and delete the all Ghost containers so you won't start them later by accident.\n\n\n##Ghost 0.5.3 Release Highlights\n\n* **New** Post Auto Save\n* **New** Structured data (open graph, twitter cards)\n* **New** GMail-style shortcuts\n* **Fixed** Themes not working correctly with symlinks\n* **Fixed** User screen limited to 20 users\n* **Fixed** Next & prev meta links don't get HTTPS","html":"<h2 id=\"thenextstepwithghost\">The next step with Ghost</h2>\n\n<p>The <a href=\"https://github.com/TryGhost/Ghost/releases\">Ghost</a> crew released a new version of the Ghost CMS system which is 0.5.3. This release includes some nice to have features seen below. So the next question is how difficult is it to upgrade Ghost while running on Docker? Well it is so simple I had to go back and check twice to make sure I didn't miss anything.</p>\n\n<h2 id=\"upgradingdockercontainertoghost053\">Upgrading Docker Container to Ghost 0.5.3</h2>\n\n<p>Since Ghost is a maintained image in the <a href=\"https://registry.hub.docker.com/u/dockerfile/ghost/\">Docker Repository</a> it makes life a lot easier. In my current setup I have 2 containers running behind a NGINX proxy container. Take a look at my <a href=\"http://brianchristner.io/migrating-from-wordpress-to-dockerized-ghost/\">Ghost setup post</a> for a better understanding. </p>\n\n<p>The first step we need to download the latest version of the Ghost image. <br />\n1. <code>docker pull dockerfile/ghost</code> <br />\n2. start the new image  <code>docker run -d -p 49150:2368 -v /var/docker/b2:/ghost-override -e</code> <code>VIRTUAL_HOST=www.yourdomain.com,yourdomain.com --name</code> <code>image_name dockerfile/ghost:latest bash /ghost-start</code> <br />\n3. Stop the old Ghost instances <code>docker stop ghost1 ghost2</code> <br />\n4. Start additonal containers if you want load balancing.</p>\n\n<p>Done! Yes, that is all. Be sure to due some housekeeping and delete the all Ghost containers so you won't start them later by accident.</p>\n\n<h2 id=\"ghost053releasehighlights\">Ghost 0.5.3 Release Highlights</h2>\n\n<ul>\n<li><strong>New</strong> Post Auto Save</li>\n<li><strong>New</strong> Structured data (open graph, twitter cards)</li>\n<li><strong>New</strong> GMail-style shortcuts</li>\n<li><strong>Fixed</strong> Themes not working correctly with symlinks</li>\n<li><strong>Fixed</strong> User screen limited to 20 users</li>\n<li><strong>Fixed</strong> Next &amp; prev meta links don't get HTTPS</li>\n</ul>","image":"/content/images/2014/11/ghost_cms.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"Upgrading Docker Containers running Ghost CMS","meta_description":"How to upgrade a Docker container running Ghost to 0.5.3","author_id":1,"created_at":1415210017202,"created_by":1,"updated_at":1421393025056,"updated_by":1,"published_at":1415216612382,"published_by":1},{"id":22,"uuid":"53cfdecf-b65f-4877-8e69-36f42c06df8b","title":"Countdown to 3 Startup Launches!","slug":"countdown-to-3-startup-launches","markdown":"With the upcoming Christmas Holidays I've already set a very sporty goal for myself. I plan on launching 3 different startups before the end of the Christmas break. Enough of the sitting around dreaming of something to launch. I'm going to pull the trigger and force myself to launch and set the countdown in motion.\n\nMy inspiration comes from Pieter Levels from [Levels.io](http://www.Levels.io) and [Bootstrappers.io](http://www.Bootstrappers.io). Pieter kicked off his own personal challenge of launching 12 Startups in 12 Months and so far he is doing quite well with it. I've come to like Pieters clear way of explaining his process and the methods he used to launch. I'm not sure what website lead me to Pieter but this particular post is what motivated me to launch on my own [How I build Minimum Viable Products](https://levels.io/how-i-build-my-minimum-viable-products/).\n\n##What I'm going to Launch\n\nSo I am busy preparing ahead of time Minimum Viable Products (MVP) for each of the three products. I've already begun validating with professionals in each segment. Although these are projects and not businesses who knows one might gain traction and become popular. That is why I am spreading my launch across three MVP's in 3 different segments.\n\nI will send out a Tweet once a landing page is in place for the different pages.\n\n**InstaGP** - A mashup of Instagram and Twitter for Sporting events\n\n**WebWrench** - An Analytics Tool for Small Businesses\n\n**Hashtag Haters** - A site tracking funny Hashtags submitting & voting up/down HashTags\n\n##Why Launch?\nSo why would I lanunch anything? Well I it forces me to do a couple things.\n\n* Build an MVP\n* Understand Lean Startup Processes\n* Increase my exposure to the Instragram & Twitter API's\n* Experience a product launch\n\n\n##When is the Launch?\nThe countdown is on. So when is the launch? I set the Launch date for January 2, 2015. It's a Friday, New Year, and a good time to have everything ready before people get back to the first full week of 2015. \n\n\n\n","html":"<p>With the upcoming Christmas Holidays I've already set a very sporty goal for myself. I plan on launching 3 different startups before the end of the Christmas break. Enough of the sitting around dreaming of something to launch. I'm going to pull the trigger and force myself to launch and set the countdown in motion.</p>\n\n<p>My inspiration comes from Pieter Levels from <a href=\"http://www.Levels.io\">Levels.io</a> and <a href=\"http://www.Bootstrappers.io\">Bootstrappers.io</a>. Pieter kicked off his own personal challenge of launching 12 Startups in 12 Months and so far he is doing quite well with it. I've come to like Pieters clear way of explaining his process and the methods he used to launch. I'm not sure what website lead me to Pieter but this particular post is what motivated me to launch on my own <a href=\"https://levels.io/how-i-build-my-minimum-viable-products/\">How I build Minimum Viable Products</a>.</p>\n\n<h2 id=\"whatimgoingtolaunch\">What I'm going to Launch</h2>\n\n<p>So I am busy preparing ahead of time Minimum Viable Products (MVP) for each of the three products. I've already begun validating with professionals in each segment. Although these are projects and not businesses who knows one might gain traction and become popular. That is why I am spreading my launch across three MVP's in 3 different segments.</p>\n\n<p>I will send out a Tweet once a landing page is in place for the different pages.</p>\n\n<p><strong>InstaGP</strong> - A mashup of Instagram and Twitter for Sporting events</p>\n\n<p><strong>WebWrench</strong> - An Analytics Tool for Small Businesses</p>\n\n<p><strong>Hashtag Haters</strong> - A site tracking funny Hashtags submitting &amp; voting up/down HashTags</p>\n\n<h2 id=\"whylaunch\">Why Launch?</h2>\n\n<p>So why would I lanunch anything? Well I it forces me to do a couple things.</p>\n\n<ul>\n<li>Build an MVP</li>\n<li>Understand Lean Startup Processes</li>\n<li>Increase my exposure to the Instragram &amp; Twitter API's</li>\n<li>Experience a product launch</li>\n</ul>\n\n<h2 id=\"whenisthelaunch\">When is the Launch?</h2>\n\n<p>The countdown is on. So when is the launch? I set the Launch date for January 2, 2015. It's a Friday, New Year, and a good time to have everything ready before people get back to the first full week of 2015. </p>","image":"/content/images/2014/11/snoopy_rocket_launch-1.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"Countdown to 3 Startup Launches","meta_description":"Here's the beginning on my road to launching 3 startups before the end of the 2014 Christmas holiday. Join me in my journey of bootstrapping 3 startups.","author_id":1,"created_at":1416387759967,"created_by":1,"updated_at":1420072050415,"updated_by":1,"published_at":1416398460000,"published_by":1},{"id":23,"uuid":"2d65bfa5-d6de-4b51-9982-588a8436c591","title":"InstaGP Time to Pivot","slug":"instagp-time-to-pivot","markdown":"After my initial post of 3 Startups before the end of the year I already have an update. Like lots of tech companies a pivot was definitely going to occur. Well I certainly didn’t expect a pivot so early on.\n\nI started working on InstaGP the Instagram + MotoGP (Motorcycle Racing) mashup. Initially I was going to pull pictures from Instagram based on time and location. Based on this information it was planned to take these pictures + locations and overlay them on top of the particular race track. Well that was the plan...\n\nSo what happened? I created a wireframe of what I wanted to build for InstaGP and the integration between InstaGP and the Instagram API. Before I wrote the first line of code, I decided to test the API to find out exactly what I could retrieve from the API. The results blew my plan for InstaGP right out of the water. When I queried the Instagram API for a particular race track location just for MotoGP related pictures the amount of pictures returned were almost nothing. After doing a few more queries I quickly realized most MotoGP related pictures have no location assigned at all. Searching by the Tag name “MotoGP” or riders names like \"Valentino Rossi\" or \"Nicky Hayden\" returned all sorts of crazy results with some pictures not even MotoGP or motorcycle racing related.\n\nThe common term used in the startup world for such occasions is a pivot or change of direction which is exactly what was needed. I’ve pivoted my initial plan to the next phase. I’ve decided to build InstaGP pivot as follows:\n\n* Create a website which acts as a portal for gathering all the social media for all MotoGP riders, teams, and tracks. The initial release will contain just Instagram feeds per rider, team, or track.\n\n* Release 2 (January 2015) will integrate Twitter and Facebook feeds although I’m not convinced about Facebook.\n\n* Release 3 (February 2015) will provided a Most Popular Tweets or Instagram Images category from all rider feeds. Basically displaying the most popular picture or tweets from all the pictures or Tweets.\n\nStill lots of work to do but so far I’m very happy with the progress. But the end of the year is quickly approaching. Yikes!\n","html":"<p>After my initial post of 3 Startups before the end of the year I already have an update. Like lots of tech companies a pivot was definitely going to occur. Well I certainly didn’t expect a pivot so early on.</p>\n\n<p>I started working on InstaGP the Instagram + MotoGP (Motorcycle Racing) mashup. Initially I was going to pull pictures from Instagram based on time and location. Based on this information it was planned to take these pictures + locations and overlay them on top of the particular race track. Well that was the plan...</p>\n\n<p>So what happened? I created a wireframe of what I wanted to build for InstaGP and the integration between InstaGP and the Instagram API. Before I wrote the first line of code, I decided to test the API to find out exactly what I could retrieve from the API. The results blew my plan for InstaGP right out of the water. When I queried the Instagram API for a particular race track location just for MotoGP related pictures the amount of pictures returned were almost nothing. After doing a few more queries I quickly realized most MotoGP related pictures have no location assigned at all. Searching by the Tag name “MotoGP” or riders names like \"Valentino Rossi\" or \"Nicky Hayden\" returned all sorts of crazy results with some pictures not even MotoGP or motorcycle racing related.</p>\n\n<p>The common term used in the startup world for such occasions is a pivot or change of direction which is exactly what was needed. I’ve pivoted my initial plan to the next phase. I’ve decided to build InstaGP pivot as follows:</p>\n\n<ul>\n<li><p>Create a website which acts as a portal for gathering all the social media for all MotoGP riders, teams, and tracks. The initial release will contain just Instagram feeds per rider, team, or track.</p></li>\n<li><p>Release 2 (January 2015) will integrate Twitter and Facebook feeds although I’m not convinced about Facebook.</p></li>\n<li><p>Release 3 (February 2015) will provided a Most Popular Tweets or Instagram Images category from all rider feeds. Basically displaying the most popular picture or tweets from all the pictures or Tweets.</p></li>\n</ul>\n\n<p>Still lots of work to do but so far I’m very happy with the progress. But the end of the year is quickly approaching. Yikes!</p>","image":"/content/images/2014/11/Change-Direction.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"InstaGP Time to Pivot","meta_description":"As is the case with most star-ups a Pivot is surely in their future. InstaGP pivoted to a new MotoGP riders portal with much more planned.","author_id":1,"created_at":1416772979899,"created_by":1,"updated_at":1421394061027,"updated_by":1,"published_at":1417077938175,"published_by":1},{"id":24,"uuid":"23f6f02a-4c7e-40ac-8e2c-a3199e9ec348","title":"First Project Launched - InstaGP","slug":"first-project-launched-instagp","markdown":"![](http://)\nIt's been quite a ride to get to this point. After the first [InstaGP Pivot](http://brianchristner.io/instagp-time-to-pivot/) until now it's been a lot of time coding and trial and error. I quite enjoyed the project and learned a ton about the Instagram API and Twiiter Bootstrap. Will it gain traction and become popular during MotoGP season? Only time will tell.\n\nI launched the MVP(Minimum Viable Product) for [InstaGP](http://www.instagp.com) on 5 December. I decided to keep the functionality to a minimum of just the rider profiles. I will then analyze the Analytics to see which other componets of InstaGP is interesting for viewers like tracks or teams. If enough interest for either tracks or teams is realized then I will build out these features. Until then I will continue monitoring the sites progress and polish the site for the 2015 MotoGP Season.\n\n##Second Startup MVP\nSo what's next? I will now start the Second Startup MVP for Hashtag Haters. I'm now busy hashing out(no pun intended) the design and functionality of HH. I'm still not sure the direction I will go with HH but I'm certain I will again use Twitter Bootstrap as a basis. Stay tuned for HH updates.","html":"<p><img src=\"http://\" alt=\"\" />\nIt's been quite a ride to get to this point. After the first <a href=\"http://brianchristner.io/instagp-time-to-pivot/\">InstaGP Pivot</a> until now it's been a lot of time coding and trial and error. I quite enjoyed the project and learned a ton about the Instagram API and Twiiter Bootstrap. Will it gain traction and become popular during MotoGP season? Only time will tell.</p>\n\n<p>I launched the MVP(Minimum Viable Product) for <a href=\"http://www.instagp.com\">InstaGP</a> on 5 December. I decided to keep the functionality to a minimum of just the rider profiles. I will then analyze the Analytics to see which other componets of InstaGP is interesting for viewers like tracks or teams. If enough interest for either tracks or teams is realized then I will build out these features. Until then I will continue monitoring the sites progress and polish the site for the 2015 MotoGP Season.</p>\n\n<h2 id=\"secondstartupmvp\">Second Startup MVP</h2>\n\n<p>So what's next? I will now start the Second Startup MVP for Hashtag Haters. I'm now busy hashing out(no pun intended) the design and functionality of HH. I'm still not sure the direction I will go with HH but I'm certain I will again use Twitter Bootstrap as a basis. Stay tuned for HH updates.</p>","image":"/content/images/2014/12/phase2-1.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"First Project Launched - InstaGP","meta_description":"The Launch of InstaGP has been an awesome experience. Now Phase 2 will be the launch of Hashtag Haters for the 3 Startups before the end of 2015 project.","author_id":1,"created_at":1417768346233,"created_by":1,"updated_at":1421394048351,"updated_by":1,"published_at":1417985733678,"published_by":1},{"id":25,"uuid":"5e8f752e-d5e0-4e6d-b816-39557017ffb5","title":"2014 in Review and Goals for 2015","slug":"2014-in-review-and-goals-for-2015","markdown":"Wow what a year 2014 was. It had many up's and down's but had a lot of great accomplishments and moments. I'm happy to have completed so many goals this year but I want to continue my progress in 2015. My ToDo list for 2015 is big and and quite venturesome.\n\n##2014 in Review\n* One of my goals for 2014 was moving all of my websites to Digital Ocean. This was probably the start of many other projects I undertook. I am still really happy with the performance and Digital Oceans support and features.\n* NGNIX was a huge goal for me. Not only did I convert all my websites to NGINX but also have it running as a load balanced proxy running in Docker.\n* Docker was still relatively new the beginning of last year. I wanted to learn as much as possible about the technology and build several projects with it. I not only built all my new projects with Docker but gave a couple Docker presentations as well.\n* I challenged myself to 3 Startups before Jan 5, 2015. So far I have completed 2 and the 3rd one is almost complete. I'm very happy with the challenge and will be challenging myself with more for 2015.\n* Attend more German classes. My level of German has vastly improved but still has a long way to go.\n* Fitness was a huge goal for me in 2014. Unfortunately the summer was rained out so I was not able to get on my Mountain Bike as much as I would've liked but I hit the gym frequently and I'm happy with the results. \n\n##2015 Goals\nSince writing the article about building 3 startups I found it was extremly motivating to publish my goals. So here it goes again for 2015.\n\n* Ride the Zugerberg Classic Mountain Bike race.\n* Continue my fitness regime and start counting calories to limit myself to 2750 per day until I reach my target weight and waist size.\n* Write 3 blog posts per week\n* Learn and Master Cloud Foundry\n* Take online courses in Finance and Trading\n* Take online refresher courses in Javascript.\n* Launch more projects. As I started the 3 Startup challenge I want to conitune launching new products & services.\n* Build more projects with Docker\n* Continue improving my German. This seems to be a never ending goal\n\nI'm already looking forward to tackle this list. I hope you make 2015 a memorable one!","html":"<p>Wow what a year 2014 was. It had many up's and down's but had a lot of great accomplishments and moments. I'm happy to have completed so many goals this year but I want to continue my progress in 2015. My ToDo list for 2015 is big and and quite venturesome.</p>\n\n<h2 id=\"2014inreview\">2014 in Review</h2>\n\n<ul>\n<li>One of my goals for 2014 was moving all of my websites to Digital Ocean. This was probably the start of many other projects I undertook. I am still really happy with the performance and Digital Oceans support and features.</li>\n<li>NGNIX was a huge goal for me. Not only did I convert all my websites to NGINX but also have it running as a load balanced proxy running in Docker.</li>\n<li>Docker was still relatively new the beginning of last year. I wanted to learn as much as possible about the technology and build several projects with it. I not only built all my new projects with Docker but gave a couple Docker presentations as well.</li>\n<li>I challenged myself to 3 Startups before Jan 5, 2015. So far I have completed 2 and the 3rd one is almost complete. I'm very happy with the challenge and will be challenging myself with more for 2015.</li>\n<li>Attend more German classes. My level of German has vastly improved but still has a long way to go.</li>\n<li>Fitness was a huge goal for me in 2014. Unfortunately the summer was rained out so I was not able to get on my Mountain Bike as much as I would've liked but I hit the gym frequently and I'm happy with the results. </li>\n</ul>\n\n<h2 id=\"2015goals\">2015 Goals</h2>\n\n<p>Since writing the article about building 3 startups I found it was extremly motivating to publish my goals. So here it goes again for 2015.</p>\n\n<ul>\n<li>Ride the Zugerberg Classic Mountain Bike race.</li>\n<li>Continue my fitness regime and start counting calories to limit myself to 2750 per day until I reach my target weight and waist size.</li>\n<li>Write 3 blog posts per week</li>\n<li>Learn and Master Cloud Foundry</li>\n<li>Take online courses in Finance and Trading</li>\n<li>Take online refresher courses in Javascript.</li>\n<li>Launch more projects. As I started the 3 Startup challenge I want to conitune launching new products &amp; services.</li>\n<li>Build more projects with Docker</li>\n<li>Continue improving my German. This seems to be a never ending goal</li>\n</ul>\n\n<p>I'm already looking forward to tackle this list. I hope you make 2015 a memorable one!</p>","image":"/content/images/2015/01/2015-1.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"2014 in Review and Goals for 2015","meta_description":"Time to track our 2014 progress and make resolutions for 2015.","author_id":1,"created_at":1420111170217,"created_by":1,"updated_at":1421394031329,"updated_by":1,"published_at":1420154747172,"published_by":1},{"id":26,"uuid":"84c855fe-06b0-4783-a124-311566cdf1b3","title":"Luck has nothing to do with it!","slug":"luck-has-nothing-to-do-with-it","markdown":"The Casino Floor was my home for the best part of 10 years. I lived in Las Vegas and worked for a Slot Machine manufacture as a Casino Systems Engineer. This work required me to work in a variety of casinos in Las Vegas and around the United States. Eventually I moved to Europe where I also worked in Casinos around Europe and the World. But the questions from every player (punter) remained the same. \n\n* *Which machine is lucky?*\n* *What's the secret to winning?*\n* *Did you program a secret code into a machine?*\n* *How do I win?*\n\nMy answer was and still is *Luck has nothing to do with it!*. Slot machines are programmed computers that are designed to seperate you from your money as quickly as possible without it appearing like you lost. Slot machines are programmed with a [PAR or Hold percentage](http://http://en.wikipedia.org/wiki/Slot_machine#Payout_percentage) checkout Wikipedia's defintion on exactly how it works. This means a mathmatical algorithm determines the outcome of the slot machine. Over the lifetime of the machine the casino know's approximately how much money this machine should make for the casino. So the casino already knows what the machine is supposed to do. That's not luck!\n\n\n##History of the Slot Machine\nThis is not a history lesson on the evolution of the slot machine itself from mechanical to today's network connected computer. This is the history of how Slot Machines evolved to separate you from your money faster and more effeciently.\n\n* **Tokens/Coins** - The first step in gambling is inserting money into the slot machine. The first method that was used on Slot Machines were the coin/token acceptors. The introduction of these acceptors revolutionized the Slot Machine and helped create what they are today. However as time went on it was quickly realized that players cannot insert money very quickly which slows down game play as well as profits for the casinos.\n\n* **Bill Acceptors** - Bill acceptors also doubled, tripled, and even blew the tops off casinos with profit gains. Now players can insert a currency note into a slot machine and play off the credits. This not only increased the amount of games played per minute but also the Casino's bottom line. This led to yet another shortfall. If a customer wished to change machines or cashout they had to wait for the slot machine to spit out your winnings in coins which depending on the amount, lasted sometime or worse yet the machine was empty or didn't have enough coins and was locked waiting for someone to come pay the winnings. This reduced games played per minute and effected casino profits while the players were waiting instead of playing.\n\n* **Tickets** - Tickets were introduced circa 2002. Ticket-in/Ticket-out allowed players to easily cashout their winnings move to another machine and continue playing quickly & easily. This not only reduced casino staff but increased casino revenues once again and increase the amount of games played per minute that players could play. Ticketing is still used around the world today and is considered a necessity for today's slot machines.\n\n* **Smart Cards** - Although Smart Cards were introduced before Tickets it was not as widely accepted as tickets. The early Smart Card systems were slow, unreliable, and customers didn't trust their money on cards. Smart Cards are still being used but not nearly widely accepted as ticketing.\n\n* **Loyalty Cards/Bonusing** - Now the boom of loyalty cards have somewhat replaced Smart Cards. Players accumulate points with a players card which can then be converted to credits on a machine. Better yet the loyalty card also allow you to win seperate winnings that are stored on your account and can easily transfer to other machines.\n\n##The Psychology of a slot machine\nSlot machines have been designed to make the player as comfortable as possible. The seating positon, graphics, and even the sound of the machine is tuned to appeal to the player. I've even experienced some machines that emitted an aroma to attract players(this didn't work). \n\nAs I've traveled the world it came to my attention that certain cultures gravatate to certain slot machine themed games. Like Cleopatra/Egyptian themed games are a huge hit in southern Europe, Gold Mining & TV Shows themes in the United States, and dragon and Asian themed games obviously are big in Asia. Not only the design of the machine is taken into consideration but also the location of the casino. All of these stastics are recorded and used to develop new games and features to better attrack more players.\n\n##Present Day Casinos\nToday casinos can change every aspect of a casino floor in a moments notice. Server Based Gaming was introduced a few years ago and has been spreading like wild fire across the world. This enables a casino to change par/hold percentages, game themes, and even machine configurations on the fly. \n\nA casino can change their games and configuration of the casino floor for an upcoming weekend tighter (less winning) then loosen them back up during the week (more winning) to adapt to the clientele and attrack customers during off peak hours all from the click of a mouse button. As more data is collected by casino's they create better marketing campaigns, analyze slot machine performance, and player tendacies all to tune the casino floor better for the best revenue optimization. This is all done every time you spin the wheels of a machine.\n\n##How to win playing slot machines\nSo back to one of the original question of how do I win? Well that's easy. Keep your money in your pocket and head home. But if you ignore this advice here are some tips on winning at the slots. Remember one thing, Las Vegas was built by a bunch of losers not by a bunch of winners.\n\n* **Play Video Poker** - Video Poker has the best odds on the casino floor. However Poker also requires the players input. So you may throw away a Royal Flush (Seen it happen) because you never knew you had one.\n\n* **Always play Max Bet / Cover all Lines** - I cannot say this one loud enough. If you don't play Max Bet and cover all the lines you will never hit the big payouts. It is also very common that Bets other than Max Bet have worse odds.\n\n* **The End Game** - Many times casinos will configure a bank of machines with the ends as the highest paying and the middle less so. It is also possible that machines in the back of the casino have better payouts than those at the front. However this tip is set on a per casino basis.\n\n* **Become friends with slot attendants** - Although they cannot tell you which machine to play. They can tell you which machines they visit more often than others. If they don't tell you then pull a seat up at the bar and watch which machines they visit. If you see a pattern develop you may want to head over to those machines.\n\nGood luck losing your money!","html":"<p>The Casino Floor was my home for the best part of 10 years. I lived in Las Vegas and worked for a Slot Machine manufacture as a Casino Systems Engineer. This work required me to work in a variety of casinos in Las Vegas and around the United States. Eventually I moved to Europe where I also worked in Casinos around Europe and the World. But the questions from every player (punter) remained the same. </p>\n\n<ul>\n<li><em>Which machine is lucky?</em></li>\n<li><em>What's the secret to winning?</em></li>\n<li><em>Did you program a secret code into a machine?</em></li>\n<li><em>How do I win?</em></li>\n</ul>\n\n<p>My answer was and still is <em>Luck has nothing to do with it!</em>. Slot machines are programmed computers that are designed to seperate you from your money as quickly as possible without it appearing like you lost. Slot machines are programmed with a <a href=\"http://http://en.wikipedia.org/wiki/Slot_machine#Payout_percentage\">PAR or Hold percentage</a> checkout Wikipedia's defintion on exactly how it works. This means a mathmatical algorithm determines the outcome of the slot machine. Over the lifetime of the machine the casino know's approximately how much money this machine should make for the casino. So the casino already knows what the machine is supposed to do. That's not luck!</p>\n\n<h2 id=\"historyoftheslotmachine\">History of the Slot Machine</h2>\n\n<p>This is not a history lesson on the evolution of the slot machine itself from mechanical to today's network connected computer. This is the history of how Slot Machines evolved to separate you from your money faster and more effeciently.</p>\n\n<ul>\n<li><p><strong>Tokens/Coins</strong> - The first step in gambling is inserting money into the slot machine. The first method that was used on Slot Machines were the coin/token acceptors. The introduction of these acceptors revolutionized the Slot Machine and helped create what they are today. However as time went on it was quickly realized that players cannot insert money very quickly which slows down game play as well as profits for the casinos.</p></li>\n<li><p><strong>Bill Acceptors</strong> - Bill acceptors also doubled, tripled, and even blew the tops off casinos with profit gains. Now players can insert a currency note into a slot machine and play off the credits. This not only increased the amount of games played per minute but also the Casino's bottom line. This led to yet another shortfall. If a customer wished to change machines or cashout they had to wait for the slot machine to spit out your winnings in coins which depending on the amount, lasted sometime or worse yet the machine was empty or didn't have enough coins and was locked waiting for someone to come pay the winnings. This reduced games played per minute and effected casino profits while the players were waiting instead of playing.</p></li>\n<li><p><strong>Tickets</strong> - Tickets were introduced circa 2002. Ticket-in/Ticket-out allowed players to easily cashout their winnings move to another machine and continue playing quickly &amp; easily. This not only reduced casino staff but increased casino revenues once again and increase the amount of games played per minute that players could play. Ticketing is still used around the world today and is considered a necessity for today's slot machines.</p></li>\n<li><p><strong>Smart Cards</strong> - Although Smart Cards were introduced before Tickets it was not as widely accepted as tickets. The early Smart Card systems were slow, unreliable, and customers didn't trust their money on cards. Smart Cards are still being used but not nearly widely accepted as ticketing.</p></li>\n<li><p><strong>Loyalty Cards/Bonusing</strong> - Now the boom of loyalty cards have somewhat replaced Smart Cards. Players accumulate points with a players card which can then be converted to credits on a machine. Better yet the loyalty card also allow you to win seperate winnings that are stored on your account and can easily transfer to other machines.</p></li>\n</ul>\n\n<h2 id=\"thepsychologyofaslotmachine\">The Psychology of a slot machine</h2>\n\n<p>Slot machines have been designed to make the player as comfortable as possible. The seating positon, graphics, and even the sound of the machine is tuned to appeal to the player. I've even experienced some machines that emitted an aroma to attract players(this didn't work). </p>\n\n<p>As I've traveled the world it came to my attention that certain cultures gravatate to certain slot machine themed games. Like Cleopatra/Egyptian themed games are a huge hit in southern Europe, Gold Mining &amp; TV Shows themes in the United States, and dragon and Asian themed games obviously are big in Asia. Not only the design of the machine is taken into consideration but also the location of the casino. All of these stastics are recorded and used to develop new games and features to better attrack more players.</p>\n\n<h2 id=\"presentdaycasinos\">Present Day Casinos</h2>\n\n<p>Today casinos can change every aspect of a casino floor in a moments notice. Server Based Gaming was introduced a few years ago and has been spreading like wild fire across the world. This enables a casino to change par/hold percentages, game themes, and even machine configurations on the fly. </p>\n\n<p>A casino can change their games and configuration of the casino floor for an upcoming weekend tighter (less winning) then loosen them back up during the week (more winning) to adapt to the clientele and attrack customers during off peak hours all from the click of a mouse button. As more data is collected by casino's they create better marketing campaigns, analyze slot machine performance, and player tendacies all to tune the casino floor better for the best revenue optimization. This is all done every time you spin the wheels of a machine.</p>\n\n<h2 id=\"howtowinplayingslotmachines\">How to win playing slot machines</h2>\n\n<p>So back to one of the original question of how do I win? Well that's easy. Keep your money in your pocket and head home. But if you ignore this advice here are some tips on winning at the slots. Remember one thing, Las Vegas was built by a bunch of losers not by a bunch of winners.</p>\n\n<ul>\n<li><p><strong>Play Video Poker</strong> - Video Poker has the best odds on the casino floor. However Poker also requires the players input. So you may throw away a Royal Flush (Seen it happen) because you never knew you had one.</p></li>\n<li><p><strong>Always play Max Bet / Cover all Lines</strong> - I cannot say this one loud enough. If you don't play Max Bet and cover all the lines you will never hit the big payouts. It is also very common that Bets other than Max Bet have worse odds.</p></li>\n<li><p><strong>The End Game</strong> - Many times casinos will configure a bank of machines with the ends as the highest paying and the middle less so. It is also possible that machines in the back of the casino have better payouts than those at the front. However this tip is set on a per casino basis.</p></li>\n<li><p><strong>Become friends with slot attendants</strong> - Although they cannot tell you which machine to play. They can tell you which machines they visit more often than others. If they don't tell you then pull a seat up at the bar and watch which machines they visit. If you see a pattern develop you may want to head over to those machines.</p></li>\n</ul>\n\n<p>Good luck losing your money!</p>","image":"/content/images/2015/01/Slot_machines-1.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"Luck has nothing to do with it!","meta_description":"A one time Casino Engineer let's you in on how slot machines are designed to separate you from your money as quickly as possible.","author_id":1,"created_at":1420748475950,"created_by":1,"updated_at":1421394014681,"updated_by":1,"published_at":1420754891176,"published_by":1},{"id":32,"uuid":"8bc97fd6-7fef-42d7-adb8-771f0e96589a","title":"Mac OSX Error connecting with RDP to Windows Server","slug":"mac-osx-error-connecting-with-rdp-to-windows-server","markdown":"I was having trouble creating an RDP client for Mac to a Windows Server. When I RDP to tha same Windows machine from another Windows machine everything worked as advertised.\n\nWhen I opened a RDP connection from my Mac to the Windows Server I would ge the following error: *\"Remote Desktop Connection cannot verify the identity of the computer that you want to connect to\"*\n![](/content/images/2015/02/Cannot_Verify_Identity_Mac_Rdp.png)\n\nSince I was able to connect from a Windows Machine I was under the assumption that the RDP problem layed with my Mac. Wrong!\n\nAfter trolling the internet for ages I finally found the fix.\n\n##How to fix the Mac OSX RDP Error:\nOn the Windows Server you are trying to RDP to perform the following\n\n* Ensure that RDP is enabled on the Windows Server and that the Firewall allows RDP.\n* Open the Management Console (mmc.exe) \n* Add the 'Local Computer Policy' snap-in\nGoto: -> Computer Configuration -> Administrative Templates -> Windows Components -> Remote Desktop Services -> Remote Desktop Session Host -> Security\n* Change the following two settings from their default (be aware that there might be a reason that MSFT has decided to set them to default. It might be advisable to revise those settings after a new Mac RDP client has been released)\n\n* **'Require use of specific for remote desktop (RDP) connections' from 'Default' to 'Enabled', then select 'RDP' in the options pane**\n\n* **'Require user authentication for remote connections by using Network Level Authentications' to 'Disabled'\nRestart the 'Remote Desktop Service' or simply restart the computer**\n\nI was able to connect to various versions of Windows Server with this fix.\n\nCredit -[Microsoft Technet](http://https://social.technet.microsoft.com/Forums/en-US/0b865c92-5e0b-4518-9092-790aed895f5b/remote-desktop-connection-for-mac-os-x-cannot-connect-to-windows-81?forum=w81previtpro)","html":"<p>I was having trouble creating an RDP client for Mac to a Windows Server. When I RDP to tha same Windows machine from another Windows machine everything worked as advertised.</p>\n\n<p>When I opened a RDP connection from my Mac to the Windows Server I would ge the following error: <em>\"Remote Desktop Connection cannot verify the identity of the computer that you want to connect to\"</em> <br />\n<img src=\"/content/images/2015/02/Cannot_Verify_Identity_Mac_Rdp.png\" alt=\"\" /></p>\n\n<p>Since I was able to connect from a Windows Machine I was under the assumption that the RDP problem layed with my Mac. Wrong!</p>\n\n<p>After trolling the internet for ages I finally found the fix.</p>\n\n<h2 id=\"howtofixthemacosxrdperror\">How to fix the Mac OSX RDP Error:</h2>\n\n<p>On the Windows Server you are trying to RDP to perform the following</p>\n\n<ul>\n<li>Ensure that RDP is enabled on the Windows Server and that the Firewall allows RDP.</li>\n<li>Open the Management Console (mmc.exe) </li>\n<li>Add the 'Local Computer Policy' snap-in\nGoto: -> Computer Configuration -> Administrative Templates -> Windows Components -> Remote Desktop Services -> Remote Desktop Session Host -> Security  </li>\n<li><p>Change the following two settings from their default (be aware that there might be a reason that MSFT has decided to set them to default. It might be advisable to revise those settings after a new Mac RDP client has been released)</p></li>\n<li><p><strong>'Require use of specific for remote desktop (RDP) connections' from 'Default' to 'Enabled', then select 'RDP' in the options pane</strong></p></li>\n<li><p><strong>'Require user authentication for remote connections by using Network Level Authentications' to 'Disabled'\nRestart the 'Remote Desktop Service' or simply restart the computer</strong></p></li>\n</ul>\n\n<p>I was able to connect to various versions of Windows Server with this fix.</p>\n\n<p>Credit -<a href=\"http://https://social.technet.microsoft.com/Forums/en-US/0b865c92-5e0b-4518-9092-790aed895f5b/remote-desktop-connection-for-mac-os-x-cannot-connect-to-windows-81?forum=w81previtpro\">Microsoft Technet</a></p>","image":"/content/images/2015/02/Cannot_Verify_Identity_Mac_Rdp-1.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"Mac OSX Error connecting with RDP to Windows Server","meta_description":"How to fix the MAC OSX RDP error Cannot Verify the Identity of the computer you want to connect to. It's an easy Windows Fix.","author_id":1,"created_at":1424159748012,"created_by":1,"updated_at":1424162474361,"updated_by":1,"published_at":1424162474362,"published_by":1},{"id":33,"uuid":"fc205cf8-be57-4aab-89ef-49b2af806bfc","title":"How to convert your website to SSL for Free","slug":"how-to-convert-your-website-to-ssl-for-free","markdown":"I was very doubtful to learn of the new offering by [CloudFlare SSL](https://www.cloudflare.com/ssl) and actually procratenated on installing it until yesterday. How the heck can they offer SSL for Free without having to install certificates? Since [Google ranks SSL](http://googlewebmastercentral.blogspot.ch/2014/08/https-as-ranking-signal.html)based sites higher than non https sites it was time to make the switch. The nice thing about this excercise I have several different website configurations: Static Website built on Foundation, Ghost, and Wordpress just to cover all the bases.\n\nCloud Flare offers serveral different levels of SSL protection. The Free level is Flexible SSL. This is the level I installed on all my sites including this one.\n\n![](/content/images/2015/03/Flexible_SSL_CloudFlare.png)\n**Flexible SSL:** is an encrypted connection between your site visitors and CloudFlare, but not from CloudFlare to your server.\n\nFirst things first. If you are not using CloudFlare now's the time to singup and take advantage of this awesome CDN service. Here's the quick and dirty to get started with [CloudFlare Getting started](https://support.cloudflare.com/hc/en-us/articles/201720164-How-do-I-sign-up-for-CloudFlare-)\n\n##How to switch to CloudFlare SSL with a Static Website\nThis is obviously the easiest switch.\n\n* Open the CloudFlare dashboard and click on the gear on the left side to access the settings.\n![CloudFlare settings](/content/images/2015/03/CloudFlare_Settings.png)\n* Click on Page rules\n\n* Add a new rule and toggle the **Always use HTTPS** flag. Type the domain name format you wish to forward to https. This will be either www.domain.com or domain.com\n![Add HTTPS Rule](/content/images/2015/03/Add_HTTPS_Rule_CloudFlare.png)\n\n* After about 5 minutes your web traffic will start forwarding to https and you will see the green SSL lock on your address bar. W00T!\n\n##How to switch to CloudFlare SSL with a Ghost Website\nSo the same rules apply for Ghost. We will create the rule just as we have above. Once the rule has been created for your Ghost Website you will need to edit your config.js inside of your Ghost installation directory. Update the URL field in this file to HTTPS.\n\n![Ghost config.js settings for CloudFlare SSL](/content/images/2015/03/Ghost_CloudFlare_SSL.png)\n\n##How to switch to CloudFlare SSL with a Wordpress Website\nWe wouldn't be complete without updating our Wordpress site as well, right?\n\nOf course last but not least caused me the biggest grief. Initially everything worked great until I tried to login to the wp-admin section. When I tried to login via wp-admin it went in an indefinite redirect loop and couldn't login.\n\nAfter hours of writing redirect rules and Googling I finally found a solution. That is until I found [TJOSM](https://tjosm.com/3699/setting-cloudflare-free-ssl-wordpress-nginx/) which saved the day and my sanity as he created the complete tutorial on making the switch for WordPress with NGINX.\n\n##SSL Everywhere\nNow that I have SSL installed and running across all my domains I not only feel safer but I'm expecting any moment my Google rankings to jump through the roof.\n\nEither way it is a nice to see the green lock in my address bar when I access my websites now.\n\nMission accomplished for a Free SSL installation.","html":"<p>I was very doubtful to learn of the new offering by <a href=\"https://www.cloudflare.com/ssl\">CloudFlare SSL</a> and actually procratenated on installing it until yesterday. How the heck can they offer SSL for Free without having to install certificates? Since <a href=\"http://googlewebmastercentral.blogspot.ch/2014/08/https-as-ranking-signal.html\">Google ranks SSL</a>based sites higher than non https sites it was time to make the switch. The nice thing about this excercise I have several different website configurations: Static Website built on Foundation, Ghost, and Wordpress just to cover all the bases.</p>\n\n<p>Cloud Flare offers serveral different levels of SSL protection. The Free level is Flexible SSL. This is the level I installed on all my sites including this one.</p>\n\n<p><img src=\"/content/images/2015/03/Flexible_SSL_CloudFlare.png\" alt=\"\" />\n<strong>Flexible SSL:</strong> is an encrypted connection between your site visitors and CloudFlare, but not from CloudFlare to your server.</p>\n\n<p>First things first. If you are not using CloudFlare now's the time to singup and take advantage of this awesome CDN service. Here's the quick and dirty to get started with <a href=\"https://support.cloudflare.com/hc/en-us/articles/201720164-How-do-I-sign-up-for-CloudFlare-\">CloudFlare Getting started</a></p>\n\n<h2 id=\"howtoswitchtocloudflaresslwithastaticwebsite\">How to switch to CloudFlare SSL with a Static Website</h2>\n\n<p>This is obviously the easiest switch.</p>\n\n<ul>\n<li>Open the CloudFlare dashboard and click on the gear on the left side to access the settings.\n<img src=\"/content/images/2015/03/CloudFlare_Settings.png\" alt=\"CloudFlare settings\" /></li>\n<li><p>Click on Page rules</p></li>\n<li><p>Add a new rule and toggle the <strong>Always use HTTPS</strong> flag. Type the domain name format you wish to forward to https. This will be either www.domain.com or domain.com\n<img src=\"/content/images/2015/03/Add_HTTPS_Rule_CloudFlare.png\" alt=\"Add HTTPS Rule\" /></p></li>\n<li><p>After about 5 minutes your web traffic will start forwarding to https and you will see the green SSL lock on your address bar. W00T!</p></li>\n</ul>\n\n<h2 id=\"howtoswitchtocloudflaresslwithaghostwebsite\">How to switch to CloudFlare SSL with a Ghost Website</h2>\n\n<p>So the same rules apply for Ghost. We will create the rule just as we have above. Once the rule has been created for your Ghost Website you will need to edit your config.js inside of your Ghost installation directory. Update the URL field in this file to HTTPS.</p>\n\n<p><img src=\"/content/images/2015/03/Ghost_CloudFlare_SSL.png\" alt=\"Ghost config.js settings for CloudFlare SSL\" /></p>\n\n<h2 id=\"howtoswitchtocloudflaresslwithawordpresswebsite\">How to switch to CloudFlare SSL with a Wordpress Website</h2>\n\n<p>We wouldn't be complete without updating our Wordpress site as well, right?</p>\n\n<p>Of course last but not least caused me the biggest grief. Initially everything worked great until I tried to login to the wp-admin section. When I tried to login via wp-admin it went in an indefinite redirect loop and couldn't login.</p>\n\n<p>After hours of writing redirect rules and Googling I finally found a solution. That is until I found <a href=\"https://tjosm.com/3699/setting-cloudflare-free-ssl-wordpress-nginx/\">TJOSM</a> which saved the day and my sanity as he created the complete tutorial on making the switch for WordPress with NGINX.</p>\n\n<h2 id=\"ssleverywhere\">SSL Everywhere</h2>\n\n<p>Now that I have SSL installed and running across all my domains I not only feel safer but I'm expecting any moment my Google rankings to jump through the roof.</p>\n\n<p>Either way it is a nice to see the green lock in my address bar when I access my websites now.</p>\n\n<p>Mission accomplished for a Free SSL installation.</p>","image":"/content/images/2015/03/SSL-1.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to convert your website to SSL for Free","meta_description":"A how to guide on setting up a static website, ghost CMS, or Wordpress with the Free CloudFlare Flexible SSL.","author_id":1,"created_at":1427228329579,"created_by":1,"updated_at":1427230872175,"updated_by":1,"published_at":1427230872177,"published_by":1},{"id":34,"uuid":"ca00d3f8-af4e-4813-b9b6-7929c3f92c4b","title":"The Amazing Advancements in Mountain Bikes","slug":"the-amazing-advancements-in-mountain-bikes","markdown":"![2015 Specialized Stunpjumper FSR Elite](/content/images/2015/04/Specialized_Stumpjumper_FSR_Elite.jpeg)\nWhen I moved to Switzerland back in 2010 I purchased a Rocky Mountain Instinct full suspension Mountain Bike. Since moving to Switzerland I've really been riding as much as I can as I really love the sport and the people that I ride with. [My journey with Mountain Biking](https://www.brianchristner.io/mountain-biking-coming-age/) started a long time ago.\n\nHowever after a lot of group rides and a couple races it was time to upgrade. The Rock Machine Instinct was a great bike to get me back in the game and really improve my fitness to a Swiss standard took me some time.\n\nI started my search by visiting all the bike shops in my area, which surprisingly was a ton. I checked out all major manufactures KTM, Trek, Specialized, Cannondale, Bergamont, Rocky Mountain, Rock Machine and a few more. The advancement in Technology in 5 years is mind blowing. Suspension, Brakes, Drivetrain and Frame Geometry could be components of a [MotoGP](http://www.motogp.com) motorcycle.\n\n##Frame Geometry\n![29er Head Downtube](/content/images/2015/04/29er_Head_Downtube.png)\nWhen I first bought my Rock Machine the 29\" wheels were just starting to catch on. However, many manufacutres opted to just slap 29\" wheels on existing frames with slight modifications which resulted in horrible handling and suspension issues.\n\nAs technology and time advanced so did the frame geometry to better adapt 29\" wheels. The first 29\" Frames had a straight downtube from the Head Tube to the crank. Now many models of 29er's have a slight bend upwards in the front downtube and offset backwards allowing plenty of clearnce for the front wheel when the suspension is compressed. Also, the entire frame is slightly lower which lowers the rider due to the 3\" inch bigger tires. This also helps lower Center of Gravity and overall handling.\n\nAnother newcomer to the Frame department is dropper posts. Dropper posts are such a simple addition providing a convience factor for riding trails.\n\n##Drivetrain\n![Shimano XTR Crank Drivetrain](/content/images/2015/04/Shimano_XTR_Crank_Drivetrain.png)\nDuring the last couple of years the amount of front sprockets has been decreasing from 3 to 2 and sometimes only 1 on the race bikes. This limits the amount of cross gearing that can occur and reduces the risk of chains jumping off. Now electric shifting is also available by Shimano. So is the next step Automatic Transmissions?\n\n##Suspension\n![Specialized Brain Shock internals](/content/images/2015/04/Specialized_Brain_Shock.jpg)\nThe most amazing advancement in Mountain Biking that I've tested and seen is the Suspension. I tip my hat towards Specialized in regards to the biggest advancement with their [Brain Technology](http://www.specialized.com/us/en/technology/brain) and Fox Suspension with their Autosag technology allowing for super easy bike/rider setup.\n\nThe amount of compression and rebound adjustments reminds me of setting up my race ready motorcycle. Depending on manufacture and bike model rear shocks are in a ton of different positions with some even offering adjustable angle for even further tuning.\n\n##Brakes\n![MTB Floating Disc Brake Rotor](/content/images/2015/04/MTB_Floating_Brake_Disc.jpg)\nBrakes are absolutely amazing now and combined with present day suspension makes braking performance incredible. Some bikes offer floating discs, radial mounted disc calipers and steel brake lines. The brakes now look like something off a MotoGP bike. So my next question is when will ABS be available?\n\n##2015 Specialized Stumpjumper FSR Elite\n\nI narrowed my search to a 29er Full Suspension bike that was more geared for Trail Riding. This immediately filtered out quite some models of bikes. I test rode several bikes, read every review I could on the bikes I rode and finally decided on the 2015 Specialized Sumpjumper FSR Elite. The Specialized Brain technology for the rear shock and Specialized engineering won me over. I felt instantly comfortable on the bike and it makes you feel like a pro.\n\nAfter taking delivery of my Stumpjumper today I dropped about 30 seconds on technical climb I normally ride. This is amazing! Downhill is even more fun now that I can drop the seat post on the fly and the suspension and brakes inspire so much confidence that your speed increases naturally. I'm extremly happy with my purchase and look forward to riding the heck out of it and do a couple fun races.","html":"<p><img src=\"/content/images/2015/04/Specialized_Stumpjumper_FSR_Elite.jpeg\" alt=\"2015 Specialized Stunpjumper FSR Elite\" />\nWhen I moved to Switzerland back in 2010 I purchased a Rocky Mountain Instinct full suspension Mountain Bike. Since moving to Switzerland I've really been riding as much as I can as I really love the sport and the people that I ride with. <a href=\"https://www.brianchristner.io/mountain-biking-coming-age/\">My journey with Mountain Biking</a> started a long time ago.</p>\n\n<p>However after a lot of group rides and a couple races it was time to upgrade. The Rock Machine Instinct was a great bike to get me back in the game and really improve my fitness to a Swiss standard took me some time.</p>\n\n<p>I started my search by visiting all the bike shops in my area, which surprisingly was a ton. I checked out all major manufactures KTM, Trek, Specialized, Cannondale, Bergamont, Rocky Mountain, Rock Machine and a few more. The advancement in Technology in 5 years is mind blowing. Suspension, Brakes, Drivetrain and Frame Geometry could be components of a <a href=\"http://www.motogp.com\">MotoGP</a> motorcycle.</p>\n\n<h2 id=\"framegeometry\">Frame Geometry</h2>\n\n<p><img src=\"/content/images/2015/04/29er_Head_Downtube.png\" alt=\"29er Head Downtube\" />\nWhen I first bought my Rock Machine the 29\" wheels were just starting to catch on. However, many manufacutres opted to just slap 29\" wheels on existing frames with slight modifications which resulted in horrible handling and suspension issues.</p>\n\n<p>As technology and time advanced so did the frame geometry to better adapt 29\" wheels. The first 29\" Frames had a straight downtube from the Head Tube to the crank. Now many models of 29er's have a slight bend upwards in the front downtube and offset backwards allowing plenty of clearnce for the front wheel when the suspension is compressed. Also, the entire frame is slightly lower which lowers the rider due to the 3\" inch bigger tires. This also helps lower Center of Gravity and overall handling.</p>\n\n<p>Another newcomer to the Frame department is dropper posts. Dropper posts are such a simple addition providing a convience factor for riding trails.</p>\n\n<h2 id=\"drivetrain\">Drivetrain</h2>\n\n<p><img src=\"/content/images/2015/04/Shimano_XTR_Crank_Drivetrain.png\" alt=\"Shimano XTR Crank Drivetrain\" />\nDuring the last couple of years the amount of front sprockets has been decreasing from 3 to 2 and sometimes only 1 on the race bikes. This limits the amount of cross gearing that can occur and reduces the risk of chains jumping off. Now electric shifting is also available by Shimano. So is the next step Automatic Transmissions?</p>\n\n<h2 id=\"suspension\">Suspension</h2>\n\n<p><img src=\"/content/images/2015/04/Specialized_Brain_Shock.jpg\" alt=\"Specialized Brain Shock internals\" />\nThe most amazing advancement in Mountain Biking that I've tested and seen is the Suspension. I tip my hat towards Specialized in regards to the biggest advancement with their <a href=\"http://www.specialized.com/us/en/technology/brain\">Brain Technology</a> and Fox Suspension with their Autosag technology allowing for super easy bike/rider setup.</p>\n\n<p>The amount of compression and rebound adjustments reminds me of setting up my race ready motorcycle. Depending on manufacture and bike model rear shocks are in a ton of different positions with some even offering adjustable angle for even further tuning.</p>\n\n<h2 id=\"brakes\">Brakes</h2>\n\n<p><img src=\"/content/images/2015/04/MTB_Floating_Brake_Disc.jpg\" alt=\"MTB Floating Disc Brake Rotor\" />\nBrakes are absolutely amazing now and combined with present day suspension makes braking performance incredible. Some bikes offer floating discs, radial mounted disc calipers and steel brake lines. The brakes now look like something off a MotoGP bike. So my next question is when will ABS be available?</p>\n\n<h2 id=\"2015specializedstumpjumperfsrelite\">2015 Specialized Stumpjumper FSR Elite</h2>\n\n<p>I narrowed my search to a 29er Full Suspension bike that was more geared for Trail Riding. This immediately filtered out quite some models of bikes. I test rode several bikes, read every review I could on the bikes I rode and finally decided on the 2015 Specialized Sumpjumper FSR Elite. The Specialized Brain technology for the rear shock and Specialized engineering won me over. I felt instantly comfortable on the bike and it makes you feel like a pro.</p>\n\n<p>After taking delivery of my Stumpjumper today I dropped about 30 seconds on technical climb I normally ride. This is amazing! Downhill is even more fun now that I can drop the seat post on the fly and the suspension and brakes inspire so much confidence that your speed increases naturally. I'm extremly happy with my purchase and look forward to riding the heck out of it and do a couple fun races.</p>","image":"/content/images/2015/04/Specialized_Stumpjumper_FSR_Elite-1.jpeg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"The Amazing Advancements in Mountain Bikes","meta_description":"Mountain Bike advancements in the last 5 years in the Frame, Suspension, Brakes, and Drivetrain instantly provides speed and confidence of a pro rider","author_id":1,"created_at":1428786137178,"created_by":1,"updated_at":1428792915687,"updated_by":1,"published_at":1428792915710,"published_by":1},{"id":35,"uuid":"90d0c0ee-67e2-4ae2-a541-7b9aa456aae4","title":"How to install and configure CoreOS inside VMware","slug":"how-to-install-and-configure-coreos-inside-vmware","markdown":"I'm working on building a my own Cloud Platform based on Docker and CoreOS. Howerver my underlying infrastrucutre is VMware vCloud which is not exactly straight forward in comparison to Amazon EC2 or Digital Ocean when installing CoreOS. \n\nVMWare has a really nice [CoreOS tutorial](http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&cmd=displayKC&externalId=2109161) but it is lacking the CoreOS network configurations. So this small tutuorial will help you get get static networking running in no time. But most of the details can be found in the [CoreOS Tutorial](http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&cmd=displayKC&externalId=2109161).\n\n##Where to find a CoreOS OVA File\nSo after much searching I finally found a link to the current builds of CoreOS which also include OVF files -http://stable.release.core-os.net/amd64-usr/current/\n\nDo a quick search for OVA on this website and it will take you right to the VMware OVA image of CoreOS - *coreos_production_vmware_ova.ova*. Download this OVA file.\n\n## Configure CoreOS Network, Gateway and DNS servers\nBy this point the CoreOS should now be running inside of VMware. So far no black magic has been used. Yet.. Since CoreOS doesn't support VMware tools it uses Open VM Tools. This gives us basic funtionality but the network settings are not automatically configured inside of CoreOS.\n\nOnce you open the console on your newly created CoreOS VM (Refer to the tutorial if you cannot login). We now need to configure the network settings so we can ssh into the server from outside.\n\n* Navigate to the /etc/systemd/network directoy\n* Create the file static.network - *$sudo vi static.network*\n\nInside the static.network file add the following information in order to setup static networking.\n\n\t[Match]\n\tMACAddress=00:55:56:57:58:59\n\t[Network]\n\tAddress=192.168.10.10/24 \n\tGateway=192.168.10.1\n\tDNS=8.8.8.8```\n\nAfter configuring your network settings reboot CoreOS. The reason I say reboot as for whatever reason the systemctl restart was not reading the network settings and only a reboot reread the static.network file.\n\nAfter the reboot you should be able to ping Google's DNS 8.8.8.8 and google.com which should enable you to continue either building your CoreOS cluster or using another service.","html":"<p>I'm working on building a my own Cloud Platform based on Docker and CoreOS. Howerver my underlying infrastrucutre is VMware vCloud which is not exactly straight forward in comparison to Amazon EC2 or Digital Ocean when installing CoreOS. </p>\n\n<p>VMWare has a really nice <a href=\"http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2109161\">CoreOS tutorial</a> but it is lacking the CoreOS network configurations. So this small tutuorial will help you get get static networking running in no time. But most of the details can be found in the <a href=\"http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2109161\">CoreOS Tutorial</a>.</p>\n\n<h2 id=\"wheretofindacoreosovafile\">Where to find a CoreOS OVA File</h2>\n\n<p>So after much searching I finally found a link to the current builds of CoreOS which also include OVF files -<a href=\"http://stable.release.core-os.net/amd64-usr/current/\">http://stable.release.core-os.net/amd64-usr/current/</a></p>\n\n<p>Do a quick search for OVA on this website and it will take you right to the VMware OVA image of CoreOS - <em>coreos_production_vmware_ova.ova</em>. Download this OVA file.</p>\n\n<h2 id=\"configurecoreosnetworkgatewayanddnsservers\">Configure CoreOS Network, Gateway and DNS servers</h2>\n\n<p>By this point the CoreOS should now be running inside of VMware. So far no black magic has been used. Yet.. Since CoreOS doesn't support VMware tools it uses Open VM Tools. This gives us basic funtionality but the network settings are not automatically configured inside of CoreOS.</p>\n\n<p>Once you open the console on your newly created CoreOS VM (Refer to the tutorial if you cannot login). We now need to configure the network settings so we can ssh into the server from outside.</p>\n\n<ul>\n<li>Navigate to the /etc/systemd/network directoy</li>\n<li>Create the file static.network - <em>$sudo vi static.network</em></li>\n</ul>\n\n<p>Inside the static.network file add the following information in order to setup static networking.</p>\n\n<pre><code>[Match]\nMACAddress=00:55:56:57:58:59\n[Network]\nAddress=192.168.10.10/24 \nGateway=192.168.10.1\nDNS=8.8.8.8```\n</code></pre>\n\n<p>After configuring your network settings reboot CoreOS. The reason I say reboot as for whatever reason the systemctl restart was not reading the network settings and only a reboot reread the static.network file.</p>\n\n<p>After the reboot you should be able to ping Google's DNS 8.8.8.8 and google.com which should enable you to continue either building your CoreOS cluster or using another service.</p>","image":"/content/images/2015/04/coreos-logo.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to install and configure CoreOS inside VMware","meta_description":"A quick guide on how to configure CoreOS networking to work with VMware and where to find CoreOS OVA files.","author_id":1,"created_at":1429792382112,"created_by":1,"updated_at":1432030805061,"updated_by":1,"published_at":1429881441077,"published_by":1},{"id":36,"uuid":"9fbd77ff-93a1-4ede-8260-884c37f672f5","title":"How to Automate Docker Builds and Auto Deploy","slug":"how-to-automate-docker-builds-end-to-end","markdown":"The more time I spend with Docker the more ideas and problems I can solve with Docker. Using Docker in combination with other services expands the possabilites even further such as [Tutum](https://www.tutum.co/). \n\nThis article describes how to create an Automated Docker Build that auto deploys Docker containers in combination with these services [GitHub](https://github.com/) -> [Docker Hub](https://hub.docker.com/) -> [Tutum](https://www.tutum.co/). I've come across several articles that describe one portion of this process but I've yet found something that covers the entire end-to-end Docker deployment. So why not type it out.\n\n##Create a Hello World Fork\n\nLet's start by forking my GitHub Repo from [Docker-Hello-World](https://github.com/vegasbrianc/docker-hello-world) oringally from TutumCloud. I cleaned up the Repo a little so it is easier to navigate and edit. Once you Forked the repo click on the Settings icon on the right side of your newly created Repo.\n![Repo Settings](/content/images/2015/04/Repo_Settings.png)\nOn the left side of the settings screen click Webhooks & Services. Click add service and find the Docker service.\n![Docker Services](/content/images/2015/04/Services.png)\n\n## Create an Automated Build Docker Repository\n\nIf you don't have a [Docker Hub Account](https://registry.hub.docker.com) you should sign up for one now. Once logged into the Docker Hub, click the Button below your username ==+Add Repository --> Automated Build== ![Docker Hub Automated Build](/content/images/2015/04/Docker_Hub_Automated_Build.png)\n\nSelect GitHub as the source.\n![GitHub Repo](/content/images/2015/04/GitHub_repo.png)\n\nFinally, select the new Repository you forked in GitHub. My example below shows my Docker-Hello-World Repo.\n![Select Repo](/content/images/2015/04/Select_Repo.png)\n\nKeep the default values on the next page and click ==Create Repository==. Your GitHub Repo is now linked to your Docker Hub. Any changes that you perform inside your Forked Repo in GitHub will automatically generate a new build inside of Docker Hub.\n\nOpen your newly created Docker Repository and click on the ==Build Details== tab. Here you will see your build history. If you want to give a build a try click the blue button on the right side ==start build== This will build a new docker image based on your fork inside of your GitHub account. Neat, huh?\n\n##Auto Deploy new Containers with Tutum\nNow that we have GitHub and Docker linked let's take it one step further. We will now link Docker with Tutum. [Tutum](https://www.tutum.co/) is an amazing PaaS (Platform as a Service) tool for Docker Containers which allows you to build, deploy, and manage Docker Containers across your cloud. Tutum is the provisioning portal for your Docker infrastructure. Your data and your servers are still managed by you.\n\nSign-in to Tutum with your Docker account as we want to link directly to Docker. Once you've signed-in I advise you to follow the [getting started guide by Tutum](https://support.tutum.co/support/solutions/folders/5000036273) which walks you through setting up a Docker server with Tutum. Connecting to your own server infrastrucuture or 3rd Party Clouds like Amazone or Digital Ocean is possible. Whatever you choose it's incredibly simple.\n\nOnce you built your first node (Virtaual Machine that is connected to Tutum) we can now deploy our the service we created with our Github Repo. Login to the Tutum Dashboard and click the ==Services Tab==.\n\nInside the Services Tab click the ==Create Service== button.\n\nWe will now search the Dockerhub for our Repo. In my example below I typed my username in the searchbox *vegasbrianc* which returns my repos available inside of the Dockerhub. Click the Select button on the Repo name you created. Docker-Hello-World is my example below.\n![Tutum Create Service](/content/images/2015/04/Tutum_Create_Service.png)\n\n* Name your container\n* Click on the greyed out Ports section\n* Click Publish Port and change the port from Dynamic to port 80.\n* Click the ==Create & Deploy== button\n![Tutum Create and Deploy Service](/content/images/2015/04/Tutum_Create_Deploy_Service.png)\n\nAfter your service is up and running open your service and open the ==Endpoints== tab. Here you will see the Service Endpoints and a hyperlink. Open this hyperlink. You should see your docker-hello-world container up and running. Yeah it's that easy!\n\nOnce you've verified that your container works click on the ==Webhooks== Tab. Follow the [Tutum guide on how to setup Webhooks](https://support.tutum.co/support/solutions/articles/5000513815-webhook-handlers) for your service. This will link Tutum to the Docker Hub allowing Tutum to monitor Docker Hub for updates. If Tutum sees a new build it will then redeploy your service with the new verison. \n\n\n##Conclusion\nWe've now built an Automated Docker build configuration that auto deploys containers once a new version is found. Amazingly simple isn't it? Can you think of the possabilites now with such a setup?\n\nMake some changes in your Github repo. Change the Hello World text and save the index.php. This will kick-off a new build inside of the Docker Hub which then notifies Tutum to redeploy a new version which is all seamless. However we do have downtime between versions which we will cover how to fix in future articles.\n\nThis setup will be the foundation for future articles where I'll dive deeper into Continous Integration (CI), Continuous Deployment (CD) and A/B Testing with Docker and Tutum.","html":"<p>The more time I spend with Docker the more ideas and problems I can solve with Docker. Using Docker in combination with other services expands the possabilites even further such as <a href=\"https://www.tutum.co/\">Tutum</a>. </p>\n\n<p>This article describes how to create an Automated Docker Build that auto deploys Docker containers in combination with these services <a href=\"https://github.com/\">GitHub</a> -> <a href=\"https://hub.docker.com/\">Docker Hub</a> -> <a href=\"https://www.tutum.co/\">Tutum</a>. I've come across several articles that describe one portion of this process but I've yet found something that covers the entire end-to-end Docker deployment. So why not type it out.</p>\n\n<h2 id=\"createahelloworldfork\">Create a Hello World Fork</h2>\n\n<p>Let's start by forking my GitHub Repo from <a href=\"https://github.com/vegasbrianc/docker-hello-world\">Docker-Hello-World</a> oringally from TutumCloud. I cleaned up the Repo a little so it is easier to navigate and edit. Once you Forked the repo click on the Settings icon on the right side of your newly created Repo. <br />\n<img src=\"/content/images/2015/04/Repo_Settings.png\" alt=\"Repo Settings\" />\nOn the left side of the settings screen click Webhooks &amp; Services. Click add service and find the Docker service. <br />\n<img src=\"/content/images/2015/04/Services.png\" alt=\"Docker Services\" /></p>\n\n<h2 id=\"createanautomatedbuilddockerrepository\">Create an Automated Build Docker Repository</h2>\n\n<p>If you don't have a <a href=\"https://registry.hub.docker.com\">Docker Hub Account</a> you should sign up for one now. Once logged into the Docker Hub, click the Button below your username <mark>+Add Repository --> Automated Build</mark> <img src=\"/content/images/2015/04/Docker_Hub_Automated_Build.png\" alt=\"Docker Hub Automated Build\" title=\"\" /></p>\n\n<p>Select GitHub as the source. <br />\n<img src=\"/content/images/2015/04/GitHub_repo.png\" alt=\"GitHub Repo\" /></p>\n\n<p>Finally, select the new Repository you forked in GitHub. My example below shows my Docker-Hello-World Repo. <br />\n<img src=\"/content/images/2015/04/Select_Repo.png\" alt=\"Select Repo\" /></p>\n\n<p>Keep the default values on the next page and click <mark>Create Repository</mark>. Your GitHub Repo is now linked to your Docker Hub. Any changes that you perform inside your Forked Repo in GitHub will automatically generate a new build inside of Docker Hub.</p>\n\n<p>Open your newly created Docker Repository and click on the <mark>Build Details</mark> tab. Here you will see your build history. If you want to give a build a try click the blue button on the right side <mark>start build</mark> This will build a new docker image based on your fork inside of your GitHub account. Neat, huh?</p>\n\n<h2 id=\"autodeploynewcontainerswithtutum\">Auto Deploy new Containers with Tutum</h2>\n\n<p>Now that we have GitHub and Docker linked let's take it one step further. We will now link Docker with Tutum. <a href=\"https://www.tutum.co/\">Tutum</a> is an amazing PaaS (Platform as a Service) tool for Docker Containers which allows you to build, deploy, and manage Docker Containers across your cloud. Tutum is the provisioning portal for your Docker infrastructure. Your data and your servers are still managed by you.</p>\n\n<p>Sign-in to Tutum with your Docker account as we want to link directly to Docker. Once you've signed-in I advise you to follow the <a href=\"https://support.tutum.co/support/solutions/folders/5000036273\">getting started guide by Tutum</a> which walks you through setting up a Docker server with Tutum. Connecting to your own server infrastrucuture or 3rd Party Clouds like Amazone or Digital Ocean is possible. Whatever you choose it's incredibly simple.</p>\n\n<p>Once you built your first node (Virtaual Machine that is connected to Tutum) we can now deploy our the service we created with our Github Repo. Login to the Tutum Dashboard and click the <mark>Services Tab</mark>.</p>\n\n<p>Inside the Services Tab click the <mark>Create Service</mark> button.</p>\n\n<p>We will now search the Dockerhub for our Repo. In my example below I typed my username in the searchbox <em>vegasbrianc</em> which returns my repos available inside of the Dockerhub. Click the Select button on the Repo name you created. Docker-Hello-World is my example below. <br />\n<img src=\"/content/images/2015/04/Tutum_Create_Service.png\" alt=\"Tutum Create Service\" /></p>\n\n<ul>\n<li>Name your container</li>\n<li>Click on the greyed out Ports section</li>\n<li>Click Publish Port and change the port from Dynamic to port 80.</li>\n<li>Click the <mark>Create &amp; Deploy</mark> button\n<img src=\"/content/images/2015/04/Tutum_Create_Deploy_Service.png\" alt=\"Tutum Create and Deploy Service\" /></li>\n</ul>\n\n<p>After your service is up and running open your service and open the <mark>Endpoints</mark> tab. Here you will see the Service Endpoints and a hyperlink. Open this hyperlink. You should see your docker-hello-world container up and running. Yeah it's that easy!</p>\n\n<p>Once you've verified that your container works click on the <mark>Webhooks</mark> Tab. Follow the <a href=\"https://support.tutum.co/support/solutions/articles/5000513815-webhook-handlers\">Tutum guide on how to setup Webhooks</a> for your service. This will link Tutum to the Docker Hub allowing Tutum to monitor Docker Hub for updates. If Tutum sees a new build it will then redeploy your service with the new verison. </p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>We've now built an Automated Docker build configuration that auto deploys containers once a new version is found. Amazingly simple isn't it? Can you think of the possabilites now with such a setup?</p>\n\n<p>Make some changes in your Github repo. Change the Hello World text and save the index.php. This will kick-off a new build inside of the Docker Hub which then notifies Tutum to redeploy a new version which is all seamless. However we do have downtime between versions which we will cover how to fix in future articles.</p>\n\n<p>This setup will be the foundation for future articles where I'll dive deeper into Continous Integration (CI), Continuous Deployment (CD) and A/B Testing with Docker and Tutum.</p>","image":"/content/images/2015/04/Container_Automation.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to Automate Docker Build and Auto Deploy","meta_description":"A step-by-step guide on how to link GitHub, Docker and Tutum in order to Automate Builds and automatically deploy new Docker containers.","author_id":1,"created_at":1430204762717,"created_by":1,"updated_at":1432028425726,"updated_by":1,"published_at":1430238564335,"published_by":1},{"id":37,"uuid":"69101f76-0ff0-4e64-a8ef-1d61123921f3","title":"How to setup Docker Monitoring","slug":"how-to-setup-docker-monitoring","markdown":"Docker monitoring of servers and containers is becoming necessary the more Docker hosts and containers we provision. This tutorial will walk you through how to glue together several different components in order to achieve Docker monitoring.\n\n###Components for Docker Monitoring\nFirst things first. We assume that Docker is installed, configured, and running on your host before we begin. *Please ensure you can connect to your Docker host with a Web Browser either locally or over a Public IP*. The rest of the Tutorial we will refer to this as the *DockerIP* The below components will be used to create our Docker Monitoring solution.\n\n[**cAdvisor**](https://registry.hub.docker.com/u/google/cadvisor/) - Google has been using containers for quite sometime and created cAdvisor to help monitor their infrastructure. This single tool alone is an amazing monitoring tool. It not only monitors your Docker containers but the Docker host as well without any configuratio by just running the cAdvisor container on your Docker host. Be sure to check out the [cAdvisor GitHub](https://github.com/google/cadvisor) for more documentation on the API and different configuration options.\n\n[**InfluxDB**](https://registry.hub.docker.com/u/tutum/influxdb/) - InfluxDB is a distributed time series database. cAdvisor only displays realtime information and doesn't store the metrics. We need to store the monitoring information which cAdvisor provides in order to display a time range other than realtime. \n\n[**Grafana Metrics Dashboard**](https://registry.hub.docker.com/u/grafana/grafana/) - The Grafana Dashboard allows us to pull all the pieces together visually. This powerful Dashboard allows us to run queries against the InfluxDB and chart them accordingly in a very nice layout.\n\n##Installation of Docker Monitoring\nNow that we have an overview of the different components involved in our Docker Monitoring setup let's get started pulling it all together.\n\nWe will start with the InfluxDB first and work our way towards connecting the cAdvisor.\n\n1) Install the InfluxDb. We use the default settings below and name the container *influxsrv* which we will use later on for linking.\n`sudo docker run -d\n-p 8083:8083\n-p 8086:8086\n--expose 8090 \n--expose 8099\n--name influxsrv\ntutum/influxdb`\n\nLet's test quickly that our InfluxDB installed correctly. Navigate to your http://DockerIP:8083 Use the credentials below to login to InfluxDB.\nUsername - root\nPassword - root\n![InfluxDB Login Screen](/content/images/2015/05/InfluxDB_login.png)\n\n2) Create the cadvisor Database\nAfter logging into InfluxDB click on the Databases link at the top of the screen. Type the name *cadvisor* for the Database name and click *Create Database*\n![Create Database](/content/images/2015/05/CreateDB.png)\n\n3) Install the cAdvisor container and link it to the InfluxDB container.\n\n`sudo docker run\n  --volume=/:/rootfs:ro\n  --volume=/var/run:/var/run:rw\n  --volume=/sys:/sys:ro\n  --volume=/var/lib/docker/:/var/lib/docker:ro\n  --publish=8080:8080\n  --detach=true\n  --link influxsrv:influxsrv\n  --name=cadvisor\n  google/cadvisor:latest \n  -storage_driver_db=cadvisor \n  -storage_driver_host=influxsrv:8086`\n\nOnce the cAdvisor container has been installed and running you can now navigate to the http://DockerIP:8080 For example, `http://192.168.10.1:8080` You should now see the cAdvisor gathering statistics on your Docker host and containers.\n![cAdvisor Dashboard](/content/images/2015/05/cAdvisor_Dashboard.png)\n\n4) Install the Grafana Dashboard and link it to the InfluxDB container:\n`sudo docker run -d\n-p 3000:3000\n-e INFLUXDB_HOST=localhost\n-e INFLUXDB_PORT=8086\n-e INFLUXDB_NAME=cadvisor\n-e INFLUXDB_USER=root\n-e INFLUXDB_PASS=root\n--link influxsrv:influxsrv\n--name grafana\ngrafana/grafana`\n\n5) Login to Grafana and configure the Data Sources. \nNavigate to http://DockerIP:3000 \nUsername - admin\nPassword - admin\n\n6) Connect the InfluxDB to the Grafana Dashboard:\nOnce logged in click on the Grafana icon(Fireball) in the upper left hand corner of the GUI. This should pop out a sidebar menu. Click on *Data Sources*.\n\nNext, click on *Add New* Data Source at the top of the screen.\nFill in the following information in the Data Source screen:\n\n**Data Source Settings**\n\nName: influxdb\nType: InfluxDB 0.8.x\nBe sure to check default box.\n\nHttp settings\nUrl: http://influxsrv:8086 (This is the name we specified when createing the link on the Grafana container)\nAccess: proxy\nBasic Auth: Enabled\nUser: admin\nPassword: admin\n\nInfluxDB Details\nDatabase: cadvisor (Or the name you specified when creating the database in step 2)\nUser: root\nPassword: root\n\nYou should now have an established connection to the InfluxDB which we will test in the next section.\n![Grafana Data Source Configuration](/content/images/2015/05/Grafana_Config.png)\n\n##Configuring Grafana for Docker Monitoring\nNow comes the fun part. Let's setup our first Dashboard with Grafana and visualize the data coming from the cAdvisor.\n\n1) Click on the Grafana icon once again (The Fireball icon upper left corner)\n\n2) Open the Dashboard menu --> Expand the Home Menu drop Down --> Click *+New*\n\n3) We've now created a new Dashboard inside of Grafana. Let's create our first graph inside this Dashboard. Click the green vertical line as seen below in the screenshot circled in Red. This expands the row options for the Dashboard.\n\n4) Click *Add Panel* --> *Graph*\n\n![Create New Grafana Dashboard](/content/images/2015/05/New_Dashboard.png)\n\n5) Click the Title area of the new Graph you created where it says \"no title (click here)\" and click *Edit*\n![Create Grafana Graph](/content/images/2015/05/Create_Graph.jpg)\n\n6) It's time to write our first query for our graph. We will create a graph displaying the Filesystem storage limit and usage.\n**Query 1** - Fill in the following information inside the Graph screen:\nseries: stats\nClick on \"value\" which will present you a drop down list of available series available inside of the InfluxDB.\nselect: mean(fs_limit)\nAlias: Limit\n\n**Query 2** - At the Bottom of Graph screen is an *+Add Query* button which allows us to add another metric to our graph.\nseries: stats\nselect: mean(fs_usage)\nAlias: Usage\n\n![Docker Filesystem Graph](/content/images/2015/05/filesystem_graph.png)\n\n7) Click on the General Menu and Change the Title of your Graph\n\n8) Click on the Axis & Grid Menu\nLeft Y Unit: Bytes\nYour Chart should now display with the correct units.\n\n9) Once finished like any other project be sure to save your work. Hit the Save icon a the top of the screen.\n\n## Docker Monitoring Conclusion\nWe have now built a single Grafana Dashboard with a Graph containing our Filesystem statistics. As you can see it's extremely simple to create multiple graphs to monitor our Docker Host and Containers.\n\nBe sure to check out the [Grafana Docs](http://docs.grafana.org/) to dive deeper with the queries and functionality of Grafana. Take a look below at the screenshot which shows the possibilities for creating some really interesting graphs (Bandwidth, CPU Usage per Container, Memory Usage, and Filesystem Limit/Usage).\n\n![Docker Monitoring with cAdvisor, InfluxDB, and Grafana](/content/images/2015/05/Docker_Monitoring.png)\n\nLeave a comment below if you have any issues or questions.\n\nGood Luck!\n\n## Troubleshooting\nIn the event you have troubles this is for you. It took me quite sometime to figure out all the settings and where the problems were with the connection from Grafana to InfluxDB. In the event you have issues with your Graphs I highly recommend a Development Console in your Browser of choice.\n\nWith the development console it is really easy to see problems with your queries or connections to the InfluxDB container. For Example: Chrome Development Tools -> More Tools -> Javascript Console\n\nAnother workaround is using the IP address of the containers to resolve connection issues. However, if you restart the container the IP address changes so this is only a temp fix.\n\n`docker inspect <container name>`\n\nSearch the output for the IP address which is under the Network Settings section as seen below:\n`\"NetworkSettings\": {\n        \"Bridge\": \"docker0\",\n        \"Gateway\": \"172.17.42.1\",\n        \"GlobalIPv6Address\": \"\",\n        \"GlobalIPv6PrefixLen\": 0,\n        \"IPAddress\": \"172.17.0.54\",\n`\n\nYou can then replace the name that we used in Data Source settings we used above as a workaround. This worked for me until I fixed the links between containers.\n\n## Update \nThanks to everyone for the overwhelming response to this article. Since this article was published Dale Kate-Murray and Ross Jimenez created a [Docker Monitoring Compose file](http://bit.ly/1LFek7L) to help everyone get started.\n\nAnother question that came up in the comments is how to build the different dashboards. So here is the JSON file from the Dashboard - https://github.com/vegasbrianc/docker-monitoring\n\n","html":"<p>Docker monitoring of servers and containers is becoming necessary the more Docker hosts and containers we provision. This tutorial will walk you through how to glue together several different components in order to achieve Docker monitoring.</p>\n\n<h3 id=\"componentsfordockermonitoring\">Components for Docker Monitoring</h3>\n\n<p>First things first. We assume that Docker is installed, configured, and running on your host before we begin. <em>Please ensure you can connect to your Docker host with a Web Browser either locally or over a Public IP</em>. The rest of the Tutorial we will refer to this as the <em>DockerIP</em> The below components will be used to create our Docker Monitoring solution.</p>\n\n<p><a href=\"https://registry.hub.docker.com/u/google/cadvisor/\"><strong>cAdvisor</strong></a> - Google has been using containers for quite sometime and created cAdvisor to help monitor their infrastructure. This single tool alone is an amazing monitoring tool. It not only monitors your Docker containers but the Docker host as well without any configuratio by just running the cAdvisor container on your Docker host. Be sure to check out the <a href=\"https://github.com/google/cadvisor\">cAdvisor GitHub</a> for more documentation on the API and different configuration options.</p>\n\n<p><a href=\"https://registry.hub.docker.com/u/tutum/influxdb/\"><strong>InfluxDB</strong></a> - InfluxDB is a distributed time series database. cAdvisor only displays realtime information and doesn't store the metrics. We need to store the monitoring information which cAdvisor provides in order to display a time range other than realtime. </p>\n\n<p><a href=\"https://registry.hub.docker.com/u/grafana/grafana/\"><strong>Grafana Metrics Dashboard</strong></a> - The Grafana Dashboard allows us to pull all the pieces together visually. This powerful Dashboard allows us to run queries against the InfluxDB and chart them accordingly in a very nice layout.</p>\n\n<h2 id=\"installationofdockermonitoring\">Installation of Docker Monitoring</h2>\n\n<p>Now that we have an overview of the different components involved in our Docker Monitoring setup let's get started pulling it all together.</p>\n\n<p>We will start with the InfluxDB first and work our way towards connecting the cAdvisor.</p>\n\n<p>1) Install the InfluxDb. We use the default settings below and name the container <em>influxsrv</em> which we will use later on for linking. <br />\n<code>sudo docker run -d\n-p 8083:8083\n-p 8086:8086\n--expose 8090 \n--expose 8099\n--name influxsrv\ntutum/influxdb</code></p>\n\n<p>Let's test quickly that our InfluxDB installed correctly. Navigate to your <a href=\"http://DockerIP:8083\">http://DockerIP:8083</a> Use the credentials below to login to InfluxDB. <br />\nUsername - root <br />\nPassword - root <br />\n<img src=\"/content/images/2015/05/InfluxDB_login.png\" alt=\"InfluxDB Login Screen\" /></p>\n\n<p>2) Create the cadvisor Database <br />\nAfter logging into InfluxDB click on the Databases link at the top of the screen. Type the name <em>cadvisor</em> for the Database name and click <em>Create Database</em> <br />\n<img src=\"/content/images/2015/05/CreateDB.png\" alt=\"Create Database\" /></p>\n\n<p>3) Install the cAdvisor container and link it to the InfluxDB container.</p>\n\n<p><code>sudo docker run\n  --volume=/:/rootfs:ro\n  --volume=/var/run:/var/run:rw\n  --volume=/sys:/sys:ro\n  --volume=/var/lib/docker/:/var/lib/docker:ro\n  --publish=8080:8080\n  --detach=true\n  --link influxsrv:influxsrv\n  --name=cadvisor\n  google/cadvisor:latest \n  -storage_driver_db=cadvisor \n  -storage_driver_host=influxsrv:8086</code></p>\n\n<p>Once the cAdvisor container has been installed and running you can now navigate to the <a href=\"http://DockerIP:8080\">http://DockerIP:8080</a> For example, <code>http://192.168.10.1:8080</code> You should now see the cAdvisor gathering statistics on your Docker host and containers. <br />\n<img src=\"/content/images/2015/05/cAdvisor_Dashboard.png\" alt=\"cAdvisor Dashboard\" /></p>\n\n<p>4) Install the Grafana Dashboard and link it to the InfluxDB container: <br />\n<code>sudo docker run -d\n-p 3000:3000\n-e INFLUXDB_HOST=localhost\n-e INFLUXDB_PORT=8086\n-e INFLUXDB_NAME=cadvisor\n-e INFLUXDB_USER=root\n-e INFLUXDB_PASS=root\n--link influxsrv:influxsrv\n--name grafana\ngrafana/grafana</code></p>\n\n<p>5) Login to Grafana and configure the Data Sources. <br />\nNavigate to <a href=\"http://DockerIP:3000\">http://DockerIP:3000</a> <br />\nUsername - admin <br />\nPassword - admin</p>\n\n<p>6) Connect the InfluxDB to the Grafana Dashboard: <br />\nOnce logged in click on the Grafana icon(Fireball) in the upper left hand corner of the GUI. This should pop out a sidebar menu. Click on <em>Data Sources</em>.</p>\n\n<p>Next, click on <em>Add New</em> Data Source at the top of the screen. <br />\nFill in the following information in the Data Source screen:</p>\n\n<p><strong>Data Source Settings</strong></p>\n\n<p>Name: influxdb <br />\nType: InfluxDB 0.8.x <br />\nBe sure to check default box.</p>\n\n<p>Http settings <br />\nUrl: <a href=\"http://influxsrv:8086\">http://influxsrv:8086</a> (This is the name we specified when createing the link on the Grafana container) <br />\nAccess: proxy <br />\nBasic Auth: Enabled <br />\nUser: admin <br />\nPassword: admin</p>\n\n<p>InfluxDB Details <br />\nDatabase: cadvisor (Or the name you specified when creating the database in step 2) <br />\nUser: root <br />\nPassword: root</p>\n\n<p>You should now have an established connection to the InfluxDB which we will test in the next section. <br />\n<img src=\"/content/images/2015/05/Grafana_Config.png\" alt=\"Grafana Data Source Configuration\" /></p>\n\n<h2 id=\"configuringgrafanafordockermonitoring\">Configuring Grafana for Docker Monitoring</h2>\n\n<p>Now comes the fun part. Let's setup our first Dashboard with Grafana and visualize the data coming from the cAdvisor.</p>\n\n<p>1) Click on the Grafana icon once again (The Fireball icon upper left corner)</p>\n\n<p>2) Open the Dashboard menu --> Expand the Home Menu drop Down --> Click <em>+New</em></p>\n\n<p>3) We've now created a new Dashboard inside of Grafana. Let's create our first graph inside this Dashboard. Click the green vertical line as seen below in the screenshot circled in Red. This expands the row options for the Dashboard.</p>\n\n<p>4) Click <em>Add Panel</em> --> <em>Graph</em></p>\n\n<p><img src=\"/content/images/2015/05/New_Dashboard.png\" alt=\"Create New Grafana Dashboard\" /></p>\n\n<p>5) Click the Title area of the new Graph you created where it says \"no title (click here)\" and click <em>Edit</em> <br />\n<img src=\"/content/images/2015/05/Create_Graph.jpg\" alt=\"Create Grafana Graph\" /></p>\n\n<p>6) It's time to write our first query for our graph. We will create a graph displaying the Filesystem storage limit and usage. <br />\n<strong>Query 1</strong> - Fill in the following information inside the Graph screen:\nseries: stats <br />\nClick on \"value\" which will present you a drop down list of available series available inside of the InfluxDB. <br />\nselect: mean(fs_limit) <br />\nAlias: Limit</p>\n\n<p><strong>Query 2</strong> - At the Bottom of Graph screen is an <em>+Add Query</em> button which allows us to add another metric to our graph.\nseries: stats <br />\nselect: mean(fs_usage) <br />\nAlias: Usage</p>\n\n<p><img src=\"/content/images/2015/05/filesystem_graph.png\" alt=\"Docker Filesystem Graph\" /></p>\n\n<p>7) Click on the General Menu and Change the Title of your Graph</p>\n\n<p>8) Click on the Axis &amp; Grid Menu <br />\nLeft Y Unit: Bytes <br />\nYour Chart should now display with the correct units.</p>\n\n<p>9) Once finished like any other project be sure to save your work. Hit the Save icon a the top of the screen.</p>\n\n<h2 id=\"dockermonitoringconclusion\">Docker Monitoring Conclusion</h2>\n\n<p>We have now built a single Grafana Dashboard with a Graph containing our Filesystem statistics. As you can see it's extremely simple to create multiple graphs to monitor our Docker Host and Containers.</p>\n\n<p>Be sure to check out the <a href=\"http://docs.grafana.org/\">Grafana Docs</a> to dive deeper with the queries and functionality of Grafana. Take a look below at the screenshot which shows the possibilities for creating some really interesting graphs (Bandwidth, CPU Usage per Container, Memory Usage, and Filesystem Limit/Usage).</p>\n\n<p><img src=\"/content/images/2015/05/Docker_Monitoring.png\" alt=\"Docker Monitoring with cAdvisor, InfluxDB, and Grafana\" /></p>\n\n<p>Leave a comment below if you have any issues or questions.</p>\n\n<p>Good Luck!</p>\n\n<h2 id=\"troubleshooting\">Troubleshooting</h2>\n\n<p>In the event you have troubles this is for you. It took me quite sometime to figure out all the settings and where the problems were with the connection from Grafana to InfluxDB. In the event you have issues with your Graphs I highly recommend a Development Console in your Browser of choice.</p>\n\n<p>With the development console it is really easy to see problems with your queries or connections to the InfluxDB container. For Example: Chrome Development Tools -> More Tools -> Javascript Console</p>\n\n<p>Another workaround is using the IP address of the containers to resolve connection issues. However, if you restart the container the IP address changes so this is only a temp fix.</p>\n\n<p><code>docker inspect &lt;container name&gt;</code></p>\n\n<p>Search the output for the IP address which is under the Network Settings section as seen below: <br />\n<code>\"NetworkSettings\": {\n        \"Bridge\": \"docker0\",\n        \"Gateway\": \"172.17.42.1\",\n        \"GlobalIPv6Address\": \"\",\n        \"GlobalIPv6PrefixLen\": 0,\n        \"IPAddress\": \"172.17.0.54\",\n</code></p>\n\n<p>You can then replace the name that we used in Data Source settings we used above as a workaround. This worked for me until I fixed the links between containers.</p>\n\n<h2 id=\"update\">Update</h2>\n\n<p>Thanks to everyone for the overwhelming response to this article. Since this article was published Dale Kate-Murray and Ross Jimenez created a <a href=\"http://bit.ly/1LFek7L\">Docker Monitoring Compose file</a> to help everyone get started.</p>\n\n<p>Another question that came up in the comments is how to build the different dashboards. So here is the JSON file from the Dashboard - <a href=\"https://github.com/vegasbrianc/docker-monitoring\">https://github.com/vegasbrianc/docker-monitoring</a></p>","image":"/content/images/2015/05/war_games_movie.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to setup Docker Monitoring","meta_description":"A Tutorial on setting up Docker Monitoring using cAdvisor, InfluxDB, and Grafana. This setup will allow you to monitor both the Docker Host and Containers.","author_id":1,"created_at":1431677668292,"created_by":1,"updated_at":1436786333671,"updated_by":1,"published_at":1432139732243,"published_by":1},{"id":38,"uuid":"321cc122-830b-43f0-a378-93585931d497","title":"Contact Brian","slug":"contact-brian-christner","markdown":"If you have the burning desire to contact me. Please fill out the form below and I will get back to you as soon as I can.\n\n## Contact Brian Christner\n<iframe src=\"https://docs.google.com/forms/d/1V91F_CTIc3ze_RC9xfTyhOBMjfr5pfWL8-JWIVgar5E/viewform?embedded=true#start=embed\" width=\"760\" height=\"800\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading...</iframe>","html":"<p>If you have the burning desire to contact me. Please fill out the form below and I will get back to you as soon as I can.</p>\n\n<h2 id=\"contactbrianchristner\">Contact Brian Christner</h2>\n\n<iframe src=\"https://docs.google.com/forms/d/1V91F_CTIc3ze_RC9xfTyhOBMjfr5pfWL8-JWIVgar5E/viewform?embedded=true#start=embed\" width=\"760\" height=\"800\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading...</iframe>","image":"/content/images/2015/05/homer_computer.png","featured":0,"page":1,"status":"published","language":"en_US","meta_title":"Contact Brian Christner","meta_description":"","author_id":1,"created_at":1432190690753,"created_by":1,"updated_at":1432191265128,"updated_by":1,"published_at":1432191056825,"published_by":1},{"id":39,"uuid":"d283e606-dd84-4767-8119-d3d45c1cbe45","title":"How to Resize Ubuntu Root Partition","slug":"how-to-resize-ubuntu-root-partition","markdown":"I used to be able to do these tasks with my eyes closed with AIX and other version of Linux and Unix. Today my brain blue screened on me while trying to expand my Ubuntu machine's root volume group, logical volume, and filesystem. Wow it's been awhile.\n\nSo instead of racking my brain in the future I will jot down the process here for anyone else stuck in the same situation. \n\n##How to expand Ubuntu root filesystem\nSo a quick recap for those that don't remember. We have to expand components of the filesystem in the following order. **Physical Volume -> Volume Group -> Logical Volume -> Filesystem**\n\nIn my scenario I increased the size of my Virtual Machine disk in VMware from 18GB to 28 GB.\n\n* **Step 1** Before we get started run *pvdisplay* in order to see the current state of the physical volume\n```\nroot@Docker01:~# pvdisplay\n--- Physical volume ---\n  PV Name               /dev/sda1\n  VG Name               ubuvg\n  PV Size               16.00 GiB / not usable 2.00 MiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              4095\n  Free PE               678\n  Allocated PE          3417\n  PV UUID               HiNAY2-sfqz-7fwT-tLvy-XKfT-3QR6-BXash5\n```\n* **Step 2** Manipulate the disk partition table with *fdisk*\n\n```\nroot@Docker01:~# fdisk /dev/sdb\nn   (create new partition, select start and end cylinders, all free space is selected by default)\nPartition type:\n   p   primary (1 primary, 0 extended, 3 free)\n   e   extended\nSelect (default p):\nUsing default response p\nPartition number (1-4, default 2):\nUsing default value 2\nFirst sector (33552384-33554431, default 33552384):\nUsing default value 33552384\nLast sector, +sectors or +size{K,M,G} (33552384-33554431, default 33554431):\nUsing default value 33554431\nw  (save partition table and exit)\n```\n==Accept the default values that are provide that the \"n\" option returns.==\n\n* **Step 3** Reboot your Ubuntu machine in order for Ubuntu to recognize the change.\n`root@Docker01:~# reboot`\n\n* **Step 4** Update the partition table tool using *cfdisk*.\n`root@Docker01:~# cfdisk`\nSelect **[NEW]** partition and **[PRIMARY]** for partition type. Select how big you want the partition and enter. \nOnce finished select **[WRITE]** to save your changes to your partition then **[QUIT]**.\nYou've now created a new partition most likely **/dev/sda1**\n![CFDisk](/content/images/2015/06/cfdisk.png)\n* **Step 5** Intialize the newly created partition with *pvcreate*\n```\nroot@Docker01:~# pvcreate /dev/sda3\nPhysical volume \"/dev/sda3\" successfully created\n```\n\n* **Step 6** Add the newly created partition to the root volume group. First rerun *pvdisplay* to show the new physical volume details. You should now see the new partition\n\n```\n  \"/dev/sda3\" is a new physical volume of \"9.00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/sda3\n  VG Name\n  PV Size               9.00 GiB\n  Allocatable           NO\n  PE Size               0\n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               OEADew-tamR-EHil-FU4p-kIuW-F5rT-V0CTcY\n```\nRun the command *vgs* in order to get the name of your volume group\n```\nroot@Docker01:~# vgs\n  VG    #PV #LV #SN Attr   VSize  VFree\n  ubuvg   1   5   0 wz--n- 16.00g 2.65g\n```\n\nExpand the volume group with *vgextend* then verify your volume group again once complete with *vgs*\n```\nroot@Docker01:~# vgextend ubuvg /dev/sda3\n  Volume group \"ubuvg\" successfully extended\nroot@Docker01:~# vgs\n  VG    #PV #LV #SN Attr   VSize  VFree\n  ubuvg   2   5   0 wz--n- 24.99g 11.64g\nroot@Docker01:~#\n\n```\n* **Step 7** Next we need to extend the Logical Volume with *lvextend*\n\n```\nroot@Docker01:~# df -k\nFilesystem                 1K-blocks    Used Available Use% Mounted on\n/dev/mapper/ubuvg-ubulv      8726456 7739868    520260  94% /\n\nroot@Docker01:~# lvextend -L +10G /dev/mapper/ubuvg-ubulv\n  Extending logical volume ubulv to 18.58 GiB\n  Logical volume ubulv successfully resized\n```\n\n* **Step 8** Extend the Filesystem to fill the logical volume\n```\nroot@Docker01:~# resize2fs /dev/mapper/ubuvg-ubulv\nresize2fs 1.42.9 (4-Feb-2014)\nFilesystem at /dev/mapper/ubuvg-ubulv is mounted on /; on-line resizing required\nold_desc_blocks = 1, new_desc_blocks = 2\nThe filesystem on /dev/mapper/ubuvg-ubulv is now 4871168 blocks long.\n\nroot@Docker01:~# df -k\nFilesystem                 1K-blocks    Used Available Use% Mounted on\n/dev/mapper/ubuvg-ubulv     19048316 7744220  10420152  43% /\n```\n\n### Ubuntu Root Resize in Review\nHopefully this tutorial will save you time and give you a little more background on the flow of a resize. Important to remember is the path of the resize **Physical Volume -> Volume Group -> Logical Volume -> Filesystem**. We must follow this flow or the resize will either fail or encounter problems. If you use the Ubuntu GUI some tools contain the entire process in a single tool.\n\nI'm a CLI junkie so no plans of me finding out how a GUI works anytime soon. \n","html":"<p>I used to be able to do these tasks with my eyes closed with AIX and other version of Linux and Unix. Today my brain blue screened on me while trying to expand my Ubuntu machine's root volume group, logical volume, and filesystem. Wow it's been awhile.</p>\n\n<p>So instead of racking my brain in the future I will jot down the process here for anyone else stuck in the same situation. </p>\n\n<h2 id=\"howtoexpandubunturootfilesystem\">How to expand Ubuntu root filesystem</h2>\n\n<p>So a quick recap for those that don't remember. We have to expand components of the filesystem in the following order. <strong>Physical Volume -> Volume Group -> Logical Volume -> Filesystem</strong></p>\n\n<p>In my scenario I increased the size of my Virtual Machine disk in VMware from 18GB to 28 GB.</p>\n\n<ul>\n<li><strong>Step 1</strong> Before we get started run <em>pvdisplay</em> in order to see the current state of the physical volume</li>\n</ul>\n\n<pre><code>root@Docker01:~# pvdisplay  \n--- Physical volume ---\n  PV Name               /dev/sda1\n  VG Name               ubuvg\n  PV Size               16.00 GiB / not usable 2.00 MiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              4095\n  Free PE               678\n  Allocated PE          3417\n  PV UUID               HiNAY2-sfqz-7fwT-tLvy-XKfT-3QR6-BXash5\n</code></pre>\n\n<ul>\n<li><strong>Step 2</strong> Manipulate the disk partition table with <em>fdisk</em></li>\n</ul>\n\n<pre><code>root@Docker01:~# fdisk /dev/sdb  \nn   (create new partition, select start and end cylinders, all free space is selected by default)  \nPartition type:  \n   p   primary (1 primary, 0 extended, 3 free)\n   e   extended\nSelect (default p):  \nUsing default response p  \nPartition number (1-4, default 2):  \nUsing default value 2  \nFirst sector (33552384-33554431, default 33552384):  \nUsing default value 33552384  \nLast sector, +sectors or +size{K,M,G} (33552384-33554431, default 33554431):  \nUsing default value 33554431  \nw  (save partition table and exit)  \n</code></pre>\n\n<p><mark>Accept the default values that are provide that the \"n\" option returns.</mark></p>\n\n<ul>\n<li><p><strong>Step 3</strong> Reboot your Ubuntu machine in order for Ubuntu to recognize the change.\n<code>root@Docker01:~# reboot</code></p></li>\n<li><p><strong>Step 4</strong> Update the partition table tool using <em>cfdisk</em>.\n<code>root@Docker01:~# cfdisk</code>\nSelect <strong>[NEW]</strong> partition and <strong>[PRIMARY]</strong> for partition type. Select how big you want the partition and enter. <br />\nOnce finished select <strong>[WRITE]</strong> to save your changes to your partition then <strong>[QUIT]</strong>. <br />\nYou've now created a new partition most likely <strong>/dev/sda1</strong> <br />\n<img src=\"/content/images/2015/06/cfdisk.png\" alt=\"CFDisk\" /></p></li>\n<li><strong>Step 5</strong> Intialize the newly created partition with <em>pvcreate</em></li>\n</ul>\n\n<pre><code>root@Docker01:~# pvcreate /dev/sda3  \nPhysical volume \"/dev/sda3\" successfully created  \n</code></pre>\n\n<ul>\n<li><strong>Step 6</strong> Add the newly created partition to the root volume group. First rerun <em>pvdisplay</em> to show the new physical volume details. You should now see the new partition</li>\n</ul>\n\n<pre><code>  \"/dev/sda3\" is a new physical volume of \"9.00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/sda3\n  VG Name\n  PV Size               9.00 GiB\n  Allocatable           NO\n  PE Size               0\n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               OEADew-tamR-EHil-FU4p-kIuW-F5rT-V0CTcY\n</code></pre>\n\n<p>Run the command <em>vgs</em> in order to get the name of your volume group  </p>\n\n<pre><code>root@Docker01:~# vgs  \n  VG    #PV #LV #SN Attr   VSize  VFree\n  ubuvg   1   5   0 wz--n- 16.00g 2.65g\n</code></pre>\n\n<p>Expand the volume group with <em>vgextend</em> then verify your volume group again once complete with <em>vgs</em>  </p>\n\n<pre><code>root@Docker01:~# vgextend ubuvg /dev/sda3  \n  Volume group \"ubuvg\" successfully extended\nroot@Docker01:~# vgs  \n  VG    #PV #LV #SN Attr   VSize  VFree\n  ubuvg   2   5   0 wz--n- 24.99g 11.64g\nroot@Docker01:~#\n</code></pre>\n\n<ul>\n<li><strong>Step 7</strong> Next we need to extend the Logical Volume with <em>lvextend</em></li>\n</ul>\n\n<pre><code>root@Docker01:~# df -k  \nFilesystem                 1K-blocks    Used Available Use% Mounted on  \n/dev/mapper/ubuvg-ubulv      8726456 7739868    520260  94% /\n\nroot@Docker01:~# lvextend -L +10G /dev/mapper/ubuvg-ubulv  \n  Extending logical volume ubulv to 18.58 GiB\n  Logical volume ubulv successfully resized\n</code></pre>\n\n<ul>\n<li><strong>Step 8</strong> Extend the Filesystem to fill the logical volume</li>\n</ul>\n\n<pre><code>root@Docker01:~# resize2fs /dev/mapper/ubuvg-ubulv  \nresize2fs 1.42.9 (4-Feb-2014)  \nFilesystem at /dev/mapper/ubuvg-ubulv is mounted on /; on-line resizing required  \nold_desc_blocks = 1, new_desc_blocks = 2  \nThe filesystem on /dev/mapper/ubuvg-ubulv is now 4871168 blocks long.\n\nroot@Docker01:~# df -k  \nFilesystem                 1K-blocks    Used Available Use% Mounted on  \n/dev/mapper/ubuvg-ubulv     19048316 7744220  10420152  43% /\n</code></pre>\n\n<h3 id=\"ubunturootresizeinreview\">Ubuntu Root Resize in Review</h3>\n\n<p>Hopefully this tutorial will save you time and give you a little more background on the flow of a resize. Important to remember is the path of the resize <strong>Physical Volume -> Volume Group -> Logical Volume -> Filesystem</strong>. We must follow this flow or the resize will either fail or encounter problems. If you use the Ubuntu GUI some tools contain the entire process in a single tool.</p>\n\n<p>I'm a CLI junkie so no plans of me finding out how a GUI works anytime soon. </p>","image":"/content/images/2015/06/ubuntu-penguin.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to Resize Ubuntu Root Partition","meta_description":"A quick and dirty tutorial on resizing a root Ubuntu partition via the command line and why we follow a particular process.","author_id":1,"created_at":1432209730163,"created_by":1,"updated_at":1433247906879,"updated_by":1,"published_at":1433247906882,"published_by":1},{"id":40,"uuid":"7d15ca47-7454-4a58-b3ef-0e0e0e30ec4d","title":"Docker Base Image OS Size Comparison","slug":"docker-image-base-os-size-comparison","markdown":"The race to zero is a theme that is catching on with Docker Images. Developers are racing to create the thinest most usable image possible. But why, do you ask?\n\nIf you've used Docker for any period of time then you will quickly realize that you spend a lot of time downloading or distributing images. This is not necessarily a bad thing for some but for others that scale their infrastructure are required to store a copy of every image that's running on each Docker host. If you are running the Ubuntu base image then you will need to store the 188MB image on each host. However, if you have a scenario that scales your application to a new host then you will not want to wait for the download of 188MB to complete before your container starts. Feel me?\n\nDevelopers are working in much the same way as a race car mechanic would. The goal is to strip all the unnecessary weight off the race car leaving just the bare essentials. Same goes for our Docker images. Do we need every Linux commands, library, etc inside of our container to run a Hello World script? Probably not. Why not install just the bare essentials required to run the application thats inside of your container.\n\n## Benefits of Smaller Docker Images \nWhat are the benefits of smaller images you ask? Besides the obvious which is pure size it also makes your environment small and efficient. Small images all increase security as you reduce your security footprint size.\n\n## Docker Image Size Comparison\nThe team over at [CenturyLink Labs](http://www.centurylinklabs.com/) continue to crank out some very impressive tools. Below is a screenshot from [ImageLayers](https://imagelayers.io) which is a tool to visualize Docker images. But the tool doesn't stop there. You can actually compare the images per layer and visualize every what each layer is doing.\n![Docker Image Size Comparison](/content/images/2015/07/Docker_Image_Size.png)\n\nSo what does our comparison show us? Reading from left to right the number of layers in each image decreases as you read to the right. We also notice that Ubuntu for example has 4 Layers and is 188MB while Alpine Linux has 1 Layer and is 5MB. However, Busybox is the smallest image but has 2x0 byte layers which are not bad.\n\n## Docker Image Size Run Down\nWe compiled a list of some of the most popular Base OS Images based on Docker Hub downloads and File Size. The list is not who is best or worst but a an overview of the usage by the community and image size. The best image will depend on your environment and application requirements.\n\n* **[Ubuntu](https://registry.hub.docker.com/_/ubuntu/) 6.5 Million Downloads and 188 MB in size** - The most downloaded OS image of the bunch. But it is also the fattest cat on the block as well.\n\n* **[Debian](https://registry.hub.docker.com/u/library/debian/) 3.3 Million Downloads and 125 MB in size** - Debian uses the Linux aka FreeBSD kernel and the basic tools are based on the GNU Project.\n\n* **[BusyBox](https://registry.hub.docker.com/_/busybox/) 2.5 Million Downloads and 2 MB in size** - BusyBox webiste statest \"Busybox has been written with size-optimization and limited resources in mind. It is also extremely modular so you can easily include or exclude commands (or features) at compile time. This makes it easy to customize your embedded systems. To create a working system, just add some device nodes in /dev, a few configuration files in /etc, and a Linux kernel.\"\n\n* **[CentOS](https://registry.hub.docker.com/_/centos/) 1.2 Million Downloads and 172 MB in size** - Derived from Red Hat Linux Enterprise RHEL and each version is supported for 10 years.\n\n* **[Fedora](https://registry.hub.docker.com/_/fedora/) 1.2 Million Downloads and 187 MB in size** - Sponsored by Red Hat Linux Enterprise and strives to drive new innovation.\n\n* **[Alpine](https://registry.hub.docker.com/_/alpine/) 40K+ Downloads and 5 MB in size** - A more complete Busybox image with access to a package repository. My personal favorite at the moment.\n\n* **[Cirros](https://registry.hub.docker.com/_/cirros/) 23K+ Downloads and 8 MB in size** - Is a tiny OS that specializes running in the cloud. It is also the image that has the most amount of layers at 5.\n\nHere's the link to the comparison so you can dive deeper per image - [Docker OS Image Comparison](https://imagelayers.io/?images=ubuntu:latest,centos:latest,opensuse:latest,busybox:latest,alpine:latest,debian:latest,fedora:latest,cirros:latest)\n\n## Conclusion\nBusybox wins the size war weighing in at only 2MB. However, Ubuntu has the biggest installation base by far and is also the fattest image. What can we learn from these stats? At first glance it appears a lot of Docker users have a lot of room for optimization and making their infrastructures more efficient.\n\nUbuntu is a good Image and has many use cases. However, if you want to cut out all the fluff and only run the necessary components for your application I would recommend either Busybox or Alpine.\n\nI will dive deeper in the next article uncovering best practices for Docker Images and why we should limit the amount of OS images we install on our hosts.","html":"<p>The race to zero is a theme that is catching on with Docker Images. Developers are racing to create the thinest most usable image possible. But why, do you ask?</p>\n\n<p>If you've used Docker for any period of time then you will quickly realize that you spend a lot of time downloading or distributing images. This is not necessarily a bad thing for some but for others that scale their infrastructure are required to store a copy of every image that's running on each Docker host. If you are running the Ubuntu base image then you will need to store the 188MB image on each host. However, if you have a scenario that scales your application to a new host then you will not want to wait for the download of 188MB to complete before your container starts. Feel me?</p>\n\n<p>Developers are working in much the same way as a race car mechanic would. The goal is to strip all the unnecessary weight off the race car leaving just the bare essentials. Same goes for our Docker images. Do we need every Linux commands, library, etc inside of our container to run a Hello World script? Probably not. Why not install just the bare essentials required to run the application thats inside of your container.</p>\n\n<h2 id=\"benefitsofsmallerdockerimages\">Benefits of Smaller Docker Images</h2>\n\n<p>What are the benefits of smaller images you ask? Besides the obvious which is pure size it also makes your environment small and efficient. Small images all increase security as you reduce your security footprint size.</p>\n\n<h2 id=\"dockerimagesizecomparison\">Docker Image Size Comparison</h2>\n\n<p>The team over at <a href=\"http://www.centurylinklabs.com/\">CenturyLink Labs</a> continue to crank out some very impressive tools. Below is a screenshot from <a href=\"https://imagelayers.io\">ImageLayers</a> which is a tool to visualize Docker images. But the tool doesn't stop there. You can actually compare the images per layer and visualize every what each layer is doing. <br />\n<img src=\"/content/images/2015/07/Docker_Image_Size.png\" alt=\"Docker Image Size Comparison\" /></p>\n\n<p>So what does our comparison show us? Reading from left to right the number of layers in each image decreases as you read to the right. We also notice that Ubuntu for example has 4 Layers and is 188MB while Alpine Linux has 1 Layer and is 5MB. However, Busybox is the smallest image but has 2x0 byte layers which are not bad.</p>\n\n<h2 id=\"dockerimagesizerundown\">Docker Image Size Run Down</h2>\n\n<p>We compiled a list of some of the most popular Base OS Images based on Docker Hub downloads and File Size. The list is not who is best or worst but a an overview of the usage by the community and image size. The best image will depend on your environment and application requirements.</p>\n\n<ul>\n<li><p><strong><a href=\"https://registry.hub.docker.com/_/ubuntu/\">Ubuntu</a> 6.5 Million Downloads and 188 MB in size</strong> - The most downloaded OS image of the bunch. But it is also the fattest cat on the block as well.</p></li>\n<li><p><strong><a href=\"https://registry.hub.docker.com/u/library/debian/\">Debian</a> 3.3 Million Downloads and 125 MB in size</strong> - Debian uses the Linux aka FreeBSD kernel and the basic tools are based on the GNU Project.</p></li>\n<li><p><strong><a href=\"https://registry.hub.docker.com/_/busybox/\">BusyBox</a> 2.5 Million Downloads and 2 MB in size</strong> - BusyBox webiste statest \"Busybox has been written with size-optimization and limited resources in mind. It is also extremely modular so you can easily include or exclude commands (or features) at compile time. This makes it easy to customize your embedded systems. To create a working system, just add some device nodes in /dev, a few configuration files in /etc, and a Linux kernel.\"</p></li>\n<li><p><strong><a href=\"https://registry.hub.docker.com/_/centos/\">CentOS</a> 1.2 Million Downloads and 172 MB in size</strong> - Derived from Red Hat Linux Enterprise RHEL and each version is supported for 10 years.</p></li>\n<li><p><strong><a href=\"https://registry.hub.docker.com/_/fedora/\">Fedora</a> 1.2 Million Downloads and 187 MB in size</strong> - Sponsored by Red Hat Linux Enterprise and strives to drive new innovation.</p></li>\n<li><p><strong><a href=\"https://registry.hub.docker.com/_/alpine/\">Alpine</a> 40K+ Downloads and 5 MB in size</strong> - A more complete Busybox image with access to a package repository. My personal favorite at the moment.</p></li>\n<li><p><strong><a href=\"https://registry.hub.docker.com/_/cirros/\">Cirros</a> 23K+ Downloads and 8 MB in size</strong> - Is a tiny OS that specializes running in the cloud. It is also the image that has the most amount of layers at 5.</p></li>\n</ul>\n\n<p>Here's the link to the comparison so you can dive deeper per image - <a href=\"https://imagelayers.io/?images=ubuntu:latest,centos:latest,opensuse:latest,busybox:latest,alpine:latest,debian:latest,fedora:latest,cirros:latest\">Docker OS Image Comparison</a></p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Busybox wins the size war weighing in at only 2MB. However, Ubuntu has the biggest installation base by far and is also the fattest image. What can we learn from these stats? At first glance it appears a lot of Docker users have a lot of room for optimization and making their infrastructures more efficient.</p>\n\n<p>Ubuntu is a good Image and has many use cases. However, if you want to cut out all the fluff and only run the necessary components for your application I would recommend either Busybox or Alpine.</p>\n\n<p>I will dive deeper in the next article uncovering best practices for Docker Images and why we should limit the amount of OS images we install on our hosts.</p>","image":"/content/images/2015/07/Docker-Containers.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"Docker Base OS Image Size Comparison","meta_description":"I compare the most popular Docker Base OS Images and explain why smaller is better.","author_id":1,"created_at":1433434151609,"created_by":1,"updated_at":1437044909151,"updated_by":1,"published_at":1437044412199,"published_by":1},{"id":41,"uuid":"7ede25b9-a250-43ad-b4af-92959098c95a","title":"Docker Images Best Practices","slug":"docker-images-best-practices","markdown":"","html":"","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1437041563166,"created_by":1,"updated_at":1437041563166,"updated_by":1,"published_at":null,"published_by":null},{"id":43,"uuid":"f1a13329-0857-43d8-a28d-0ff48a6808df","title":"How to setup Prometheus Docker Monitoring","slug":"how-to-setup-prometheus-docker-monitoring","markdown":"Continuing with the great response from the [Docker Monitoring](https://www.brianchristner.io/how-to-setup-docker-monitoring/) post. I am following up by investigating the setup of Prometheus. I first discovered Prometheus while making some changes to the [cAdvisor](https://github.com/google/cadvisor) documentation and noticed that cAdvisor now integrates with Prometheus.\n\nSo what is Prometheus? Prometheus was a solution created by SoundCloud (Yes, that SoundCloud). ~~As current Docker monitoring solutions were not scratching their itch they decided to roll their own solution to suit their needs. Thankfully SoundCloud decided to Open Source Prometheus back in January 2015 as it is a great product. Take a look at the [SoundCloud's blog](back in January 2015) for more details about the release.\n~~ **UPDATE:** [Tobi](https://twitter.com/dagrobie) from Sound Cloud clarified this paragraph. Sound Cloud created Prometheus as a general monitoring solution that recently integrated Docker. Also, Prometheus has been open source sine the beginning but only announced beginning of this year. Thanks Tobi!\n\nOK, enough beating around the bush. How the heck can we deploy a Prometheus Docker Monitoring stack? I spent a lot of time fine tuning the docker-compose file so you can easily stand up a Prometheus stack with all the required components to quickly get up and running. \n\n##Pre-requisites\nBefore we get started installing the Prometheus stack. Ensure you install [docker-compose](https://docs.docker.com/compose/install/) on your Docker host machine.\n\n##Installation & Configuration\nClone the project [Prometheus Monitoring Project](https://github.com/vegasbrianc/prometheus) locally to your Docker host. \n\nIf you would like to change which targets should be monitored or make configuration changes edit the [/prom/prometheus.yml](https://github.com/vegasbrianc/prometheus/blob/master/prom/prometheus.yml#L30) file. The targets section. The targets section is where you define which componets(data exporters) should be monitored by Prometheus. The names defined in this file are actually sourced from the service name in the docker-compose file. If you wish to change names of the services change the \"container_name\" parameter in the docker-compose.yml file. \n\nOnce configurations are done let's start it up. From the /prometheus project directory run the following commands:\n\n    $ docker-compose up\n    $ docker-compose start\n\nThe Prometheus stack should now be running. To access the different components:\n\nPrometheus: `http://<Host IP Address>:9090>` for example http://192.168.10.1:9090\n\nPrometheus Dashboard: `http://<Host IP Address>:3000` for example http://192.168.10.1:3000\n\n## Post Configuration\nNow we need to connect the Prometheus Dashboard to the Prometheus installation. Access the Prom Dash as mentioned above. \n* Click the \"Server\" Menu at the top\n* Click \"New Server\"\n* Input desired name, Prometheus server IP and port (`http://<Host IP Address>:9090>` ) and select Prometheus for server type.\n\n![New Prometheus Server](/content/images/2015/08/New_server.png)\n\n## Configure Dashboards\nLet's create our first Dashboard. Head over up to the Dashboard menu. First, create a new directory. Next, create a new Dashboard.\n\nHere's a quick Dashboard I put together as an example.\n![Prometheus Dashboard](/content/images/2015/08/Dashboard_example.png)\n\n## ToDo \n* Integrate Alerting with project\n* Make a separate stack with just cAdvisor as the metric collection\n\n","html":"<p>Continuing with the great response from the <a href=\"https://www.brianchristner.io/how-to-setup-docker-monitoring/\">Docker Monitoring</a> post. I am following up by investigating the setup of Prometheus. I first discovered Prometheus while making some changes to the <a href=\"https://github.com/google/cadvisor\">cAdvisor</a> documentation and noticed that cAdvisor now integrates with Prometheus.</p>\n\n<p>So what is Prometheus? Prometheus was a solution created by SoundCloud (Yes, that SoundCloud). <del>As current Docker monitoring solutions were not scratching their itch they decided to roll their own solution to suit their needs. Thankfully SoundCloud decided to Open Source Prometheus back in January 2015 as it is a great product. Take a look at the <a href=\"back in January 2015\">SoundCloud's blog</a> for more details about the release. <br />\n</del> <strong>UPDATE:</strong> <a href=\"https://twitter.com/dagrobie\">Tobi</a> from Sound Cloud clarified this paragraph. Sound Cloud created Prometheus as a general monitoring solution that recently integrated Docker. Also, Prometheus has been open source sine the beginning but only announced beginning of this year. Thanks Tobi!</p>\n\n<p>OK, enough beating around the bush. How the heck can we deploy a Prometheus Docker Monitoring stack? I spent a lot of time fine tuning the docker-compose file so you can easily stand up a Prometheus stack with all the required components to quickly get up and running. </p>\n\n<h2 id=\"prerequisites\">Pre-requisites</h2>\n\n<p>Before we get started installing the Prometheus stack. Ensure you install <a href=\"https://docs.docker.com/compose/install/\">docker-compose</a> on your Docker host machine.</p>\n\n<h2 id=\"installationconfiguration\">Installation &amp; Configuration</h2>\n\n<p>Clone the project <a href=\"https://github.com/vegasbrianc/prometheus\">Prometheus Monitoring Project</a> locally to your Docker host. </p>\n\n<p>If you would like to change which targets should be monitored or make configuration changes edit the <a href=\"https://github.com/vegasbrianc/prometheus/blob/master/prom/prometheus.yml#L30\">/prom/prometheus.yml</a> file. The targets section. The targets section is where you define which componets(data exporters) should be monitored by Prometheus. The names defined in this file are actually sourced from the service name in the docker-compose file. If you wish to change names of the services change the \"container_name\" parameter in the docker-compose.yml file. </p>\n\n<p>Once configurations are done let's start it up. From the /prometheus project directory run the following commands:</p>\n\n<pre><code>$ docker-compose up\n$ docker-compose start\n</code></pre>\n\n<p>The Prometheus stack should now be running. To access the different components:</p>\n\n<p>Prometheus: <code>http://&lt;Host IP Address&gt;:9090&gt;</code> for example <a href=\"http://192.168.10.1:9090\">http://192.168.10.1:9090</a></p>\n\n<p>Prometheus Dashboard: <code>http://&lt;Host IP Address&gt;:3000</code> for example <a href=\"http://192.168.10.1:3000\">http://192.168.10.1:3000</a></p>\n\n<h2 id=\"postconfiguration\">Post Configuration</h2>\n\n<p>Now we need to connect the Prometheus Dashboard to the Prometheus installation. Access the Prom Dash as mentioned above. <br />\n* Click the \"Server\" Menu at the top\n* Click \"New Server\"\n* Input desired name, Prometheus server IP and port (<code>http://&lt;Host IP Address&gt;:9090&gt;</code> ) and select Prometheus for server type.</p>\n\n<p><img src=\"/content/images/2015/08/New_server.png\" alt=\"New Prometheus Server\" /></p>\n\n<h2 id=\"configuredashboards\">Configure Dashboards</h2>\n\n<p>Let's create our first Dashboard. Head over up to the Dashboard menu. First, create a new directory. Next, create a new Dashboard.</p>\n\n<p>Here's a quick Dashboard I put together as an example. <br />\n<img src=\"/content/images/2015/08/Dashboard_example.png\" alt=\"Prometheus Dashboard\" /></p>\n\n<h2 id=\"todo\">ToDo</h2>\n\n<ul>\n<li>Integrate Alerting with project</li>\n<li>Make a separate stack with just cAdvisor as the metric collection</li>\n</ul>","image":"/content/images/2015/08/Dashboard_example-1.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to setup a Docker Monitoring Prometheus stack","meta_description":"We designed a simple tutorial on how to easily get up and running with Prometheus and start monitoring your Docker Host and containers.","author_id":1,"created_at":1439980922802,"created_by":1,"updated_at":1440053770458,"updated_by":1,"published_at":1439983619703,"published_by":1},{"id":44,"uuid":"67fca99e-2ab9-4222-9b20-afaf07f8fb23","title":"How to scale Docker Containers with Docker-Compose","slug":"how-to-scale-a-docker-container-with-docker-compose","markdown":"I've been working on a few projects at the moment and scaling keeps coming to a head. So let's take a look on how to scale a Docker web services stack with Docker-Compose. Before we get started we need to lay a bit of ground work. \n\nWhat we are building is a web service with three components that are built, configured, and deployed via docker-compose.\n\n1. HAProxy which provides us with round-robin load balancing\n2. Web Application based on Python\n3. Redis Database \n![Docker Loadbalanced Web Service](/content/images/2015/09/LB_Webapp.gif)\n\nThe HAProxy receives the web requests and routes it to the single web service which prints the hostname of the container that receives the request where a counter is incremented, and this value is then stored in the Redis Database.\n\nNow let's scale our stack out to 5 web instances/containers that are  now load balanced and still connected to the Redis DB. Docker-compose easily scales our service from 1 to 5 instances. Once the web services scales out to 5 we need to inform the Database and HAProxy of these changes so they can accept and route traffic accordingly.\n![Scaling Docker containers with Docker-Compose](/content/images/2015/09/Scaled_Services.gif)\n\nAs before the web requests are received by the HAProxy but are now routed round-robin to all 5 of the web service instances. All these instances are also linked to the Redis DB and thus our application prints the hostname and increments the number of visits works flawlessly all while printing the hostname from each container that responds. We can also scale the the web service back to 1 container when we are done.\n\n# DEMO - How to scale Docker Containers with Docker-Compose\nYou can find the contents of this demo on my [Github/vegasbrianc](https://github.com/vegasbrianc/docker-compose-demo) page \n\n### Install\nThe instructions assume that you have already installed [Docker](https://docs.docker.com/installation/) and [Docker Compose](https://docs.docker.com/compose/install/). \n\nIn order to get started be sure to clone [this project](https://github.com/vegasbrianc/docker-compose-demo) onto your Docker Host. Create a directory on your host. Please note that the web services will inherit the name from the directory you create. If you create a folder named test. Then the services will all be named test-web, test-redis, test-lb. Also, when you scale your services it will then tack on a number to the end of the service you scale. \n\n    git clone https://github.com/vegasbrianc/docker-compose-demo.git .\n\n#### How to get up and running\nOnce you've cloned the project to your host we can now start our demo project. Easy! Navigate to the directory in which you cloned the project. Run the following commands from this directory \n\n    docker-compose up -d\n\nThe  docker-compose command will pull the images from Docker Hub and then link them together based on the information inside the docker-compose.yml file. This will create ports, links between containers, and configure applications as required. After the command completes we can now view the status of our stack\n\n    docker-compose ps\n\nVerify our service is running by either curlng the IP from the command line or view the IP from a web browser. You will notice that the each time you run the command the number of times seen is stored in the Redis Database which increments. The hostname is also reported.\n\n###Curling from the command line\n    curl 0.0.0.0\n    \n    Hello World!\n    I have been seen 1 times.\n    My Host name is 29c69c89417c\n\n#### Scaling\nNow comes the fun part of compose which is scaling. Let's scale our web service from 1 instance to 5 instances.\n\n    docker-compose scale web=5\n    \nWe have now scaled our web service container. We now should run an update on our stack so the Load balancer and Redis are informed about the new web service containers. We found after updating docker and docker-compose we had to add the --force-recreate flag in order for the container to actually load balance the new containers. Thanks to [Sharry Stowell](https://github.com/molinto) for finding this bug.\n\n    docker-compose up --force-recreate -d\n\nNow run our curl command again on our web services and we will now see the number of visits increase and the hostname change. To get a deeper understanding tail the logs of the stack to watch what happens each time you access your web services with curl.\n\n    docker-compose logs\n\nHere's the output from my docker-compose logs after I curled my application 5 times so it is clear that the round-robin is sent to all 5 web service containers.\n\n    web_5   | 172.17.1.140 - - [04/Sep/2015 14:11:34] \"GET /     HTTP/1.1\" 200 -\n    web_1   | 172.17.1.140 - - [04/Sep/2015 14:11:43] \"GET /         HTTP/1.1\" 200 -\n    web_2   | 172.17.1.140 - - [04/Sep/2015 14:11:46] \"GET / HTTP/1.1\" 200 -\n    web_3   | 172.17.1.140 - - [04/Sep/2015 14:11:48] \"GET / HTTP/1.1\" 200 -\n    web_4   | 172.17.1.140 - - [04/Sep/2015 14:14:19] \"GET / HTTP/1.1\" 200 -","html":"<p>I've been working on a few projects at the moment and scaling keeps coming to a head. So let's take a look on how to scale a Docker web services stack with Docker-Compose. Before we get started we need to lay a bit of ground work. </p>\n\n<p>What we are building is a web service with three components that are built, configured, and deployed via docker-compose.</p>\n\n<ol>\n<li>HAProxy which provides us with round-robin load balancing  </li>\n<li>Web Application based on Python  </li>\n<li>Redis Database <br />\n<img src=\"/content/images/2015/09/LB_Webapp.gif\" alt=\"Docker Loadbalanced Web Service\" /></li>\n</ol>\n\n<p>The HAProxy receives the web requests and routes it to the single web service which prints the hostname of the container that receives the request where a counter is incremented, and this value is then stored in the Redis Database.</p>\n\n<p>Now let's scale our stack out to 5 web instances/containers that are  now load balanced and still connected to the Redis DB. Docker-compose easily scales our service from 1 to 5 instances. Once the web services scales out to 5 we need to inform the Database and HAProxy of these changes so they can accept and route traffic accordingly. <br />\n<img src=\"/content/images/2015/09/Scaled_Services.gif\" alt=\"Scaling Docker containers with Docker-Compose\" /></p>\n\n<p>As before the web requests are received by the HAProxy but are now routed round-robin to all 5 of the web service instances. All these instances are also linked to the Redis DB and thus our application prints the hostname and increments the number of visits works flawlessly all while printing the hostname from each container that responds. We can also scale the the web service back to 1 container when we are done.</p>\n\n<h1 id=\"demohowtoscaledockercontainerswithdockercompose\">DEMO - How to scale Docker Containers with Docker-Compose</h1>\n\n<p>You can find the contents of this demo on my <a href=\"https://github.com/vegasbrianc/docker-compose-demo\">Github/vegasbrianc</a> page </p>\n\n<h3 id=\"install\">Install</h3>\n\n<p>The instructions assume that you have already installed <a href=\"https://docs.docker.com/installation/\">Docker</a> and <a href=\"https://docs.docker.com/compose/install/\">Docker Compose</a>. </p>\n\n<p>In order to get started be sure to clone <a href=\"https://github.com/vegasbrianc/docker-compose-demo\">this project</a> onto your Docker Host. Create a directory on your host. Please note that the web services will inherit the name from the directory you create. If you create a folder named test. Then the services will all be named test-web, test-redis, test-lb. Also, when you scale your services it will then tack on a number to the end of the service you scale. </p>\n\n<pre><code>git clone https://github.com/vegasbrianc/docker-compose-demo.git .\n</code></pre>\n\n<h4 id=\"howtogetupandrunning\">How to get up and running</h4>\n\n<p>Once you've cloned the project to your host we can now start our demo project. Easy! Navigate to the directory in which you cloned the project. Run the following commands from this directory </p>\n\n<pre><code>docker-compose up -d\n</code></pre>\n\n<p>The  docker-compose command will pull the images from Docker Hub and then link them together based on the information inside the docker-compose.yml file. This will create ports, links between containers, and configure applications as required. After the command completes we can now view the status of our stack</p>\n\n<pre><code>docker-compose ps\n</code></pre>\n\n<p>Verify our service is running by either curlng the IP from the command line or view the IP from a web browser. You will notice that the each time you run the command the number of times seen is stored in the Redis Database which increments. The hostname is also reported.</p>\n\n<h3 id=\"curlingfromthecommandline\">Curling from the command line</h3>\n\n<pre><code>curl 0.0.0.0\n\nHello World!\nI have been seen 1 times.\nMy Host name is 29c69c89417c\n</code></pre>\n\n<h4 id=\"scaling\">Scaling</h4>\n\n<p>Now comes the fun part of compose which is scaling. Let's scale our web service from 1 instance to 5 instances.</p>\n\n<pre><code>docker-compose scale web=5\n</code></pre>\n\n<p>We have now scaled our web service container. We now should run an update on our stack so the Load balancer and Redis are informed about the new web service containers. We found after updating docker and docker-compose we had to add the --force-recreate flag in order for the container to actually load balance the new containers. Thanks to <a href=\"https://github.com/molinto\">Sharry Stowell</a> for finding this bug.</p>\n\n<pre><code>docker-compose up --force-recreate -d\n</code></pre>\n\n<p>Now run our curl command again on our web services and we will now see the number of visits increase and the hostname change. To get a deeper understanding tail the logs of the stack to watch what happens each time you access your web services with curl.</p>\n\n<pre><code>docker-compose logs\n</code></pre>\n\n<p>Here's the output from my docker-compose logs after I curled my application 5 times so it is clear that the round-robin is sent to all 5 web service containers.</p>\n\n<pre><code>web_5   | 172.17.1.140 - - [04/Sep/2015 14:11:34] \"GET /     HTTP/1.1\" 200 -\nweb_1   | 172.17.1.140 - - [04/Sep/2015 14:11:43] \"GET /         HTTP/1.1\" 200 -\nweb_2   | 172.17.1.140 - - [04/Sep/2015 14:11:46] \"GET / HTTP/1.1\" 200 -\nweb_3   | 172.17.1.140 - - [04/Sep/2015 14:11:48] \"GET / HTTP/1.1\" 200 -\nweb_4   | 172.17.1.140 - - [04/Sep/2015 14:14:19] \"GET / HTTP/1.1\" 200 -\n</code></pre>","image":"/content/images/2015/09/scaled-containers.jpg","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"How to scale Docker Containers with Docker-Compose","meta_description":"A tutorial on how to use Docker-Compose to scale a web service that is load balanced and connected to a Redis database.","author_id":1,"created_at":1441290248757,"created_by":1,"updated_at":1442488966240,"updated_by":1,"published_at":1441377328040,"published_by":1}],"users":[{"id":1,"uuid":"fadc5a01-973b-4d61-88fb-99bd311d9904","name":"Brian Christner","slug":"brian","password":"$2a$10$an6Wl/VTKZv4/BsBBXh7hOaygn6HsT2Cv.vxwFNBlnkQixA3dFmoq","email":"brian.christner@gmail.com","image":"/content/images/2014/12/b2-2.jpg","cover":null,"bio":"The Swiss Army knife of cloud computing specializing in Linux, Docker, IaaS, PaaS, or anything with a .io domain name. I enjoy riding my motorcycle, the outdoors, and open source projects.","website":"https://www.brianchristner.io/aboutme","location":"Switzerland","accessibility":null,"status":"active","language":"en_US","meta_title":null,"meta_description":null,"last_login":1442484444558,"created_at":1411456686355,"created_by":1,"updated_at":1442484444559,"updated_by":1}],"roles":[{"id":1,"uuid":"cac7efe9-7cea-45ea-9fe4-1e9dbcd7ee6f","name":"Administrator","description":"Administrators","created_at":1411456685378,"created_by":1,"updated_at":1411456685378,"updated_by":1},{"id":2,"uuid":"6c094d33-360d-427a-b026-109fafe2c3de","name":"Editor","description":"Editors","created_at":1411456685380,"created_by":1,"updated_at":1411456685380,"updated_by":1},{"id":3,"uuid":"86978d39-690a-4089-ba57-cc23621f85b5","name":"Author","description":"Authors","created_at":1411456685380,"created_by":1,"updated_at":1411456685380,"updated_by":1},{"id":4,"uuid":"3a848851-189d-4c85-aff3-45f8bc88525b","name":"Owner","description":"Blog Owner","created_at":1411456685380,"created_by":1,"updated_at":1411456685380,"updated_by":1}],"roles_users":[{"id":1,"role_id":4,"user_id":1}],"permissions":[{"id":1,"uuid":"b84a444f-950f-46ea-bc75-d289c3a284d9","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":1411456685452,"created_by":1,"updated_at":1411456685452,"updated_by":1},{"id":2,"uuid":"ae4de0fe-c986-4eb6-9c42-b70e955e9c0a","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":1411456685466,"created_by":1,"updated_at":1411456685466,"updated_by":1},{"id":3,"uuid":"f8614359-c51f-432e-8d32-c7cb951a7640","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":1411456685475,"created_by":1,"updated_at":1411456685475,"updated_by":1},{"id":4,"uuid":"d5806942-ba00-417d-b80c-b1760f4b2509","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":1411456685480,"created_by":1,"updated_at":1411456685480,"updated_by":1},{"id":5,"uuid":"c86cc50b-41d3-4f3f-8638-651a354c6b08","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":1411456685488,"created_by":1,"updated_at":1411456685488,"updated_by":1},{"id":6,"uuid":"9d7a40fa-d766-4507-b3aa-29547cab5573","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":1411456685492,"created_by":1,"updated_at":1411456685492,"updated_by":1},{"id":7,"uuid":"e8b673da-8241-4727-8316-448217406e26","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":1411456685499,"created_by":1,"updated_at":1411456685499,"updated_by":1},{"id":8,"uuid":"5528c250-ce45-458c-ac01-4438f3789f7e","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":1411456685506,"created_by":1,"updated_at":1411456685506,"updated_by":1},{"id":9,"uuid":"0a7734e0-aeb2-427f-a5a3-ff4817c5e839","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":1411456685511,"created_by":1,"updated_at":1411456685511,"updated_by":1},{"id":10,"uuid":"814928e6-313d-403e-9cdc-8f3bc517e863","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":1411456685515,"created_by":1,"updated_at":1411456685515,"updated_by":1},{"id":11,"uuid":"5e70c566-5e77-48b1-b3a2-a448ea8e6c3c","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":1411456685521,"created_by":1,"updated_at":1411456685521,"updated_by":1},{"id":12,"uuid":"c69d621d-3575-44ca-9576-2d887df38847","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":1411456685524,"created_by":1,"updated_at":1411456685524,"updated_by":1},{"id":13,"uuid":"0931e68e-0adf-4c08-ba6b-b6785869c068","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":1411456685530,"created_by":1,"updated_at":1411456685530,"updated_by":1},{"id":14,"uuid":"dd784a1e-67d3-46b9-9bee-38e59653364e","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":1411456685536,"created_by":1,"updated_at":1411456685536,"updated_by":1},{"id":15,"uuid":"15098abd-d040-4373-9fb6-85688dafd415","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":1411456685539,"created_by":1,"updated_at":1411456685539,"updated_by":1},{"id":16,"uuid":"5a53b44d-fc72-496f-bda3-f5e5633540b5","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":1411456685544,"created_by":1,"updated_at":1411456685544,"updated_by":1},{"id":17,"uuid":"d2c8493f-abca-457e-b0bb-551af483814b","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":1411456685549,"created_by":1,"updated_at":1411456685549,"updated_by":1},{"id":18,"uuid":"b19d8895-2455-4ffd-96aa-0dc1d0967e06","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":1411456685556,"created_by":1,"updated_at":1411456685556,"updated_by":1},{"id":19,"uuid":"8af88651-f3c9-44e3-b4b4-69693fb12ac5","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":1411456685560,"created_by":1,"updated_at":1411456685560,"updated_by":1},{"id":20,"uuid":"a3df97a2-29bf-44b4-85f6-d7bd21688e95","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":1411456685563,"created_by":1,"updated_at":1411456685563,"updated_by":1},{"id":21,"uuid":"e6fc6002-cd7e-44ca-9577-ebbf24fc3b19","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":1411456685571,"created_by":1,"updated_at":1411456685571,"updated_by":1},{"id":22,"uuid":"ac9ebdd8-8774-421e-91d9-60b8638abb1d","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":1411456685575,"created_by":1,"updated_at":1411456685575,"updated_by":1},{"id":23,"uuid":"548cab08-a8ed-4b7a-916c-593061ec26bc","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":1411456685582,"created_by":1,"updated_at":1411456685582,"updated_by":1},{"id":24,"uuid":"5265315e-5dc5-483a-8b2b-3c668b1ee9b2","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":1411456685587,"created_by":1,"updated_at":1411456685587,"updated_by":1},{"id":25,"uuid":"507e6f95-76ed-408b-a2b8-e04c66825682","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":1411456685591,"created_by":1,"updated_at":1411456685591,"updated_by":1},{"id":26,"uuid":"2dd0a088-7ced-47c5-90c4-fcbc4303ccad","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":1411456685596,"created_by":1,"updated_at":1411456685596,"updated_by":1},{"id":27,"uuid":"3972bd8d-4af4-4f88-be86-a34a13628be0","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":1411456685602,"created_by":1,"updated_at":1411456685602,"updated_by":1},{"id":28,"uuid":"f5ae61ba-b681-4413-a237-b26fd342900e","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":1411456685607,"created_by":1,"updated_at":1411456685607,"updated_by":1},{"id":29,"uuid":"5cace7f9-ac1c-4ad1-ba18-d216f7a7b384","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":1411456685611,"created_by":1,"updated_at":1411456685611,"updated_by":1},{"id":30,"uuid":"a9047319-bd78-432e-9980-53d7f72b2ca9","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":1411456685615,"created_by":1,"updated_at":1411456685615,"updated_by":1}],"permissions_users":[],"permissions_roles":[{"id":1,"role_id":1,"permission_id":1},{"id":2,"role_id":1,"permission_id":2},{"id":3,"role_id":1,"permission_id":3},{"id":4,"role_id":1,"permission_id":4},{"id":5,"role_id":1,"permission_id":5},{"id":6,"role_id":1,"permission_id":6},{"id":7,"role_id":1,"permission_id":7},{"id":8,"role_id":1,"permission_id":8},{"id":9,"role_id":1,"permission_id":9},{"id":10,"role_id":1,"permission_id":10},{"id":11,"role_id":1,"permission_id":11},{"id":12,"role_id":1,"permission_id":12},{"id":13,"role_id":1,"permission_id":13},{"id":14,"role_id":1,"permission_id":14},{"id":15,"role_id":1,"permission_id":15},{"id":16,"role_id":1,"permission_id":16},{"id":17,"role_id":1,"permission_id":17},{"id":18,"role_id":1,"permission_id":18},{"id":19,"role_id":1,"permission_id":19},{"id":20,"role_id":1,"permission_id":20},{"id":21,"role_id":1,"permission_id":21},{"id":22,"role_id":1,"permission_id":22},{"id":23,"role_id":1,"permission_id":23},{"id":24,"role_id":1,"permission_id":24},{"id":25,"role_id":1,"permission_id":25},{"id":26,"role_id":1,"permission_id":26},{"id":27,"role_id":1,"permission_id":27},{"id":28,"role_id":1,"permission_id":28},{"id":29,"role_id":1,"permission_id":29},{"id":30,"role_id":1,"permission_id":30},{"id":31,"role_id":2,"permission_id":8},{"id":32,"role_id":2,"permission_id":9},{"id":33,"role_id":2,"permission_id":10},{"id":34,"role_id":2,"permission_id":11},{"id":35,"role_id":2,"permission_id":12},{"id":36,"role_id":2,"permission_id":13},{"id":37,"role_id":2,"permission_id":14},{"id":38,"role_id":2,"permission_id":16},{"id":39,"role_id":2,"permission_id":17},{"id":40,"role_id":2,"permission_id":18},{"id":41,"role_id":2,"permission_id":19},{"id":42,"role_id":2,"permission_id":20},{"id":43,"role_id":2,"permission_id":21},{"id":44,"role_id":2,"permission_id":24},{"id":45,"role_id":2,"permission_id":25},{"id":46,"role_id":2,"permission_id":26},{"id":47,"role_id":2,"permission_id":27},{"id":48,"role_id":2,"permission_id":28},{"id":49,"role_id":2,"permission_id":29},{"id":50,"role_id":2,"permission_id":30},{"id":51,"role_id":3,"permission_id":8},{"id":52,"role_id":3,"permission_id":9},{"id":53,"role_id":3,"permission_id":11},{"id":54,"role_id":3,"permission_id":13},{"id":55,"role_id":3,"permission_id":14},{"id":56,"role_id":3,"permission_id":16},{"id":57,"role_id":3,"permission_id":17},{"id":58,"role_id":3,"permission_id":18},{"id":59,"role_id":3,"permission_id":20},{"id":60,"role_id":3,"permission_id":24},{"id":61,"role_id":3,"permission_id":25},{"id":62,"role_id":3,"permission_id":30}],"permissions_apps":[],"settings":[{"id":1,"uuid":"25187b05-24c9-47c1-86db-4c3d8abd2886","key":"databaseVersion","value":"003","type":"core","created_at":1411456686377,"created_by":1,"updated_at":1411456686377,"updated_by":1},{"id":2,"uuid":"75a194b0-aeca-4fd9-9206-e592352a827f","key":"dbHash","value":"6d851711-8aac-4e07-977b-23daa6f4c5f4","type":"core","created_at":1411456686388,"created_by":1,"updated_at":1411456686388,"updated_by":1},{"id":3,"uuid":"3a790505-37d0-4aa8-bd51-81e303597535","key":"nextUpdateCheck","value":"1442516180","type":"core","created_at":1411456686388,"created_by":1,"updated_at":1442429781084,"updated_by":1},{"id":4,"uuid":"5921fd0b-9279-4349-a1e2-3b188383f784","key":"displayUpdateNotification","value":"0.5.0","type":"core","created_at":1411456686389,"created_by":1,"updated_at":1442429781090,"updated_by":1},{"id":5,"uuid":"98fb9cee-ad61-4f28-92f2-11b934709566","key":"title","value":"BrianChristner.io","type":"blog","created_at":1411456686390,"created_by":1,"updated_at":1433322339465,"updated_by":1},{"id":6,"uuid":"66f5ce67-9d6a-4c54-ac18-4010f6938be9","key":"description","value":"Thoughts, Ideas, Technology and Travels","type":"blog","created_at":1411456686390,"created_by":1,"updated_at":1433322339466,"updated_by":1},{"id":7,"uuid":"3b9aeb41-8989-4bb3-ad35-602112168041","key":"email","value":"brian.christner@gmail.com","type":"blog","created_at":1411456686390,"created_by":1,"updated_at":1433322339468,"updated_by":1},{"id":8,"uuid":"3641c108-04b6-4a94-99d5-09d8953ab67e","key":"logo","value":"/content/images/2015/01/BC-2.png","type":"blog","created_at":1411456686390,"created_by":1,"updated_at":1433322339470,"updated_by":1},{"id":9,"uuid":"f7eeb5d9-6012-433d-8fa1-ed864bb78615","key":"cover","value":"/content/images/2015/06/macbook-1.jpeg","type":"blog","created_at":1411456686390,"created_by":1,"updated_at":1433322339471,"updated_by":1},{"id":10,"uuid":"d6d13d6f-ffef-4e31-a35c-f2e771ecd4d0","key":"defaultLang","value":"en_US","type":"blog","created_at":1411456686391,"created_by":1,"updated_at":1433322339473,"updated_by":1},{"id":11,"uuid":"ad511abd-a822-4d2a-81f7-331408ba9192","key":"postsPerPage","value":"6","type":"blog","created_at":1411456686391,"created_by":1,"updated_at":1433322339474,"updated_by":1},{"id":12,"uuid":"463e254f-41ab-4e93-97ba-ea18c2ba070e","key":"forceI18n","value":"true","type":"blog","created_at":1411456686391,"created_by":1,"updated_at":1433322339476,"updated_by":1},{"id":13,"uuid":"b0af514e-52d4-48b0-876b-ec6844d7dfb9","key":"permalinks","value":"/:slug/","type":"blog","created_at":1411456686391,"created_by":1,"updated_at":1433322339477,"updated_by":1},{"id":14,"uuid":"a1538458-8091-4ffe-8328-ef77640e6665","key":"activeTheme","value":"privado","type":"theme","created_at":1411456686392,"created_by":1,"updated_at":1433322339479,"updated_by":1},{"id":15,"uuid":"63b90d39-4102-4049-a902-968f042175db","key":"activeApps","value":"[]","type":"app","created_at":1411456686392,"created_by":1,"updated_at":1411456686392,"updated_by":1},{"id":16,"uuid":"9763d460-0026-4d25-a342-a5ebf9b3aaee","key":"installedApps","value":"[]","type":"app","created_at":1411456686392,"created_by":1,"updated_at":1439970594191,"updated_by":1},{"id":17,"uuid":"b3cdb7ac-b116-403f-803f-af99966ffae8","key":"ghost_head","value":"<meta name=\"google-site-verification\" content=\"olGrj1eUM83gpPR_GssS8qLf5rrFd18UVmIyCUP95FM\" />\n<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-45599274-1', 'auto');\n  ga('send', 'pageview');\n\n</script>","type":"blog","created_at":1418153015241,"created_by":1,"updated_at":1433322339480,"updated_by":1},{"id":18,"uuid":"b8e7a180-2514-4984-b688-beaa6e4305fd","key":"ghost_foot","value":"","type":"blog","created_at":1418153015243,"created_by":1,"updated_at":1433322339484,"updated_by":1},{"id":19,"uuid":"c788eb13-4e5e-4ad5-80bf-0d728d0a3274","key":"labs","value":"{}","type":"blog","created_at":1423140882709,"created_by":1,"updated_at":1433322339486,"updated_by":1},{"id":20,"uuid":"8391b6fa-2892-447f-bd04-ba29d29daf2f","key":"navigation","value":"[{\"label\":\"Home\",\"url\":\"/\"},{\"label\":\"About Me\",\"url\":\"/aboutme/\"},{\"label\":\"Contact Brian\",\"url\":\"/contact-brian-christner/\"}]","type":"blog","created_at":1425907542514,"created_by":1,"updated_at":1433322339487,"updated_by":1},{"id":21,"uuid":"8ee9e435-6acf-42c2-b936-a89462c2fe21","key":"isPrivate","value":"false","type":"blog","created_at":1431677249348,"created_by":1,"updated_at":1433322339489,"updated_by":1},{"id":22,"uuid":"c8f8b17c-aef7-4b5f-b402-6fe38ce7b210","key":"password","value":"","type":"blog","created_at":1431677249351,"created_by":1,"updated_at":1433322339490,"updated_by":1}],"tags":[{"id":8,"uuid":"66b0efdb-3ce9-43d9-90e8-8c634cf01276","name":"europe","slug":"europe","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745913,"created_by":1,"updated_at":1411458745913,"updated_by":1},{"id":9,"uuid":"13c0b7d4-acc2-4cd1-98eb-459aaacd95e9","name":"facebook","slug":"facebook","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745914,"created_by":1,"updated_at":1411458745914,"updated_by":1},{"id":11,"uuid":"56f65039-4e2d-4b8c-a7d3-8f6ead81c46c","name":"Gadgets","slug":"gadgets","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745914,"created_by":1,"updated_at":1411458745914,"updated_by":1},{"id":13,"uuid":"916f520d-5c3b-4016-bfbb-e07805c78af3","name":"Linux","slug":"linux","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745915,"created_by":1,"updated_at":1411458745915,"updated_by":1},{"id":15,"uuid":"8899a5e5-6168-441c-82b5-a08f6891d4d6","name":"Mountain Bike","slug":"mountain-bike","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745916,"created_by":1,"updated_at":1411458745916,"updated_by":1},{"id":21,"uuid":"70957fae-e5c0-4e2b-9160-2e1a8448b849","name":"NGINX","slug":"nginx","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745919,"created_by":1,"updated_at":1411458745919,"updated_by":1},{"id":25,"uuid":"2987c65a-b3a3-4ac2-a5b6-8b4670153fe9","name":"Security","slug":"security","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745921,"created_by":1,"updated_at":1411458745921,"updated_by":1},{"id":28,"uuid":"1c6a8151-b16b-4273-a75e-34f58e910b12","name":"Switzerland","slug":"switzerland","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745922,"created_by":1,"updated_at":1411458745922,"updated_by":1},{"id":31,"uuid":"701c9f12-4f01-4c0f-9255-a23befab90d1","name":"VMware","slug":"vmware","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745923,"created_by":1,"updated_at":1411458745923,"updated_by":1},{"id":34,"uuid":"934e91e4-bae8-4d36-9557-d8c91c5391ec","name":"Wordpress","slug":"wordpress","description":"","image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411458745924,"created_by":1,"updated_at":1411458745924,"updated_by":1},{"id":39,"uuid":"dce8c05e-1759-4237-aaa2-1bb0aac27b61","name":"docker","slug":"docker","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411579788744,"created_by":1,"updated_at":1411579788744,"updated_by":1},{"id":40,"uuid":"7ebf3bc9-2591-495b-bfed-e0efbce30762","name":"ghost ","slug":"ghost-tag","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1411737254601,"created_by":1,"updated_at":1411737254601,"updated_by":1},{"id":42,"uuid":"9c82f881-d8b4-4e36-9a50-25f5181eb1bc","name":"startup","slug":"startup","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1416398347843,"created_by":1,"updated_at":1416398347843,"updated_by":1},{"id":43,"uuid":"27dac929-ccb1-490f-b925-3c05e0da6cb8","name":"Bootstrapping","slug":"bootstrapping","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1416398347862,"created_by":1,"updated_at":1416398347862,"updated_by":1},{"id":55,"uuid":"064b5a4e-8ad9-47c4-93be-baf29fa5ff08","name":"random","slug":"random","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1421394363699,"created_by":1,"updated_at":1421394363699,"updated_by":1}],"posts_tags":[{"id":874,"post_id":22,"tag_id":42},{"id":875,"post_id":22,"tag_id":43},{"id":1062,"post_id":21,"tag_id":39},{"id":1081,"post_id":25,"tag_id":15},{"id":1083,"post_id":25,"tag_id":39},{"id":1084,"post_id":25,"tag_id":42},{"id":1085,"post_id":24,"tag_id":42},{"id":1086,"post_id":24,"tag_id":43},{"id":1088,"post_id":23,"tag_id":42},{"id":1090,"post_id":20,"tag_id":31},{"id":1097,"post_id":16,"tag_id":9},{"id":1098,"post_id":15,"tag_id":21},{"id":1101,"post_id":13,"tag_id":8},{"id":1102,"post_id":13,"tag_id":28},{"id":1118,"post_id":33,"tag_id":21},{"id":1119,"post_id":33,"tag_id":25},{"id":1120,"post_id":33,"tag_id":34},{"id":1121,"post_id":33,"tag_id":40},{"id":1168,"post_id":34,"tag_id":15},{"id":1178,"post_id":19,"tag_id":21},{"id":1179,"post_id":19,"tag_id":39},{"id":1180,"post_id":19,"tag_id":40},{"id":1183,"post_id":17,"tag_id":25},{"id":1184,"post_id":17,"tag_id":34},{"id":1188,"post_id":18,"tag_id":21},{"id":1190,"post_id":18,"tag_id":39},{"id":1193,"post_id":14,"tag_id":21},{"id":1194,"post_id":14,"tag_id":34},{"id":1198,"post_id":3,"tag_id":15},{"id":1199,"post_id":3,"tag_id":28},{"id":1204,"post_id":4,"tag_id":55},{"id":1206,"post_id":5,"tag_id":11},{"id":1209,"post_id":7,"tag_id":25},{"id":1210,"post_id":7,"tag_id":34},{"id":1212,"post_id":8,"tag_id":25},{"id":1215,"post_id":9,"tag_id":21},{"id":1216,"post_id":9,"tag_id":34},{"id":1218,"post_id":10,"tag_id":13},{"id":1221,"post_id":11,"tag_id":25},{"id":1222,"post_id":11,"tag_id":31},{"id":1223,"post_id":36,"tag_id":39},{"id":1225,"post_id":35,"tag_id":31},{"id":1267,"post_id":39,"tag_id":13},{"id":1268,"post_id":37,"tag_id":39},{"id":1274,"post_id":40,"tag_id":39},{"id":1307,"post_id":43,"tag_id":39},{"id":1311,"post_id":44,"tag_id":39}],"apps":[],"app_settings":[],"app_fields":[]}}